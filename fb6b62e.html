<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"tallate.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.18.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="Redis Cluster介绍Cluster 优势 线性的可扩展性：扩容即迁移槽，已有很多迁移案例；如果要保存更多的数据，可以直接增加Master来支持，比如每台Master存32G，要完美存下1T数据的话，可以设置32台的Master，当然实际情况下这样非常浪费，一般会少设置一些，只用几台Master来存储最热的数据。 没有合并操作：因为 Redis 中的 List 和 Set 中保存的 V">
<meta property="og:type" content="article">
<meta property="og:title" content="Redis高可用方案Cluster">
<meta property="og:url" content="https://tallate.github.io/fb6b62e.html">
<meta property="og:site_name" content="Tallate">
<meta property="og:description" content="Redis Cluster介绍Cluster 优势 线性的可扩展性：扩容即迁移槽，已有很多迁移案例；如果要保存更多的数据，可以直接增加Master来支持，比如每台Master存32G，要完美存下1T数据的话，可以设置32台的Master，当然实际情况下这样非常浪费，一般会少设置一些，只用几台Master来存储最热的数据。 没有合并操作：因为 Redis 中的 List 和 Set 中保存的 V">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://tallate.github.io/imgs/Redis/Cluster.png">
<meta property="og:image" content="https://tallate.github.io/imgs/Redis/%E7%BD%91%E7%BB%9C%E5%88%86%E5%8C%BA.png">
<meta property="og:image" content="https://tallate.github.io/imgs/Redis/RedisCluster%E6%AF%94%E5%AF%B9Codis.jpg">
<meta property="og:image" content="https://tallate.github.io/imgs/Redis/ConsistentHashLoadBalance.png">
<meta property="og:image" content="https://tallate.github.io/imgs/Redis/RedisCluster%E6%95%85%E9%9A%9C%E5%8F%91%E7%8E%B01.png">
<meta property="og:image" content="https://tallate.github.io/imgs/Redis/RedisCluster%E6%95%85%E9%9A%9C%E5%8F%91%E7%8E%B02.png">
<meta property="og:image" content="https://tallate.github.io/imgs/Redis/RedisCluster%E6%95%85%E9%9A%9C%E5%8F%91%E7%8E%B03.png">
<meta property="article:published_time" content="2019-09-22T04:21:48.000Z">
<meta property="article:modified_time" content="2025-07-06T17:56:20.904Z">
<meta property="article:author" content="tallate">
<meta property="article:tag" content="Redis">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://tallate.github.io/imgs/Redis/Cluster.png">


<link rel="canonical" href="https://tallate.github.io/fb6b62e.html">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://tallate.github.io/fb6b62e.html","path":"/fb6b62e.html","title":"Redis高可用方案Cluster"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Redis高可用方案Cluster | Tallate</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Tallate</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">该吃吃该喝喝 啥事别往心里搁</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="tags fa-fw"></i>标签<span class="badge">83</span></a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="th fa-fw"></i>分类<span class="badge">25</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="archive fa-fw"></i>归档<span class="badge">189</span></a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Redis-Cluster%E4%BB%8B%E7%BB%8D"><span class="nav-number">1.</span> <span class="nav-text">Redis Cluster介绍</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Cluster-%E4%BC%98%E5%8A%BF"><span class="nav-number">1.1.</span> <span class="nav-text">Cluster 优势</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Cluster-%E7%BC%BA%E7%82%B9"><span class="nav-number">1.2.</span> <span class="nav-text">Cluster 缺点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Cluster%E7%9A%84%E5%8E%BB%E4%B8%AD%E5%BF%83%E5%8C%96%E6%9E%B6%E6%9E%84"><span class="nav-number">1.3.</span> <span class="nav-text">Cluster的去中心化架构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%80%E8%87%B4%E6%80%A7"><span class="nav-number">1.4.</span> <span class="nav-text">一致性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Cluster-VS-Codis"><span class="nav-number">1.5.</span> <span class="nav-text">Cluster VS Codis</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%88%86%E5%B8%83%EF%BC%88%E5%88%86%E5%8C%BA%EF%BC%89%E5%92%8C%E6%9F%A5%E8%AF%A2%E8%B7%AF%E7%94%B1"><span class="nav-number">2.</span> <span class="nav-text">数据分布（分区）和查询路由</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%86%E5%8C%BA%E7%AD%96%E7%95%A5"><span class="nav-number">2.1.</span> <span class="nav-text">分区策略</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%86%E5%8C%BA%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%B1%82%E6%AC%A1"><span class="nav-number">2.2.</span> <span class="nav-text">分区的实现层次</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%86%E5%8C%BA%E7%9A%84%E7%BC%BA%E7%82%B9"><span class="nav-number">2.3.</span> <span class="nav-text">分区的缺点</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%8A%82%E7%82%B9%E9%80%9A%E4%BF%A1"><span class="nav-number">3.</span> <span class="nav-text">节点通信</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%89%A9%E5%AE%B9-%E7%BC%A9%E5%AE%B9"><span class="nav-number">4.</span> <span class="nav-text">扩容 &#x2F; 缩容</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%96%B0%E8%8A%82%E7%82%B9%E5%8A%A0%E5%85%A5%E6%B5%81%E7%A8%8B"><span class="nav-number">4.1.</span> <span class="nav-text">新节点加入流程</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%8A%82%E7%82%B9%E8%BF%81%E7%A7%BB%E8%BF%87%E7%A8%8B"><span class="nav-number">4.1.1.</span> <span class="nav-text">节点迁移过程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%BF%81%E7%A7%BB%E8%BF%87%E7%A8%8B%E4%B8%AD%E5%AF%B9%E6%96%B0%E8%AF%B7%E6%B1%82%E7%9A%84%E5%93%8D%E5%BA%94"><span class="nav-number">4.1.2.</span> <span class="nav-text">迁移过程中对新请求的响应</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%97%A7%E8%8A%82%E7%82%B9%E9%80%80%E5%87%BA%E6%B5%81%E7%A8%8B"><span class="nav-number">4.2.</span> <span class="nav-text">旧节点退出流程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%9B%86%E7%BE%A4%E8%A7%84%E6%A8%A1%E4%BC%B0%E7%AE%97"><span class="nav-number">4.3.</span> <span class="nav-text">集群规模估算</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AE%9E%E4%BE%8B%E9%97%B4%E6%95%B0%E6%8D%AE%E7%9A%84%E5%90%8C%E6%AD%A5"><span class="nav-number">4.3.1.</span> <span class="nav-text">实例间数据的同步</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%85%E9%9A%9C%E6%81%A2%E5%A4%8D%EF%BC%88%E5%AE%B9%E9%94%99%EF%BC%89"><span class="nav-number">5.</span> <span class="nav-text">故障恢复（容错）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%85%E9%9A%9C%E5%8F%91%E7%8E%B0"><span class="nav-number">5.1.</span> <span class="nav-text">故障发现</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#PFAIL"><span class="nav-number">5.1.1.</span> <span class="nav-text">PFAIL</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#FAIL"><span class="nav-number">5.1.2.</span> <span class="nav-text">FAIL</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AD%90%E8%8A%82%E7%82%B9%E9%80%89%E4%B8%BE%EF%BC%88%E6%95%85%E9%9A%9C%E8%BF%81%E7%A7%BB%EF%BC%89"><span class="nav-number">5.2.</span> <span class="nav-text">子节点选举（故障迁移）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%85%8D%E7%BD%AE%E6%9B%B4%E6%96%B0"><span class="nav-number">5.3.</span> <span class="nav-text">配置更新</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Cluster%E6%95%B0%E6%8D%AE%E4%B8%A2%E5%A4%B1%E9%9A%90%E6%82%A3%E5%8F%8A%E5%A4%84%E7%90%86%E6%96%B9%E6%A1%88"><span class="nav-number">6.</span> <span class="nav-text">Cluster数据丢失隐患及处理方案</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BC%9A%E5%8F%91%E7%94%9F%E8%84%91%E8%A3%82%EF%BC%9F"><span class="nav-number">6.1.</span> <span class="nav-text">为什么会发生脑裂？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%84%91%E8%A3%82%E4%BC%9A%E5%AF%BC%E8%87%B4%E6%95%B0%E6%8D%AE%E4%B8%A2%E5%A4%B1%EF%BC%9F"><span class="nav-number">6.2.</span> <span class="nav-text">为什么脑裂会导致数据丢失？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E8%BF%99%E7%A7%8D%E8%84%91%E8%A3%82%E9%97%AE%E9%A2%98%EF%BC%9F"><span class="nav-number">6.3.</span> <span class="nav-text">如何解决这种脑裂问题？</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C"><span class="nav-number">7.</span> <span class="nav-text">数据倾斜</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C%E7%9A%84%E5%8D%B1%E5%AE%B3"><span class="nav-number">7.1.</span> <span class="nav-text">数据倾斜的危害</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C%E7%9A%84%E6%88%90%E5%9B%A0"><span class="nav-number">7.2.</span> <span class="nav-text">数据倾斜的成因</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C%E7%9A%84%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95"><span class="nav-number">7.3.</span> <span class="nav-text">数据倾斜的解决办法</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#QA"><span class="nav-number">8.</span> <span class="nav-text">QA</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%82%E8%80%83"><span class="nav-number">9.</span> <span class="nav-text">参考</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">tallate</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">189</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">25</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">83</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/fb6b62e.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="tallate">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="Redis高可用方案Cluster | Tallate">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Redis高可用方案Cluster
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2019-09-22 12:21:48" itemprop="dateCreated datePublished" datetime="2019-09-22T12:21:48+08:00">2019-09-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-07-07 01:56:20" itemprop="dateModified" datetime="2025-07-07T01:56:20+08:00">2025-07-07</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%BC%93%E5%AD%98/" itemprop="url" rel="index"><span itemprop="name">缓存</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><span id="more"></span>

<h2 id="Redis-Cluster介绍"><a href="#Redis-Cluster介绍" class="headerlink" title="Redis Cluster介绍"></a>Redis Cluster介绍</h2><h3 id="Cluster-优势"><a href="#Cluster-优势" class="headerlink" title="Cluster 优势"></a>Cluster 优势</h3><ol>
<li>线性的可扩展性：扩容即迁移槽，已有很多迁移案例；<br>如果要保存更多的数据，可以直接增加Master来支持，比如每台Master存32G，要完美存下1T数据的话，可以设置32台的Master，当然实际情况下这样非常浪费，一般会少设置一些，只用几台Master来存储最热的数据。</li>
<li>没有合并操作：因为 Redis 中的 List 和 Set 中保存的 Value 通常是比较大的，可能会达数以百万计的元素，而它们可能被存储到了不同的 Redis 实例上，传输和合并这样的值将很容易称为一个主要的性能瓶颈；</li>
<li>写入安全（Write Safety）：只有在非常少见的 Master 宕机的情况下，写入才会失败，并且这个失败的时间窗口不大（由一个 Slave 顶替上来）；</li>
<li>可用性（Availability）：就算有部分 Master 不可用了，它们的 Slave 仍然可以通过选举提升为 Master。</li>
</ol>
<h3 id="Cluster-缺点"><a href="#Cluster-缺点" class="headerlink" title="Cluster 缺点"></a>Cluster 缺点</h3><ol>
<li>Redis 集群并不支持处理多个 keys 的命令，因为这需要在不同的节点间移动数据，从而达不到像 Redis 那样的性能，在高负载的情况下可能会导致不可预料的错误。</li>
<li>Redis 集群不像单机版本的 Redis 那样支持多个数据库，集群只有数据库 0，而且也不支持 SELECT 命令。</li>
</ol>
<h3 id="Cluster的去中心化架构"><a href="#Cluster的去中心化架构" class="headerlink" title="Cluster的去中心化架构"></a>Cluster的去中心化架构</h3><p><img src="/imgs/Redis/Cluster.png" alt="Cluster" title="Cluster"><br>redis cluster在设计的时候，就考虑到了<strong>去中心化</strong>，去中间件，也就是说，集群中的每个节点都是平等的关系，都是对等的，每个节点都保存各自的数据和整个集群的状态。<strong>所有的 redis 节点彼此互联(PING-PONG 机制)<strong>，内部使用</strong>二进制协议</strong>优化传输速度和带宽，而且这些连接保持活跃，这样就保证了我们只需要连接集群中的任意一个节点，就可以获取到其他节点的数据。客户端与 redis 节点直连，不需要中间 proxy 层，客户端不需要连接集群所有节点，连接集群中任何一个可用节点即可。</p>
<h3 id="一致性"><a href="#一致性" class="headerlink" title="一致性"></a>一致性</h3><p>Redis 不能保证强一致性，因为：</p>
<ol>
<li>异步复制：写操作会被异步复制到 slave 节点，但可能由于出现网络分区、脑裂而导致数据丢失。<br><img src="/imgs/Redis/%E7%BD%91%E7%BB%9C%E5%88%86%E5%8C%BA.png" alt="网络分区" title="网络分区"><br>如上图所示，客户端 Z1 向 Master-B 写入数据后，集群出现了网络分区，且分区持续的时间足够长导致此时 B1 被选举为新的 Master，则在此期间 Z1 向 B 写入的数据就都丢失了。<blockquote>
<p>网络分区出现期间，客户端 Z1 可以向主节点 B 发送写命令的最大时间是有限制的， 这一时间限制称为节点超时时间（node timeout）， 是 Redis 集群的一个重要的配置选项。</p>
</blockquote>
</li>
</ol>
<h3 id="Cluster-VS-Codis"><a href="#Cluster-VS-Codis" class="headerlink" title="Cluster VS Codis"></a>Cluster VS Codis</h3><p>Codis 集群中包含了 4 类关键组件。</p>
<ul>
<li>codis server：这是进行了二次开发的 Redis 实例，其中增加了额外的数据结构，支持数据迁移操作，主要负责处理具体的数据读写请求。</li>
<li>codis proxy：接收客户端请求，并把请求转发给 codis server。</li>
<li>Zookeeper 集群：保存集群元数据，例如数据位置信息和 codis proxy 信息。</li>
<li>codis dashboard 和 codis fe：共同组成了集群管理工具。其中，codis dashboard 负责执行集群管理工作，包括增删 codis server、codis proxy 和进行数据迁移。而 codis fe 负责提供 dashboard 的 Web 操作界面，便于我们直接在 Web 界面上进行集群管理。</li>
</ul>
<p>Codis如何处理一次请求：</p>
<ol>
<li>客户端连接Codis Proxy，将请求发给Proxy；</li>
<li>codis proxy 接收到请求，就会查询请求数据和 codis server 的映射关系，并把请求转发给相应的 codis server 进行处理</li>
<li>当 codis server 处理完请求后，会把结果返回给 codis proxy，proxy 再把数据返回给客户端。</li>
</ol>
<p>以4个方面来讨论</p>
<ul>
<li>数据分布<br>和Cluster类似，Codis将数据保存到slot，集群一共有1024个slot，需要手动分配给Codis Server，或者由dashboard自动分配。<br>当客户端要读写数据时，会使用CRC32算法计算key的哈希值，并对1024取模，就可以知道对应的是哪个slot了。<br>这个路由规则需要先配置到dashboard，dashboard会把路由表发送给codis proxy，并同时保存到ZooKeeper。<br>而Cluster的数据路由表是由每个实例管理的，如果发生变化，这些实例会通过Gossip协议来互相传播，如果实例比较多，就会占用比较多的网络资源。</li>
<li>集群扩容和数据迁移<br>如果要增加Codis Server来负载slot，需要配置要迁移的slot，Codis Server会将该slot中的数据<strong>一个一个</strong>地发送给目标Server。<br>增加Codis Proxy也是类似的流程。</li>
<li>客户端兼容性<br>Codis客户端直接和Codis Proxy连接，codis proxy 是和单实例客户端兼容的，而集群相关的管理工作又都是由Codis Proxy和Codis dashboard这些组件来完成的，不需要客户端参与。</li>
<li>可靠性保证<br>Codis Server保证可靠性：Codis Server本身是Redis实例，只是增加了集群相关的操作命令，可靠性是可以通过主从机制+哨兵来实现的。<br>Codis Proxy的可靠性：Proxy上的信息都来自ZooKeeper，例如路由表，只要ZooKeeper集群中实例半数以上可以正常工作，那么ZooKeeper集群就是正常的。</li>
</ul>
<p>比较：<br><img src="/imgs/Redis/RedisCluster%E6%AF%94%E5%AF%B9Codis.jpg" alt="RedisCluster比对Codis" title="RedisCluster比对Codis"></p>
<ul>
<li>从稳定性和成熟度来看，Codis 应用得比较早，在业界已经有了成熟的生产部署。虽然 Codis 引入了 proxy 和 Zookeeper，增加了集群复杂度，但是，proxy 的无状态设计和 Zookeeper 自身的稳定性，也给 Codis 的稳定使用提供了保证。而 Redis Cluster 的推出时间晚于 Codis，相对来说，成熟度要弱于 Codis，如果你想选择一个成熟稳定的方案，Codis 更加合适些。</li>
<li>从业务应用客户端兼容性来看，连接单实例的客户端可以直接连接 codis proxy，而原本连接单实例的客户端要想连接 Redis Cluster 的话，就需要开发新功能。所以，如果你的业务应用中大量使用了单实例的客户端，而现在想应用切片集群的话，建议你选择 Codis，这样可以避免修改业务应用中的客户端。</li>
<li>从使用 Redis 新命令和新特性来看，Codis server 是基于开源的 Redis 3.2.8 开发的，所以，Codis 并不支持 Redis 后续的开源版本中的新增命令和数据类型。另外，Codis 并没有实现开源 Redis 版本的所有命令，比如 BITOP、BLPOP、BRPOP，以及和与事务相关的 MUTLI、EXEC 等命令。Codis 官网上列出了不被支持的命令列表，你在使用时记得去核查一下。所以，如果你想使用开源 Redis 版本的新特性，Redis Cluster 是一个合适的选择。</li>
<li>从数据迁移性能维度来看，Codis 能支持异步迁移，异步迁移对集群处理正常请求的性能影响要比使用同步迁移的小。所以，如果你在应用集群时，数据迁移比较频繁的话，Codis 是个更合适的选择。</li>
</ul>
<h2 id="数据分布（分区）和查询路由"><a href="#数据分布（分区）和查询路由" class="headerlink" title="数据分布（分区）和查询路由"></a>数据分布（分区）和查询路由</h2><h3 id="分区策略"><a href="#分区策略" class="headerlink" title="分区策略"></a>分区策略</h3><p>分区将原来比较大的数据集分离存储到多个存储媒介上，分区后Redis可以管理更大的内存空间和计算能力，但同时多主机又会面临很多分布式集群的可用性、一致性等问题。<br>分区策略：</p>
<ol>
<li>范围分区<br>将不同范围的对象映射到不同的Redis实例，比如用户ID为0到10000的存储到R0,10001到20000的存储到R1，以此类推。<br>缺点是需要建立一张映射表，谨小甚微地维护ID和Redis实例之间的映射关系，而且由于需要维护表，导致效率不如其他方案。</li>
<li>散列分区<br>使用散列函数（如CRC32）将key转换为一个数字，取模得到一个0到3的数字（假设Redis服务器有4台），这个数字即对应服务器的序号。</li>
<li>一致性哈希<br>一致性哈希的一种示例实现可以参考Dubbo中的实现：<code>com.alibaba.dubbo.rpc.cluster.loadbalance.ConsistentHashLoadBalance</code><br>关键代码如下：<br><img src="/imgs/Redis/ConsistentHashLoadBalance.png" alt="ConsistentHashLoadBalance" title="ConsistentHashLoadBalance"></li>
<li>哈希槽<br>Redis Cluster采用的是哈希槽的方式。<br>Redis 集群没有并使用传统的<strong>一致性哈希</strong>来分配数据，而是采用另外一种叫做<strong>哈希槽 (hash slot)<strong>的方式来分配的。redis cluster 默认分配了 16384 个 slot，当我们 set 一个 key 时，会用</strong>CRC16</strong>算法来取模得到所属的 slot，然后将这个 key 分到哈希槽区间的节点上，具体算法就是：<code>CRC16(key) % 16384</code>。所以我们在测试的时候看到 set 和 get 的时候，直接跳转到了 7000 端口的节点。<br>客户端在接收到重定向错误（redirections errors） -MOVED 和 -ASK 的时候， 将命令重定向到其他节点。客户端不需要存储集群信息（槽所在位置），但是如何客户端可以缓存键值和节点之间的映射关系，就可以明显提高命令执行的效率了（Redisson 中就是这么做的）。<br>在 Cluster 架构中，slave 节点不分配槽，只拥有读权限，但是在代码中 cluster 执行读写操作的都是 master 节点，并不是读就是从节点、写就是主节点。</li>
</ol>
<p>源码中，Redis采用一个大小固定为<code>CLUSTER_SLOTS</code>的clusterNode数组<code>slots</code>来保存每个桶的负责节点，这是个字节数组，每个位表示当前节点是否负责这个槽：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br></pre></td><td class="code"><pre><span class="line">// 节点状态</span><br><span class="line">struct clusterNode &#123;</span><br><span class="line"></span><br><span class="line">    // 创建节点的时间</span><br><span class="line">    mstime_t ctime; /* Node object creation time. */</span><br><span class="line"></span><br><span class="line">    // 节点的名字，由 40 个十六进制字符组成</span><br><span class="line">    // 例如 68eef66df23420a5862208ef5b1a7005b806f2ff</span><br><span class="line">    char name[REDIS_CLUSTER_NAMELEN]; /* Node name, hex string, sha1-size */</span><br><span class="line"></span><br><span class="line">    // 节点标识</span><br><span class="line">    // 使用各种不同的标识值记录节点的角色（比如主节点或者从节点），</span><br><span class="line">    // 以及节点目前所处的状态（比如在线或者下线）。</span><br><span class="line">    int flags;      /* REDIS_NODE_... */</span><br><span class="line"></span><br><span class="line">    // 节点当前的配置纪元，用于实现故障转移</span><br><span class="line">    uint64_t configEpoch; /* Last configEpoch observed for this node */</span><br><span class="line"></span><br><span class="line">    // 由这个节点负责处理的槽</span><br><span class="line">    // 一共有 REDIS_CLUSTER_SLOTS / 8 个字节长</span><br><span class="line">    // 每个字节的每个位记录了一个槽的保存状态</span><br><span class="line">    // 位的值为 1 表示槽正由本节点处理，值为 0 则表示槽并非本节点处理</span><br><span class="line">    // 比如 slots[0] 的第一个位保存了槽 0 的保存情况</span><br><span class="line">    // slots[0] 的第二个位保存了槽 1 的保存情况，以此类推</span><br><span class="line">    unsigned char slots[REDIS_CLUSTER_SLOTS/8]; /* slots handled by this node */</span><br><span class="line"></span><br><span class="line">    // 该节点负责处理的槽数量</span><br><span class="line">    int numslots;   /* Number of slots handled by this node */</span><br><span class="line"></span><br><span class="line">    // 如果本节点是主节点，那么用这个属性记录从节点的数量</span><br><span class="line">    int numslaves;  /* Number of slave nodes, if this is a master */</span><br><span class="line"></span><br><span class="line">    // 指针数组，指向各个从节点</span><br><span class="line">    struct clusterNode **slaves; /* pointers to slave nodes */</span><br><span class="line"></span><br><span class="line">    // 如果这是一个从节点，那么指向主节点</span><br><span class="line">    struct clusterNode *slaveof; /* pointer to the master node */</span><br><span class="line"></span><br><span class="line">    // 最后一次发送 PING 命令的时间</span><br><span class="line">    mstime_t ping_sent;      /* Unix time we sent latest ping */</span><br><span class="line"></span><br><span class="line">    // 最后一次接收 PONG 回复的时间戳</span><br><span class="line">    mstime_t pong_received;  /* Unix time we received the pong */</span><br><span class="line"></span><br><span class="line">    // 最后一次被设置为 FAIL 状态的时间</span><br><span class="line">    mstime_t fail_time;      /* Unix time when FAIL flag was set */</span><br><span class="line"></span><br><span class="line">    // 最后一次给某个从节点投票的时间</span><br><span class="line">    mstime_t voted_time;     /* Last time we voted for a slave of this master */</span><br><span class="line"></span><br><span class="line">    // 最后一次从这个节点接收到复制偏移量的时间</span><br><span class="line">    mstime_t repl_offset_time;  /* Unix time we received offset for this node */</span><br><span class="line"></span><br><span class="line">    // 这个节点的复制偏移量</span><br><span class="line">    long long repl_offset;      /* Last known repl offset for this node. */</span><br><span class="line"></span><br><span class="line">    // 节点的 IP 地址</span><br><span class="line">    char ip[REDIS_IP_STR_LEN];  /* Latest known IP address of this node */</span><br><span class="line"></span><br><span class="line">    // 节点的端口号</span><br><span class="line">    int port;                   /* Latest known port of this node */</span><br><span class="line"></span><br><span class="line">    // 保存连接节点所需的有关信息</span><br><span class="line">    clusterLink *link;          /* TCP/IP link with this node */</span><br><span class="line"></span><br><span class="line">    // 一个链表，记录了所有其他节点对该节点的下线报告</span><br><span class="line">    list *fail_reports;         /* List of nodes signaling this as failing */</span><br><span class="line"></span><br><span class="line">&#125;;</span><br><span class="line">typedef struct clusterNode clusterNode;</span><br><span class="line"></span><br><span class="line">// 集群状态，每个节点都保存着一个这样的状态，记录了它们眼中的集群的样子。</span><br><span class="line">// 另外，虽然这个结构主要用于记录集群的属性，但是为了节约资源，</span><br><span class="line">// 有些与节点有关的属性，比如 slots_to_keys 、 failover_auth_count </span><br><span class="line">// 也被放到了这个结构里面。</span><br><span class="line">typedef struct clusterState &#123;</span><br><span class="line"></span><br><span class="line">    // 指向当前节点的指针</span><br><span class="line">    clusterNode *myself;  /* This node */</span><br><span class="line"></span><br><span class="line">    // 集群当前的配置纪元，用于实现故障转移</span><br><span class="line">    uint64_t currentEpoch;</span><br><span class="line"></span><br><span class="line">    // 集群当前的状态：是在线还是下线</span><br><span class="line">    int state;            /* REDIS_CLUSTER_OK, REDIS_CLUSTER_FAIL, ... */</span><br><span class="line"></span><br><span class="line">    // 集群中至少处理着一个槽的节点的数量。</span><br><span class="line">    int size;             /* Num of master nodes with at least one slot */</span><br><span class="line"></span><br><span class="line">    // 集群节点名单（包括 myself 节点）</span><br><span class="line">    // 字典的键为节点的名字，字典的值为 clusterNode 结构</span><br><span class="line">    dict *nodes;          /* Hash table of name -&gt; clusterNode structures */</span><br><span class="line"></span><br><span class="line">    // 节点黑名单，用于 CLUSTER FORGET 命令</span><br><span class="line">    // 防止被 FORGET 的命令重新被添加到集群里面</span><br><span class="line">    // （不过现在似乎没有在使用的样子，已废弃？还是尚未实现？）</span><br><span class="line">    dict *nodes_black_list; /* Nodes we don&#x27;t re-add for a few seconds. */</span><br><span class="line"></span><br><span class="line">    // 记录要从当前节点迁移到目标节点的槽，以及迁移的目标节点</span><br><span class="line">    // migrating_slots_to[i] = NULL 表示槽 i 未被迁移</span><br><span class="line">    // migrating_slots_to[i] = clusterNode_A 表示槽 i 要从本节点迁移至节点 A</span><br><span class="line">    clusterNode *migrating_slots_to[REDIS_CLUSTER_SLOTS];</span><br><span class="line"></span><br><span class="line">    // 记录要从源节点迁移到本节点的槽，以及进行迁移的源节点</span><br><span class="line">    // importing_slots_from[i] = NULL 表示槽 i 未进行导入</span><br><span class="line">    // importing_slots_from[i] = clusterNode_A 表示正从节点 A 中导入槽 i</span><br><span class="line">    clusterNode *importing_slots_from[REDIS_CLUSTER_SLOTS];</span><br><span class="line"></span><br><span class="line">    // 负责处理各个槽的节点</span><br><span class="line">    // 例如 slots[i] = clusterNode_A 表示槽 i 由节点 A 处理</span><br><span class="line">    clusterNode *slots[REDIS_CLUSTER_SLOTS];</span><br><span class="line"></span><br><span class="line">    // 跳跃表，表中以槽作为分值，键作为成员，对槽进行有序排序</span><br><span class="line">    // 当需要对某些槽进行区间（range）操作时，这个跳跃表可以提供方便</span><br><span class="line">    // 具体操作定义在 db.c 里面</span><br><span class="line">    zskiplist *slots_to_keys;</span><br><span class="line"></span><br><span class="line">    /* The following fields are used to take the slave state on elections. */</span><br><span class="line">    // 以下这些域被用于进行故障转移选举</span><br><span class="line"></span><br><span class="line">    // 上次执行选举或者下次执行选举的时间</span><br><span class="line">    mstime_t failover_auth_time; /* Time of previous or next election. */</span><br><span class="line"></span><br><span class="line">    // 节点获得的投票数量</span><br><span class="line">    int failover_auth_count;    /* Number of votes received so far. */</span><br><span class="line"></span><br><span class="line">    // 如果值为 1 ，表示本节点已经向其他节点发送了投票请求</span><br><span class="line">    int failover_auth_sent;     /* True if we already asked for votes. */</span><br><span class="line"></span><br><span class="line">    int failover_auth_rank;     /* This slave rank for current auth request. */</span><br><span class="line"></span><br><span class="line">    uint64_t failover_auth_epoch; /* Epoch of the current election. */</span><br><span class="line"></span><br><span class="line">    /* Manual failover state in common. */</span><br><span class="line">    /* 共用的手动故障转移状态 */</span><br><span class="line"></span><br><span class="line">    // 手动故障转移执行的时间限制</span><br><span class="line">    mstime_t mf_end;            /* Manual failover time limit (ms unixtime).</span><br><span class="line">                                   It is zero if there is no MF in progress. */</span><br><span class="line">    /* Manual failover state of master. */</span><br><span class="line">    /* 主服务器的手动故障转移状态 */</span><br><span class="line">    clusterNode *mf_slave;      /* Slave performing the manual failover. */</span><br><span class="line">    /* Manual failover state of slave. */</span><br><span class="line">    /* 从服务器的手动故障转移状态 */</span><br><span class="line">    long long mf_master_offset; /* Master offset the slave needs to start MF</span><br><span class="line">                                   or zero if stil not received. */</span><br><span class="line">    // 指示手动故障转移是否可以开始的标志值</span><br><span class="line">    // 值为非 0 时表示各个主服务器可以开始投票</span><br><span class="line">    int mf_can_start;           /* If non-zero signal that the manual failover</span><br><span class="line">                                   can start requesting masters vote. */</span><br><span class="line"></span><br><span class="line">    /* The followign fields are uesd by masters to take state on elections. */</span><br><span class="line">    /* 以下这些域由主服务器使用，用于记录选举时的状态 */</span><br><span class="line"></span><br><span class="line">    // 集群最后一次进行投票的纪元</span><br><span class="line">    uint64_t lastVoteEpoch;     /* Epoch of the last vote granted. */</span><br><span class="line"></span><br><span class="line">    // 在进入下个事件循环之前要做的事情，以各个 flag 来记录</span><br><span class="line">    int todo_before_sleep; /* Things to do in clusterBeforeSleep(). */</span><br><span class="line"></span><br><span class="line">    // 通过 cluster 连接发送的消息数量</span><br><span class="line">    long long stats_bus_messages_sent;  /* Num of msg sent via cluster bus. */</span><br><span class="line"></span><br><span class="line">    // 通过 cluster 接收到的消息数量</span><br><span class="line">    long long stats_bus_messages_received; /* Num of msg rcvd via cluster bus.*/</span><br><span class="line"></span><br><span class="line">&#125; clusterState;</span><br></pre></td></tr></table></figure>

<h3 id="分区的实现层次"><a href="#分区的实现层次" class="headerlink" title="分区的实现层次"></a>分区的实现层次</h3><p>分区可以在程序的不同层次实现。</p>
<ul>
<li><strong>客户端分区</strong><br>就是在客户端就已经决定数据会被存储到哪个redis节点或者从哪个redis节点读取。大多数客户端已经实现了客户端分区。</li>
<li><strong>代理分区</strong><br>意味着客户端将请求发送给代理，然后代理决定去哪个节点写数据或者读数据。代理根据分区规则决定请求哪些Redis实例，然后根据Redis的响应结果返回给客户端。redis和memcached的一种代理实现就是Twemproxy</li>
<li><strong>查询路由(Query routing)</strong><br>意思是客户端随机地请求任意一个redis实例，然后由Redis将请求转发给正确的Redis节点。Redis Cluster实现了一种混合形式的查询路由，但并不是直接将请求从一个redis节点转发到另一个redis节点，而是在客户端的帮助下直接redirected到正确的redis节点。</li>
</ul>
<p>Redis Cluster采用的是<strong>查询路由</strong>的方式。<br>在Cluster模式下，Redis接收任何命令都会首先计算键对应的桶编号，再根据桶找出所对应的节点，如果节点是自身，则处理键命令；否则回复<code>MOVED</code>重定向错误，通知客户端请求正确的节点，这个过程称为MOVED重定向。<br>在客户端初次连接Redis集群时，如果客户端是<strong>Smart Client</strong>，它会获取集群的节点信息及slot的分布信息，并在本地缓存一份 hash slot 与node关系的路由表，这样不必每次访问服务器时都因为重定向而经过多次网络调用。<br>redis-cli不是smart client，它没有缓存路由表的功能；Java客户端Redisson是smart client，它在初始化时会调用redis实例的<code>CLUSTER NODES</code>命令来获取集群中每个Master负责的slot范围，并启动一个定时任务来每秒刷新本地缓存的集群状态：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * 启动时查询集群状态</span><br><span class="line"> */</span><br><span class="line">public ClusterConnectionManager(ClusterServersConfig cfg, Config config) &#123;</span><br><span class="line">    super(config);</span><br><span class="line"></span><br><span class="line">    this.config = create(cfg);</span><br><span class="line">    initTimer(this.config);</span><br><span class="line"></span><br><span class="line">    Throwable lastException = null;</span><br><span class="line">    List&lt;String&gt; failedMasters = new ArrayList&lt;String&gt;();</span><br><span class="line">    for (URI addr : cfg.getNodeAddresses()) &#123;</span><br><span class="line">        RFuture&lt;RedisConnection&gt; connectionFuture = connect(cfg, addr);</span><br><span class="line">        try &#123;</span><br><span class="line">            RedisConnection connection = connectionFuture.syncUninterruptibly().getNow();</span><br><span class="line">            </span><br><span class="line">            // 发送cluster nodes命令</span><br><span class="line">            </span><br><span class="line">            clusterNodesCommand = RedisCommands.CLUSTER_NODES;</span><br><span class="line">            if (&quot;rediss&quot;.equals(addr.getScheme())) &#123;</span><br><span class="line">                clusterNodesCommand = RedisCommands.CLUSTER_NODES_SSL;</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">            List&lt;ClusterNodeInfo&gt; nodes = connection.sync(clusterNodesCommand);</span><br><span class="line">            </span><br><span class="line">            StringBuilder nodesValue = new StringBuilder();</span><br><span class="line">            for (ClusterNodeInfo clusterNodeInfo : nodes) &#123;</span><br><span class="line">                nodesValue.append(clusterNodeInfo.getNodeInfo()).append(&quot;\n&quot;);</span><br><span class="line">            &#125;</span><br><span class="line">            log.info(&quot;Redis cluster nodes configuration got from &#123;&#125;:\n&#123;&#125;&quot;, connection.getRedisClient().getAddr(), nodesValue);</span><br><span class="line"></span><br><span class="line">            lastClusterNode = addr;</span><br><span class="line">            </span><br><span class="line">            // 读取每个节点的分区配置</span><br><span class="line">            </span><br><span class="line">            Collection&lt;ClusterPartition&gt; partitions = parsePartitions(nodes);</span><br><span class="line">            </span><br><span class="line">            ...</span><br><span class="line">            </span><br><span class="line">        &#125; catch (Exception e) &#123;</span><br><span class="line">            lastException = e;</span><br><span class="line">            log.warn(e.getMessage());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    ...</span><br><span class="line">    </span><br><span class="line">    // 每秒定时刷新本地缓存的cluster状态，包括每个Master节点负责的slot范围</span><br><span class="line">    scheduleClusterChangeCheck(cfg, null);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * 获取key所处的节点</span><br><span class="line"> */</span><br><span class="line">private NodeSource getNodeSource(String key) &#123;</span><br><span class="line">    int slot = connectionManager.calcSlot(key);</span><br><span class="line">    MasterSlaveEntry entry = connectionManager.getEntry(slot);</span><br><span class="line">    return new NodeSource(entry);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * 获取key所处的节点</span><br><span class="line"> */</span><br><span class="line">protected &lt;V, R&gt; void async(final boolean readOnlyMode, final NodeSource source, final Codec codec,</span><br><span class="line">    // 建立连接、发送命令</span><br><span class="line">    final RFuture&lt;RedisConnection&gt; connectionFuture;</span><br><span class="line">    if (readOnlyMode) &#123;</span><br><span class="line">        connectionFuture = connectionManager.connectionReadOp(source, command);</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        connectionFuture = connectionManager.connectionWriteOp(source, command);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    ...</span><br><span class="line">    </span><br><span class="line">    connectionFuture.addListener(new FutureListener&lt;RedisConnection&gt;() &#123;</span><br><span class="line">        @Override</span><br><span class="line">        public void operationComplete(Future&lt;RedisConnection&gt; connFuture) throws Exception &#123;</span><br><span class="line">            if (connFuture.isCancelled()) &#123;</span><br><span class="line">                return;</span><br><span class="line">            &#125;</span><br><span class="line">            // 如果执行不成功，则设置异常信息</span><br><span class="line">            if (!connFuture.isSuccess()) &#123;</span><br><span class="line">                connectionManager.getShutdownLatch().release();</span><br><span class="line">                details.setException(convertException(connectionFuture));</span><br><span class="line">                return;</span><br><span class="line">            &#125;</span><br><span class="line">            // 如果执行OK，释放连接</span><br><span class="line">            if (details.getAttemptPromise().isDone() || details.getMainPromise().isDone()) &#123;</span><br><span class="line">                releaseConnection(source, connectionFuture, details.isReadOnlyMode(), details.getAttemptPromise(), details);</span><br><span class="line">                return;</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">            final RedisConnection connection = connFuture.getNow();</span><br><span class="line">            // 响应ASK的情况</span><br><span class="line">            if (details.getSource().getRedirect() == Redirect.ASK) &#123;</span><br><span class="line">                List&lt;CommandData&lt;?, ?&gt;&gt; list = new ArrayList&lt;CommandData&lt;?, ?&gt;&gt;(2);</span><br><span class="line">                RPromise&lt;Void&gt; promise = connectionManager.newPromise();</span><br><span class="line">                list.add(new CommandData&lt;Void, Void&gt;(promise, details.getCodec(), RedisCommands.ASKING, new Object[]&#123;&#125;));</span><br><span class="line">                list.add(new CommandData&lt;V, R&gt;(details.getAttemptPromise(), details.getCodec(), details.getCommand(), details.getParams()));</span><br><span class="line">                RPromise&lt;Void&gt; main = connectionManager.newPromise();</span><br><span class="line">                ChannelFuture future = connection.send(new CommandsData(main, list));</span><br><span class="line">                details.setWriteFuture(future);</span><br><span class="line">            &#125;</span><br><span class="line">            // 响应MOVED的情况</span><br><span class="line">            else &#123;</span><br><span class="line">                if (log.isDebugEnabled()) &#123;</span><br><span class="line">                    log.debug(&quot;acquired connection for command &#123;&#125; and params &#123;&#125; from slot &#123;&#125; using node &#123;&#125;... &#123;&#125;&quot;,</span><br><span class="line">                            details.getCommand(), Arrays.toString(details.getParams()), details.getSource(), connection.getRedisClient().getAddr(), connection);</span><br><span class="line">                &#125;</span><br><span class="line">                ChannelFuture future = connection.send(new CommandData&lt;V, R&gt;(details.getAttemptPromise(), details.getCodec(), details.getCommand(), details.getParams()));</span><br><span class="line">                details.setWriteFuture(future);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            details.getWriteFuture().addListener(new ChannelFutureListener() &#123;</span><br><span class="line">                @Override</span><br><span class="line">                public void operationComplete(ChannelFuture future) throws Exception &#123;</span><br><span class="line">                    checkWriteFuture(details, connection);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line"></span><br><span class="line">            releaseConnection(source, connectionFuture, details.isReadOnlyMode(), details.getAttemptPromise(), details);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>下面是手动调用<code>cluster nodes</code>可以得到的响应，从中可以看到每个master所负责的slot范围：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">hgc@hgc-X555LD:~$ redis-cli -h 10.32.64.12 -p 16371 -c</span><br><span class="line">10.32.64.12:16371&gt; auth 123456</span><br><span class="line">OK</span><br><span class="line">10.32.64.12:16371&gt; cluster nodes</span><br><span class="line">d0af93527054ae3713c6ae82f4f58e016c4968d7 10.32.64.161:16371@26371 slave dbf60db7dc4c2d8ea944481d162bf6be7ef48f5a 0 1604569999114 28 connected</span><br><span class="line">20def2dff31ba78c04f72431a51054def2120638 10.32.64.161:16372@26372 master - 0 1604569998112 31 connected 0-5460</span><br><span class="line">b0c86436cd4cf6d2240faf01b45735616b82cae8 10.32.64.12:16371@26371 myself,slave 20def2dff31ba78c04f72431a51054def2120638 0 1604569995000 30 connected</span><br><span class="line">dbf60db7dc4c2d8ea944481d162bf6be7ef48f5a 10.32.64.162:16372@26372 master - 0 1604569996000 28 connected 5461-10922</span><br><span class="line">005c670071b5dab4ef085613f0ca6666fc5bcbce 10.32.64.12:16373@26373 slave df7f690feee2ad536f2573b55190e0f8d576779e 0 1604569998000 25 connected</span><br><span class="line">df7f690feee2ad536f2573b55190e0f8d576779e 10.32.64.162:16373@26373 master - 0 1604569997000 25 connected 10923-16383</span><br></pre></td></tr></table></figure>
<p>如果Cluster发生了扩容缩容或failover导致客户端缓存的信息过期，客户端只需要MOVED时重新更新本地缓存即可。<br>但是这里有一个问题，如果扩容缩容时正在发生槽迁移，这时正在迁移中的槽在哪个节点是不确定的，可能会导致客户端本地缓存的频繁更新。因此，Redis迁移过程中，会对正在迁移的槽打标记（<code>server.cluster-&gt;migrating_slots_to</code>），如果客户端访问的key命中了正在迁移中的槽，则服务器会返回<code>ASK</code>而不是<code>MOVED</code>，客户端接收到<code>ASK</code>后不会重新更新本地的槽缓存。<br>代码：<code>redis.c/processCommand</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line">/* If cluster is enabled perform the cluster redirection here.</span><br><span class="line"> *</span><br><span class="line"> * 如果开启了集群模式，那么在这里进行转向操作。</span><br><span class="line"> *</span><br><span class="line"> * However we don&#x27;t perform the redirection if:</span><br><span class="line"> *</span><br><span class="line"> * 不过，如果有以下情况出现，那么节点不进行转向：</span><br><span class="line"> *</span><br><span class="line"> * 1) The sender of this command is our master.</span><br><span class="line"> *    命令的发送者是本节点的主节点</span><br><span class="line"> *</span><br><span class="line"> * 2) The command has no key arguments. </span><br><span class="line"> *    命令没有 key 参数</span><br><span class="line"> */</span><br><span class="line">if (server.cluster_enabled &amp;&amp;</span><br><span class="line">    !(c-&gt;flags &amp; REDIS_MASTER) &amp;&amp;</span><br><span class="line">    !(c-&gt;cmd-&gt;getkeys_proc == NULL &amp;&amp; c-&gt;cmd-&gt;firstkey == 0))</span><br><span class="line">&#123;</span><br><span class="line">    int hashslot;</span><br><span class="line"></span><br><span class="line">    // 集群已下线</span><br><span class="line">    if (server.cluster-&gt;state != REDIS_CLUSTER_OK) &#123;</span><br><span class="line">        flagTransaction(c);</span><br><span class="line">        addReplySds(c,sdsnew(&quot;-CLUSTERDOWN The cluster is down. Use CLUSTER INFO for more information\r\n&quot;));</span><br><span class="line">        return REDIS_OK;</span><br><span class="line"></span><br><span class="line">    // 集群运作正常</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        int error_code;</span><br><span class="line">        clusterNode *n = getNodeByQuery(c,c-&gt;cmd,c-&gt;argv,c-&gt;argc,&amp;hashslot,&amp;error_code);</span><br><span class="line">        // 不能执行多键处理命令</span><br><span class="line">        if (n == NULL) &#123;</span><br><span class="line">            flagTransaction(c);</span><br><span class="line">            if (error_code == REDIS_CLUSTER_REDIR_CROSS_SLOT) &#123;</span><br><span class="line">                addReplySds(c,sdsnew(&quot;-CROSSSLOT Keys in request don&#x27;t hash to the same slot\r\n&quot;));</span><br><span class="line">            &#125; else if (error_code == REDIS_CLUSTER_REDIR_UNSTABLE) &#123;</span><br><span class="line">                /* The request spawns mutliple keys in the same slot,</span><br><span class="line">                 * but the slot is not &quot;stable&quot; currently as there is</span><br><span class="line">                 * a migration or import in progress. */</span><br><span class="line">                addReplySds(c,sdsnew(&quot;-TRYAGAIN Multiple keys request during rehashing of slot\r\n&quot;));</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                redisPanic(&quot;getNodeByQuery() unknown error.&quot;);</span><br><span class="line">            &#125;</span><br><span class="line">            return REDIS_OK;</span><br><span class="line"></span><br><span class="line">        // 命令针对的槽和键不是本节点处理的，进行转向</span><br><span class="line">        &#125; else if (n != server.cluster-&gt;myself) &#123;</span><br><span class="line">            flagTransaction(c);</span><br><span class="line">            // -&lt;ASK or MOVED&gt; &lt;slot&gt; &lt;ip&gt;:&lt;port&gt;</span><br><span class="line">            // 例如 -ASK 10086 127.0.0.1:12345</span><br><span class="line">            addReplySds(c,sdscatprintf(sdsempty(),</span><br><span class="line">                &quot;-%s %d %s:%d\r\n&quot;,</span><br><span class="line">                (error_code == REDIS_CLUSTER_REDIR_ASK) ? &quot;ASK&quot; : &quot;MOVED&quot;,</span><br><span class="line">                hashslot,n-&gt;ip,n-&gt;port));</span><br><span class="line"></span><br><span class="line">            return REDIS_OK;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        // 如果执行到这里，说明键 key 所在的槽由本节点处理</span><br><span class="line">        // 或者客户端执行的是无参数命令</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="分区的缺点"><a href="#分区的缺点" class="headerlink" title="分区的缺点"></a>分区的缺点</h3><p>有些特性在分区的情况下会受到限制：</p>
<ul>
<li>涉及多个key的操作通常不会被支持。例如你不能对两个集合求交集，因为他们可能被存储到不同的Redis实例（实际上这种情况也有办法，但是不能直接使用交集指令）。<br>同时操作多个key,则不能使用Redis事务.</li>
<li>分区使用的粒度是key，不能使用一个非常长的排序key存储一个数据集（The partitioning granularity is the key, so it is not possible to shard a dataset with a single huge key like a very big sorted set）.</li>
<li>当使用分区的时候，数据处理会非常复杂，例如为了备份你必须从不同的Redis实例和主机同时收集RDB &#x2F; AOF文件。</li>
<li>分区时动态扩容或缩容可能非常复杂。Redis集群在运行时增加或者删除Redis节点，能做到最大程度对用户透明地数据再平衡，但其他一些客户端分区或者代理分区方法则不支持这种特性。然而，有一种预分片的技术也可以较好的解决这个问题。</li>
</ul>
<p>当要把Redis当作持久化存储时，需要注意分区的性质</p>
<ul>
<li>如果Redis被当做缓存使用，使用一致性哈希实现动态扩容缩容。</li>
<li>如果Redis被当做一个持久化存储使用，必须使用固定的keys-to-nodes映射关系，节点的数量一旦确定不能变化。否则的话(即Redis节点需要动态变化的情况），必须使用可以在运行时进行数据再平衡的一套系统，现在Redis Cluster已经支持这种再平衡。</li>
</ul>
<h2 id="节点通信"><a href="#节点通信" class="headerlink" title="节点通信"></a>节点通信</h2><p>Redis Cluster采用Gossip协议完成集群状态数据及路由数据等元数据的管理。<br>一种简单的集群内状态同步思路是：每次节点都将自己本地的集群状态数据广播到集群内所有N个节点，其他节点判断接收到的数据比本地的新则更新本地数据。但是这种方式的缺点是通信量剧增，网络带宽变得紧张。<br>因此Redis采用Gossip协议来进行集群内元数据的同步，而且：<br>1、每次只随机选择K（K &lt;&lt; N）个其他节点来同步状态；<br>集群内每个节点维护定时任务默认每秒执行10次，每秒会随机选取5个节点找出最久没有通信的节点发送ping消息，用于保证Gossip信息交换的随机性。每100毫秒都会扫描本地节点列表，如果发现节点最近一次接受pong消息的时间大于cluster_node_timeout&#x2F;2，则立刻发送ping消息，防止该节点信息太长时间未更新。根据以上规则得出每个节点每秒需要发送ping消息的数量&#x3D;1+10*num（node.pong_received&gt;cluster_node_timeout&#x2F;2），因此cluster_node_timeout参数对消息发送的节点数量影响非常大。当我们的带宽资源紧张时，可以适当调大这个参数，如从默认15秒改为30秒来降低带宽占用率。过度调大cluster_node_timeout会影响消息交换的频率从而影响故障转移、槽信息更新、新节点发现的速度。因此需要根据业务容忍度和资源消耗进行平衡。同时整个集群消息总交换量也跟节点数成正比。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br></pre></td><td class="code"><pre><span class="line">/* This is executed 10 times every second */</span><br><span class="line">// 集群常规操作函数，默认每秒执行 10 次（每间隔 100 毫秒执行一次）</span><br><span class="line">void clusterCron(void) &#123;</span><br><span class="line">    dictIterator *di;</span><br><span class="line">    dictEntry *de;</span><br><span class="line">    int update_state = 0;</span><br><span class="line">    int orphaned_masters; /* How many masters there are without ok slaves. */</span><br><span class="line">    int max_slaves; /* Max number of ok slaves for a single master. */</span><br><span class="line">    int this_slaves; /* Number of ok slaves for our master (if we are slave). */</span><br><span class="line">    mstime_t min_pong = 0, now = mstime();</span><br><span class="line">    clusterNode *min_pong_node = NULL;</span><br><span class="line">    // 迭代计数器，一个静态变量</span><br><span class="line">    static unsigned long long iteration = 0;</span><br><span class="line">    mstime_t handshake_timeout;</span><br><span class="line"></span><br><span class="line">    // 记录一次迭代</span><br><span class="line">    iteration++; /* Number of times this function was called so far. */</span><br><span class="line"></span><br><span class="line">    /* The handshake timeout is the time after which a handshake node that was</span><br><span class="line">     * not turned into a normal node is removed from the nodes. Usually it is</span><br><span class="line">     * just the NODE_TIMEOUT value, but when NODE_TIMEOUT is too small we use</span><br><span class="line">     * the value of 1 second. */</span><br><span class="line">    // 如果一个 handshake 节点没有在 handshake timeout 内</span><br><span class="line">    // 转换成普通节点（normal node），</span><br><span class="line">    // 那么节点会从 nodes 表中移除这个 handshake 节点</span><br><span class="line">    // 一般来说 handshake timeout 的值总是等于 NODE_TIMEOUT</span><br><span class="line">    // 不过如果 NODE_TIMEOUT 太少的话，程序会将值设为 1 秒钟</span><br><span class="line">    handshake_timeout = server.cluster_node_timeout;</span><br><span class="line">    if (handshake_timeout &lt; 1000) handshake_timeout = 1000;</span><br><span class="line"></span><br><span class="line">    /* Check if we have disconnected nodes and re-establish the connection. */</span><br><span class="line">    // 向集群中的所有断线或者未连接节点发送消息</span><br><span class="line">    di = dictGetSafeIterator(server.cluster-&gt;nodes);</span><br><span class="line">    while((de = dictNext(di)) != NULL) &#123;</span><br><span class="line">        clusterNode *node = dictGetVal(de);</span><br><span class="line"></span><br><span class="line">        // 跳过当前节点以及没有地址的节点</span><br><span class="line">        if (node-&gt;flags &amp; (REDIS_NODE_MYSELF|REDIS_NODE_NOADDR)) continue;</span><br><span class="line"></span><br><span class="line">        /* A Node in HANDSHAKE state has a limited lifespan equal to the</span><br><span class="line">         * configured node timeout. */</span><br><span class="line">        // 如果 handshake 节点已超时，释放它</span><br><span class="line">        if (nodeInHandshake(node) &amp;&amp; now - node-&gt;ctime &gt; handshake_timeout) &#123;</span><br><span class="line">            freeClusterNode(node);</span><br><span class="line">            continue;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        // 为未创建连接的节点创建连接</span><br><span class="line">        if (node-&gt;link == NULL) &#123;</span><br><span class="line">            int fd;</span><br><span class="line">            mstime_t old_ping_sent;</span><br><span class="line">            clusterLink *link;</span><br><span class="line"></span><br><span class="line">            fd = anetTcpNonBlockBindConnect(server.neterr, node-&gt;ip,</span><br><span class="line">                node-&gt;port+REDIS_CLUSTER_PORT_INCR,</span><br><span class="line">                    server.bindaddr_count ? server.bindaddr[0] : NULL);</span><br><span class="line">            if (fd == -1) &#123;</span><br><span class="line">                redisLog(REDIS_DEBUG, &quot;Unable to connect to &quot;</span><br><span class="line">                    &quot;Cluster Node [%s]:%d -&gt; %s&quot;, node-&gt;ip,</span><br><span class="line">                    node-&gt;port+REDIS_CLUSTER_PORT_INCR,</span><br><span class="line">                    server.neterr);</span><br><span class="line">                continue;</span><br><span class="line">            &#125;</span><br><span class="line">            link = createClusterLink(node);</span><br><span class="line">            link-&gt;fd = fd;</span><br><span class="line">            node-&gt;link = link;</span><br><span class="line">            aeCreateFileEvent(server.el,link-&gt;fd,AE_READABLE,</span><br><span class="line">                    clusterReadHandler,link);</span><br><span class="line">            /* Queue a PING in the new connection ASAP: this is crucial</span><br><span class="line">             * to avoid false positives in failure detection.</span><br><span class="line">             *</span><br><span class="line">             * If the node is flagged as MEET, we send a MEET message instead</span><br><span class="line">             * of a PING one, to force the receiver to add us in its node</span><br><span class="line">             * table. */</span><br><span class="line">            // 向新连接的节点发送 PING 命令，防止节点被识进入下线</span><br><span class="line">            // 如果节点被标记为 MEET ，那么发送 MEET 命令，否则发送 PING 命令</span><br><span class="line">            old_ping_sent = node-&gt;ping_sent;</span><br><span class="line">            clusterSendPing(link, node-&gt;flags &amp; REDIS_NODE_MEET ?</span><br><span class="line">                    CLUSTERMSG_TYPE_MEET : CLUSTERMSG_TYPE_PING);</span><br><span class="line"></span><br><span class="line">            // 这不是第一次发送 PING 信息，所以可以还原这个时间</span><br><span class="line">            // 等 clusterSendPing() 函数来更新它</span><br><span class="line">            if (old_ping_sent) &#123;</span><br><span class="line">                /* If there was an active ping before the link was</span><br><span class="line">                 * disconnected, we want to restore the ping time, otherwise</span><br><span class="line">                 * replaced by the clusterSendPing() call. */</span><br><span class="line">                node-&gt;ping_sent = old_ping_sent;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            /* We can clear the flag after the first packet is sent.</span><br><span class="line">             *</span><br><span class="line">             * 在发送 MEET 信息之后，清除节点的 MEET 标识。</span><br><span class="line">             *</span><br><span class="line">             * If we&#x27;ll never receive a PONG, we&#x27;ll never send new packets</span><br><span class="line">             * to this node. Instead after the PONG is received and we</span><br><span class="line">             * are no longer in meet/handshake status, we want to send</span><br><span class="line">             * normal PING packets. </span><br><span class="line">             *</span><br><span class="line">             * 如果当前节点（发送者）没能收到 MEET 信息的回复，</span><br><span class="line">             * 那么它将不再向目标节点发送命令。</span><br><span class="line">             *</span><br><span class="line">             * 如果接收到回复的话，那么节点将不再处于 HANDSHAKE 状态，</span><br><span class="line">             * 并继续向目标节点发送普通 PING 命令。</span><br><span class="line">             */</span><br><span class="line">            node-&gt;flags &amp;= ~REDIS_NODE_MEET;</span><br><span class="line"></span><br><span class="line">            redisLog(REDIS_DEBUG,&quot;Connecting with Node %.40s at %s:%d&quot;,</span><br><span class="line">                    node-&gt;name, node-&gt;ip, node-&gt;port+REDIS_CLUSTER_PORT_INCR);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    dictReleaseIterator(di);</span><br><span class="line"></span><br><span class="line">    /* Ping some random node 1 time every 10 iterations, so that we usually ping</span><br><span class="line">     * one random node every second. */</span><br><span class="line">    // clusterCron() 每执行 10 次（至少间隔一秒钟），就向一个随机节点发送 gossip 信息</span><br><span class="line">    if (!(iteration % 10)) &#123;</span><br><span class="line">        int j;</span><br><span class="line"></span><br><span class="line">        /* Check a few random nodes and ping the one with the oldest</span><br><span class="line">         * pong_received time. */</span><br><span class="line">        // 随机 5 个节点，选出其中一个</span><br><span class="line">        for (j = 0; j &lt; 5; j++) &#123;</span><br><span class="line"></span><br><span class="line">            // 随机在集群中挑选节点</span><br><span class="line">            de = dictGetRandomKey(server.cluster-&gt;nodes);</span><br><span class="line">            clusterNode *this = dictGetVal(de);</span><br><span class="line"></span><br><span class="line">            /* Don&#x27;t ping nodes disconnected or with a ping currently active. */</span><br><span class="line">            // 不要 PING 连接断开的节点，也不要 PING 最近已经 PING 过的节点</span><br><span class="line">            if (this-&gt;link == NULL || this-&gt;ping_sent != 0) continue;</span><br><span class="line"></span><br><span class="line">            if (this-&gt;flags &amp; (REDIS_NODE_MYSELF|REDIS_NODE_HANDSHAKE))</span><br><span class="line">                continue;</span><br><span class="line"></span><br><span class="line">            // 选出 5 个随机节点中最近一次接收 PONG 回复距离现在最旧的节点</span><br><span class="line">            if (min_pong_node == NULL || min_pong &gt; this-&gt;pong_received) &#123;</span><br><span class="line">                min_pong_node = this;</span><br><span class="line">                min_pong = this-&gt;pong_received;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        // 向最久没有收到 PONG 回复的节点发送 PING 命令</span><br><span class="line">        if (min_pong_node) &#123;</span><br><span class="line">            redisLog(REDIS_DEBUG,&quot;Pinging node %.40s&quot;, min_pong_node-&gt;name);</span><br><span class="line">            clusterSendPing(min_pong_node-&gt;link, CLUSTERMSG_TYPE_PING);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // 遍历所有节点，检查是否需要将某个节点标记为下线</span><br><span class="line">    /* Iterate nodes to check if we need to flag something as failing.</span><br><span class="line">     * This loop is also responsible to:</span><br><span class="line">     * 1) Check if there are orphaned masters (masters without non failing</span><br><span class="line">     *    slaves).</span><br><span class="line">     * 2) Count the max number of non failing slaves for a single master.</span><br><span class="line">     * 3) Count the number of slaves for our master, if we are a slave. */</span><br><span class="line">    orphaned_masters = 0;</span><br><span class="line">    max_slaves = 0;</span><br><span class="line">    this_slaves = 0;</span><br><span class="line">    di = dictGetSafeIterator(server.cluster-&gt;nodes);</span><br><span class="line">    while((de = dictNext(di)) != NULL) &#123;</span><br><span class="line">        clusterNode *node = dictGetVal(de);</span><br><span class="line">        now = mstime(); /* Use an updated time at every iteration. */</span><br><span class="line">        mstime_t delay;</span><br><span class="line"></span><br><span class="line">        // 跳过节点本身、无地址节点、HANDSHAKE 状态的节点</span><br><span class="line">        if (node-&gt;flags &amp;</span><br><span class="line">            (REDIS_NODE_MYSELF|REDIS_NODE_NOADDR|REDIS_NODE_HANDSHAKE))</span><br><span class="line">                continue;</span><br><span class="line"></span><br><span class="line">        /* Orphaned master check, useful only if the current instance</span><br><span class="line">         * is a slave that may migrate to another master. */</span><br><span class="line">        if (nodeIsSlave(myself) &amp;&amp; nodeIsMaster(node) &amp;&amp; !nodeFailed(node)) &#123;</span><br><span class="line">            int okslaves = clusterCountNonFailingSlaves(node);</span><br><span class="line"></span><br><span class="line">            if (okslaves == 0 &amp;&amp; node-&gt;numslots &gt; 0) orphaned_masters++;</span><br><span class="line">            if (okslaves &gt; max_slaves) max_slaves = okslaves;</span><br><span class="line">            if (nodeIsSlave(myself) &amp;&amp; myself-&gt;slaveof == node)</span><br><span class="line">                this_slaves = okslaves;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        /* If we are waiting for the PONG more than half the cluster</span><br><span class="line">         * timeout, reconnect the link: maybe there is a connection</span><br><span class="line">         * issue even if the node is alive. */</span><br><span class="line">        // 如果等到 PONG 到达的时间超过了 node timeout 一半的连接</span><br><span class="line">        // 因为尽管节点依然正常，但连接可能已经出问题了</span><br><span class="line">        if (node-&gt;link &amp;&amp; /* is connected */</span><br><span class="line">            now - node-&gt;link-&gt;ctime &gt;</span><br><span class="line">            server.cluster_node_timeout &amp;&amp; /* was not already reconnected */</span><br><span class="line">            node-&gt;ping_sent &amp;&amp; /* we already sent a ping */</span><br><span class="line">            node-&gt;pong_received &lt; node-&gt;ping_sent &amp;&amp; /* still waiting pong */</span><br><span class="line">            /* and we are waiting for the pong more than timeout/2 */</span><br><span class="line">            now - node-&gt;ping_sent &gt; server.cluster_node_timeout/2)</span><br><span class="line">        &#123;</span><br><span class="line">            /* Disconnect the link, it will be reconnected automatically. */</span><br><span class="line">            // 释放连接，下次 clusterCron() 会自动重连</span><br><span class="line">            freeClusterLink(node-&gt;link);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        /* If we have currently no active ping in this instance, and the</span><br><span class="line">         * received PONG is older than half the cluster timeout, send</span><br><span class="line">         * a new ping now, to ensure all the nodes are pinged without</span><br><span class="line">         * a too big delay. */</span><br><span class="line">        // 如果目前没有在 PING 节点</span><br><span class="line">        // 并且已经有 node timeout 一半的时间没有从节点那里收到 PONG 回复</span><br><span class="line">        // 那么向节点发送一个 PING ，确保节点的信息不会太旧</span><br><span class="line">        // （因为一部分节点可能一直没有被随机中）</span><br><span class="line">        if (node-&gt;link &amp;&amp;</span><br><span class="line">            node-&gt;ping_sent == 0 &amp;&amp;</span><br><span class="line">            (now - node-&gt;pong_received) &gt; server.cluster_node_timeout/2)</span><br><span class="line">        &#123;</span><br><span class="line">            clusterSendPing(node-&gt;link, CLUSTERMSG_TYPE_PING);</span><br><span class="line">            continue;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        /* If we are a master and one of the slaves requested a manual</span><br><span class="line">         * failover, ping it continuously. */</span><br><span class="line">        // 如果这是一个主节点，并且有一个从服务器请求进行手动故障转移</span><br><span class="line">        // 那么向从服务器发送 PING 。</span><br><span class="line">        if (server.cluster-&gt;mf_end &amp;&amp;</span><br><span class="line">            nodeIsMaster(myself) &amp;&amp;</span><br><span class="line">            server.cluster-&gt;mf_slave == node &amp;&amp;</span><br><span class="line">            node-&gt;link)</span><br><span class="line">        &#123;</span><br><span class="line">            clusterSendPing(node-&gt;link, CLUSTERMSG_TYPE_PING);</span><br><span class="line">            continue;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        /* Check only if we have an active ping for this instance. */</span><br><span class="line">        // 以下代码只在节点发送了 PING 命令的情况下执行</span><br><span class="line">        if (node-&gt;ping_sent == 0) continue;</span><br><span class="line"></span><br><span class="line">        /* Compute the delay of the PONG. Note that if we already received</span><br><span class="line">         * the PONG, then node-&gt;ping_sent is zero, so can&#x27;t reach this</span><br><span class="line">         * code at all. */</span><br><span class="line">        // 计算等待 PONG 回复的时长</span><br><span class="line">        delay = now - node-&gt;ping_sent;</span><br><span class="line"></span><br><span class="line">        // 等待 PONG 回复的时长超过了限制值，将目标节点标记为 PFAIL （疑似下线）</span><br><span class="line">        if (delay &gt; server.cluster_node_timeout) &#123;</span><br><span class="line">            /* Timeout reached. Set the node as possibly failing if it is</span><br><span class="line">             * not already in this state. */</span><br><span class="line">            if (!(node-&gt;flags &amp; (REDIS_NODE_PFAIL|REDIS_NODE_FAIL))) &#123;</span><br><span class="line">                redisLog(REDIS_DEBUG,&quot;*** NODE %.40s possibly failing&quot;,</span><br><span class="line">                    node-&gt;name);</span><br><span class="line">                // 打开疑似下线标记</span><br><span class="line">                node-&gt;flags |= REDIS_NODE_PFAIL;</span><br><span class="line">                update_state = 1;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    dictReleaseIterator(di);</span><br><span class="line"></span><br><span class="line">    /* If we are a slave node but the replication is still turned off,</span><br><span class="line">     * enable it if we know the address of our master and it appears to</span><br><span class="line">     * be up. */</span><br><span class="line">    // 如果从节点没有在复制主节点，那么对从节点进行设置</span><br><span class="line">    if (nodeIsSlave(myself) &amp;&amp;</span><br><span class="line">        server.masterhost == NULL &amp;&amp;</span><br><span class="line">        myself-&gt;slaveof &amp;&amp;</span><br><span class="line">        nodeHasAddr(myself-&gt;slaveof))</span><br><span class="line">    &#123;</span><br><span class="line">        replicationSetMaster(myself-&gt;slaveof-&gt;ip, myself-&gt;slaveof-&gt;port);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    /* Abourt a manual failover if the timeout is reached. */</span><br><span class="line">    manualFailoverCheckTimeout();</span><br><span class="line"></span><br><span class="line">    if (nodeIsSlave(myself)) &#123;</span><br><span class="line">        clusterHandleManualFailover();</span><br><span class="line">        clusterHandleSlaveFailover();</span><br><span class="line">        /* If there are orphaned slaves, and we are a slave among the masters</span><br><span class="line">         * with the max number of non-failing slaves, consider migrating to</span><br><span class="line">         * the orphaned masters. Note that it does not make sense to try</span><br><span class="line">         * a migration if there is no master with at least *two* working</span><br><span class="line">         * slaves. */</span><br><span class="line">        if (orphaned_masters &amp;&amp; max_slaves &gt;= 2 &amp;&amp; this_slaves == max_slaves)</span><br><span class="line">            clusterHandleSlaveMigration(max_slaves);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // 更新集群状态</span><br><span class="line">    if (update_state || server.cluster-&gt;state == REDIS_CLUSTER_FAIL)</span><br><span class="line">        clusterUpdateState();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>2、状态信息并不是全量同步，而是随机选M（M &lt;&lt; N）个节点的状态同步到其他节点。<br>M值最小为3，最大为<code>N - 2</code>，一般情况下<code>M = N / 10</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br></pre></td><td class="code"><pre><span class="line">/* Send a PING or PONG packet to the specified node, making sure to add enough</span><br><span class="line"> * gossip informations. */</span><br><span class="line">// 向指定节点发送一条 MEET 、 PING 或者 PONG 消息</span><br><span class="line">void clusterSendPing(clusterLink *link, int type) &#123;</span><br><span class="line">    unsigned char buf[sizeof(clusterMsg)];</span><br><span class="line">    clusterMsg *hdr = (clusterMsg*) buf;</span><br><span class="line">    int gossipcount = 0, totlen;</span><br><span class="line">    /* freshnodes is the number of nodes we can still use to populate the</span><br><span class="line">     * gossip section of the ping packet. Basically we start with the nodes</span><br><span class="line">     * we have in memory minus two (ourself and the node we are sending the</span><br><span class="line">     * message to). Every time we add a node we decrement the counter, so when</span><br><span class="line">     * it will drop to &lt;= zero we know there is no more gossip info we can</span><br><span class="line">     * send. */</span><br><span class="line">    // freshnodes 是用于发送 gossip 信息的计数器</span><br><span class="line">    // 每次发送一条信息时，程序将 freshnodes 的值减一</span><br><span class="line">    // 当 freshnodes 的数值小于等于 0 时，程序停止发送 gossip 信息</span><br><span class="line">    // freshnodes 的数量是节点目前的 nodes 表中的节点数量减去 2 </span><br><span class="line">    // 这里的 2 指两个节点，一个是 myself 节点（也即是发送信息的这个节点）</span><br><span class="line">    // 另一个是接受 gossip 信息的节点</span><br><span class="line">    int freshnodes = dictSize(server.cluster-&gt;nodes)-2;</span><br><span class="line"></span><br><span class="line">    // 如果发送的信息是 PING ，那么更新最后一次发送 PING 命令的时间戳</span><br><span class="line">    if (link-&gt;node &amp;&amp; type == CLUSTERMSG_TYPE_PING)</span><br><span class="line">        link-&gt;node-&gt;ping_sent = mstime();</span><br><span class="line"></span><br><span class="line">    // 将当前节点的信息（比如名字、地址、端口号、负责处理的槽）记录到消息里面</span><br><span class="line">    clusterBuildMessageHdr(hdr,type);</span><br><span class="line"></span><br><span class="line">    /* Populate the gossip fields */</span><br><span class="line">    // 从当前节点已知的节点中随机选出两个节点</span><br><span class="line">    // 并通过这条消息捎带给目标节点，从而实现 gossip 协议</span><br><span class="line"></span><br><span class="line">    // 每个节点有 freshnodes 次发送 gossip 信息的机会</span><br><span class="line">    // 每次向目标节点发送 2 个被选中节点的 gossip 信息（gossipcount 计数）</span><br><span class="line">    while(freshnodes &gt; 0 &amp;&amp; gossipcount &lt; 3) &#123;</span><br><span class="line">        // 从 nodes 字典中随机选出一个节点（被选中节点）</span><br><span class="line">        dictEntry *de = dictGetRandomKey(server.cluster-&gt;nodes);</span><br><span class="line">        clusterNode *this = dictGetVal(de);</span><br><span class="line"></span><br><span class="line">        clusterMsgDataGossip *gossip;</span><br><span class="line">        int j;</span><br><span class="line"></span><br><span class="line">        /* In the gossip section don&#x27;t include:</span><br><span class="line">         * 以下节点不能作为被选中节点：</span><br><span class="line">         * 1) Myself.</span><br><span class="line">         *    节点本身。</span><br><span class="line">         * 2) Nodes in HANDSHAKE state.</span><br><span class="line">         *    处于 HANDSHAKE 状态的节点。</span><br><span class="line">         * 3) Nodes with the NOADDR flag set.</span><br><span class="line">         *    带有 NOADDR 标识的节点</span><br><span class="line">         * 4) Disconnected nodes if they don&#x27;t have configured slots.</span><br><span class="line">         *    因为不处理任何槽而被断开连接的节点 </span><br><span class="line">         */</span><br><span class="line">        if (this == myself ||</span><br><span class="line">            this-&gt;flags &amp; (REDIS_NODE_HANDSHAKE|REDIS_NODE_NOADDR) ||</span><br><span class="line">            (this-&gt;link == NULL &amp;&amp; this-&gt;numslots == 0))</span><br><span class="line">        &#123;</span><br><span class="line">                freshnodes--; /* otherwise we may loop forever. */</span><br><span class="line">                continue;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        /* Check if we already added this node */</span><br><span class="line">        // 检查被选中节点是否已经在 hdr-&gt;data.ping.gossip 数组里面</span><br><span class="line">        // 如果是的话说明这个节点之前已经被选中了</span><br><span class="line">        // 不要再选中它（否则就会出现重复）</span><br><span class="line">        for (j = 0; j &lt; gossipcount; j++) &#123;</span><br><span class="line">            if (memcmp(hdr-&gt;data.ping.gossip[j].nodename,this-&gt;name,</span><br><span class="line">                    REDIS_CLUSTER_NAMELEN) == 0) break;</span><br><span class="line">        &#125;</span><br><span class="line">        if (j != gossipcount) continue;</span><br><span class="line"></span><br><span class="line">        /* Add it */</span><br><span class="line"></span><br><span class="line">        // 这个被选中节点有效，计数器减一</span><br><span class="line">        freshnodes--;</span><br><span class="line"></span><br><span class="line">        // 指向 gossip 信息结构</span><br><span class="line">        gossip = &amp;(hdr-&gt;data.ping.gossip[gossipcount]);</span><br><span class="line"></span><br><span class="line">        // 将被选中节点的名字记录到 gossip 信息</span><br><span class="line">        memcpy(gossip-&gt;nodename,this-&gt;name,REDIS_CLUSTER_NAMELEN);</span><br><span class="line">        // 将被选中节点的 PING 命令发送时间戳记录到 gossip 信息</span><br><span class="line">        gossip-&gt;ping_sent = htonl(this-&gt;ping_sent);</span><br><span class="line">        // 将被选中节点的 PING 命令回复的时间戳记录到 gossip 信息</span><br><span class="line">        gossip-&gt;pong_received = htonl(this-&gt;pong_received);</span><br><span class="line">        // 将被选中节点的 IP 记录到 gossip 信息</span><br><span class="line">        memcpy(gossip-&gt;ip,this-&gt;ip,sizeof(this-&gt;ip));</span><br><span class="line">        // 将被选中节点的端口号记录到 gossip 信息</span><br><span class="line">        gossip-&gt;port = htons(this-&gt;port);</span><br><span class="line">        // 将被选中节点的标识值记录到 gossip 信息</span><br><span class="line">        gossip-&gt;flags = htons(this-&gt;flags);</span><br><span class="line"></span><br><span class="line">        // 这个被选中节点有效，计数器增一</span><br><span class="line">        gossipcount++;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // 计算信息长度</span><br><span class="line">    totlen = sizeof(clusterMsg)-sizeof(union clusterMsgData);</span><br><span class="line">    totlen += (sizeof(clusterMsgDataGossip)*gossipcount);</span><br><span class="line">    // 将被选中节点的数量（gossip 信息中包含了多少个节点的信息）</span><br><span class="line">    // 记录在 count 属性里面</span><br><span class="line">    hdr-&gt;count = htons(gossipcount);</span><br><span class="line">    // 将信息的长度记录到信息里面</span><br><span class="line">    hdr-&gt;totlen = htonl(totlen);</span><br><span class="line"></span><br><span class="line">    // 发送信息</span><br><span class="line">    clusterSendMessage(link,buf,totlen);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h2 id="扩容-缩容"><a href="#扩容-缩容" class="headerlink" title="扩容 &#x2F; 缩容"></a>扩容 &#x2F; 缩容</h2><p>当新的节点加入时，我们该如何重新分配数据，让新的节点也对外提供服务。当有节点退出时，我们该如何把存在该节点上的数据分配到其他机器上，让其他机器来提供这部分数据的服务。即集群的扩缩容问题。</p>
<h3 id="新节点加入流程"><a href="#新节点加入流程" class="headerlink" title="新节点加入流程"></a>新节点加入流程</h3><p>新节点加入时，需要把一部分数据迁移到新节点来达到集群的负载均衡。<br>在Redis集群中，数据的存储是以slot为单位的，因此：</p>
<ol>
<li>集群的伸缩本质上就是slot在不同机器节点之间的迁移；</li>
<li>迁移过程中，有的slot在老节点上，有的slot在新节点上，这时，客户端请求应该被重定向到正确的节点上。<br>比如slot1从A迁移到B上时，请求A或B会怎么样？请求别的节点又会怎么样？</li>
</ol>
<p>节点的迁移过程主要分为3个步骤：</p>
<ol>
<li>准备新节点</li>
<li>加入集群</li>
<li>迁移slot到新节点</li>
</ol>
<p>以下迁移过程的伪代码来自：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/105569485">Redis集群详解（中）</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">def move_slot(source,target,slot):</span><br><span class="line">    # 目标节点准备导入槽</span><br><span class="line">    target.cluster(&quot;setslot&quot;,slot,&quot;importing&quot;,source.nodeId);</span><br><span class="line">    # 目标节点准备全出槽</span><br><span class="line">    source.cluster(&quot;setslot&quot;,slot,&quot;migrating&quot;,target.nodeId);</span><br><span class="line">    while true :</span><br><span class="line">        # 批量从源节点获取键</span><br><span class="line">        keys = source.cluster(&quot;getkeysinslot&quot;,slot,pipeline_size);</span><br><span class="line">        if keys.length == 0:</span><br><span class="line">            # 键列表为空时，退出循环</span><br><span class="line">            break;</span><br><span class="line">        # 批量迁移键到目标节点</span><br><span class="line">        source.call(&quot;migrate&quot;,target.host,target.port,&quot;&quot;,0,timeout,&quot;keys&quot;,keys);</span><br><span class="line">    # 向集群所有主节点通知槽被分配给目标节点</span><br><span class="line">    for node in nodes:</span><br><span class="line">        if node.flag == &quot;slave&quot;:</span><br><span class="line">            continue;</span><br><span class="line">        node.cluster(&quot;setslot&quot;,slot,&quot;node&quot;,target.nodeId);</span><br></pre></td></tr></table></figure>

<h4 id="节点迁移过程"><a href="#节点迁移过程" class="headerlink" title="节点迁移过程"></a>节点迁移过程</h4><p>以下命令告知目标节点准备导入slot：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cluster setslot &lt;slot&gt; IMPORTING &lt;nodeId&gt;</span><br></pre></td></tr></table></figure>
<p>以下命令告知目标节点准备导出slot：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cluster setslot &lt;slot&gt; MIGRATING &lt;nodeId&gt;</span><br></pre></td></tr></table></figure>
<p>每个节点保存的集群状态中记录了迁移中的slot，其中，迁出的slot放到<code>migrating_slots_to</code>中，迁入的slot放到<code>importing_slots_from</code>：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">typedef struct clusterState &#123;</span><br><span class="line">    clusterNode *myself;  /* This node */</span><br><span class="line">    // 当前纪元</span><br><span class="line">    uint64_t currentEpoch;</span><br><span class="line">    // 集群的状态</span><br><span class="line">    int state;            /* CLUSTER_OK, CLUSTER_FAIL, ... */</span><br><span class="line">    // 集群中至少负责一个槽的主节点个数</span><br><span class="line">    int size;             /* Num of master nodes with at least one slot */</span><br><span class="line">    // 保存集群节点的字典，键是节点名字，值是clusterNode结构的指针</span><br><span class="line">    dict *nodes;          /* Hash table of name -&gt; clusterNode structures */</span><br><span class="line">    // 防止重复添加节点的黑名单</span><br><span class="line">    dict *nodes_black_list; /* Nodes we don&#x27;t re-add for a few seconds. */</span><br><span class="line">    // 导入槽数据到目标节点，该数组记录这些节点</span><br><span class="line">    clusterNode *migrating_slots_to[CLUSTER_SLOTS];</span><br><span class="line">    // 导出槽数据到目标节点，该数组记录这些节点</span><br><span class="line">    clusterNode *importing_slots_from[CLUSTER_SLOTS];</span><br><span class="line">    // 槽和负责槽节点的映射</span><br><span class="line">    clusterNode *slots[CLUSTER_SLOTS];</span><br><span class="line">    // 槽映射到键的有序集合</span><br><span class="line">    zskiplist *slots_to_keys;</span><br><span class="line">    </span><br><span class="line">&#125; clusterState;</span><br></pre></td></tr></table></figure>

<p>接下来，将待迁移slot中的key批量转移到目标节点：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 返回count个slot中的键</span><br><span class="line">cluster getkeysinslot &lt;slot&gt; &lt;count&gt;</span><br><span class="line"># 需要对上面命令返回的每个键都发送以下命令，该命令会将所指定的键原子地从源节点移动到目标节点</span><br><span class="line">migrate &lt;host&gt; &lt;port&gt; key destination-db timeout</span><br></pre></td></tr></table></figure>
<p>migrate命令就是向节点发送了N个RESTORE-ASKING命令，实现代码如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">/* Create RESTORE payload and generate the protocol to call the command. */</span><br><span class="line">for (j = 0; j &lt; num_keys; j++) &#123;</span><br><span class="line">    long long ttl = 0;</span><br><span class="line">    long long expireat = getExpire(c-&gt;db,kv[j]);</span><br><span class="line">    //检查键是不是已经过期</span><br><span class="line">    if (expireat != -1) &#123;</span><br><span class="line">        ttl = expireat-mstime();</span><br><span class="line">        if (ttl &lt; 0) &#123;</span><br><span class="line">            continue;</span><br><span class="line">        &#125;</span><br><span class="line">        if (ttl &lt; 1) ttl = 1;</span><br><span class="line">    &#125;</span><br><span class="line">    kv[non_expired++] = kv[j];</span><br><span class="line"></span><br><span class="line">    // 集群模式下写入RESTORE-ASKING命令，普通模式下写入RESTORE命令</span><br><span class="line">    if (server.cluster_enabled)</span><br><span class="line">        serverAssertWithInfo(c,NULL,</span><br><span class="line">            rioWriteBulkString(&amp;cmd,&quot;RESTORE-ASKING&quot;,14));</span><br><span class="line">    else</span><br><span class="line">        serverAssertWithInfo(c,NULL,rioWriteBulkString(&amp;cmd,&quot;RESTORE&quot;,7));</span><br><span class="line">    // 写入KEY，写入TTL</span><br><span class="line">    serverAssertWithInfo(c,NULL,sdsEncodedObject(kv[j]));</span><br><span class="line">    serverAssertWithInfo(c,NULL,rioWriteBulkString(&amp;cmd,kv[j]-&gt;ptr,</span><br><span class="line">            sdslen(kv[j]-&gt;ptr)));</span><br><span class="line">    serverAssertWithInfo(c,NULL,rioWriteBulkLongLong(&amp;cmd,ttl));</span><br><span class="line">    // 写入VALUE以及Redis版本校验码等信息</span><br><span class="line">    createDumpPayload(&amp;payload,ov[j],kv[j]);</span><br><span class="line">    serverAssertWithInfo(c,NULL,</span><br><span class="line">        rioWriteBulkString(&amp;cmd,payload.io.buffer.ptr,</span><br><span class="line">                           sdslen(payload.io.buffer.ptr)));</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>迁入节点接收到restore-asking命令后，执行节点的恢复操作，即获取key，解析出value，然后写入数据库：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">/* RESTORE key ttl serialized-value [REPLACE] */</span><br><span class="line">// 根据给定的 DUMP 数据，还原出一个键值对数据，并将它保存到数据库里面</span><br><span class="line">void restoreCommand(redisClient *c) &#123;</span><br><span class="line">    long long ttl;</span><br><span class="line">    rio payload;</span><br><span class="line">    int j, type, replace = 0;</span><br><span class="line">    robj *obj;</span><br><span class="line"></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">    // 读取 DUMP 数据，并反序列化出键值对的类型和值</span><br><span class="line">    rioInitWithBuffer(&amp;payload,c-&gt;argv[3]-&gt;ptr);</span><br><span class="line">    if (((type = rdbLoadObjectType(&amp;payload)) == -1) ||</span><br><span class="line">        ((obj = rdbLoadObject(type,&amp;payload)) == NULL))</span><br><span class="line">    &#123;</span><br><span class="line">        addReplyError(c,&quot;Bad data format&quot;);</span><br><span class="line">        return;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    /* Remove the old key if needed. */</span><br><span class="line">    // 如果给定了 REPLACE 选项，那么先删除数据库中已存在的同名键</span><br><span class="line">    if (replace) dbDelete(c-&gt;db,c-&gt;argv[1]);</span><br><span class="line"></span><br><span class="line">    /* Create the key and set the TTL if any */</span><br><span class="line">    // 将键值对添加到数据库</span><br><span class="line">    dbAdd(c-&gt;db,c-&gt;argv[1],obj);</span><br><span class="line"></span><br><span class="line">    // 如果键带有 TTL 的话，设置键的 TTL</span><br><span class="line">    if (ttl) setExpire(c-&gt;db,c-&gt;argv[1],mstime()+ttl);</span><br><span class="line"></span><br><span class="line">    signalModifiedKey(c-&gt;db,c-&gt;argv[1]);</span><br><span class="line"></span><br><span class="line">    addReply(c,shared.ok);</span><br><span class="line">    server.dirty++;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>迁移过程中，在外部客户端的视角看来，在任意时间点上，key只会存在于某个节点上，而不会同时存在于两个节点上。</p>
<p>现在，待迁移槽中的key都已经被迁移了，但是对其他节点来说，该slot仍是由迁出节点负责的，它们接收到相关请求后仍然会路由到迁出节点，所以迁移的最后一步需要向集群中的所有主节点通知槽已经被分配给目标节点。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cluster setslot &lt;slot&gt; node &lt;nodeId&gt;</span><br></pre></td></tr></table></figure>

<h4 id="迁移过程中对新请求的响应"><a href="#迁移过程中对新请求的响应" class="headerlink" title="迁移过程中对新请求的响应"></a>迁移过程中对新请求的响应</h4><p>迁移过程中：</p>
<ul>
<li>如果迁出节点接收请求，迁出节点判断slot或key是否已迁出，若是则<strong>ASK重定向</strong>到迁入节点上，否则迁出节点自己负责处理请求；</li>
<li>如果迁入节点接收请求，会把请求重定向到迁出节点上，除非请求中包含<strong>ASKING</strong>命令；</li>
<li>其他节点接收到的相关请求会被重定向到迁出节点上；<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line">int processCommand(redisClient *c) &#123;</span><br><span class="line">    </span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">    /* If cluster is enabled perform the cluster redirection here.</span><br><span class="line">     *</span><br><span class="line">     * 如果开启了集群模式，那么在这里进行转向操作。</span><br><span class="line">     *</span><br><span class="line">     * However we don&#x27;t perform the redirection if:</span><br><span class="line">     *</span><br><span class="line">     * 不过，如果有以下情况出现，那么节点不进行转向：</span><br><span class="line">     *</span><br><span class="line">     * 1) The sender of this command is our master.</span><br><span class="line">     *    命令的发送者是本节点的主节点</span><br><span class="line">     *</span><br><span class="line">     * 2) The command has no key arguments. </span><br><span class="line">     *    命令没有 key 参数</span><br><span class="line">     */</span><br><span class="line">    if (server.cluster_enabled &amp;&amp;</span><br><span class="line">        !(c-&gt;flags &amp; REDIS_MASTER) &amp;&amp;</span><br><span class="line">        !(c-&gt;cmd-&gt;getkeys_proc == NULL &amp;&amp; c-&gt;cmd-&gt;firstkey == 0))</span><br><span class="line">    &#123;</span><br><span class="line">        int hashslot;</span><br><span class="line"></span><br><span class="line">        // 集群已下线</span><br><span class="line">        if (server.cluster-&gt;state != REDIS_CLUSTER_OK) &#123;</span><br><span class="line">            flagTransaction(c);</span><br><span class="line">            addReplySds(c,sdsnew(&quot;-CLUSTERDOWN The cluster is down. Use CLUSTER INFO for more information\r\n&quot;));</span><br><span class="line">            return REDIS_OK;</span><br><span class="line"></span><br><span class="line">        // 集群运作正常</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            int error_code;</span><br><span class="line">            clusterNode *n = getNodeByQuery(c,c-&gt;cmd,c-&gt;argv,c-&gt;argc,&amp;hashslot,&amp;error_code);</span><br><span class="line">            // 不能执行多键处理命令</span><br><span class="line">            if (n == NULL) &#123;</span><br><span class="line">                flagTransaction(c);</span><br><span class="line">                if (error_code == REDIS_CLUSTER_REDIR_CROSS_SLOT) &#123;</span><br><span class="line">                    addReplySds(c,sdsnew(&quot;-CROSSSLOT Keys in request don&#x27;t hash to the same slot\r\n&quot;));</span><br><span class="line">                &#125; else if (error_code == REDIS_CLUSTER_REDIR_UNSTABLE) &#123;</span><br><span class="line">                    /* The request spawns mutliple keys in the same slot,</span><br><span class="line">                     * but the slot is not &quot;stable&quot; currently as there is</span><br><span class="line">                     * a migration or import in progress. */</span><br><span class="line">                    addReplySds(c,sdsnew(&quot;-TRYAGAIN Multiple keys request during rehashing of slot\r\n&quot;));</span><br><span class="line">                &#125; else &#123;</span><br><span class="line">                    redisPanic(&quot;getNodeByQuery() unknown error.&quot;);</span><br><span class="line">                &#125;</span><br><span class="line">                return REDIS_OK;</span><br><span class="line"></span><br><span class="line">            // 命令针对的槽和键不是本节点处理的，进行转向</span><br><span class="line">            &#125; else if (n != server.cluster-&gt;myself) &#123;</span><br><span class="line">                flagTransaction(c);</span><br><span class="line">                // -&lt;ASK or MOVED&gt; &lt;slot&gt; &lt;ip&gt;:&lt;port&gt;</span><br><span class="line">                // 例如 -ASK 10086 127.0.0.1:12345</span><br><span class="line">                addReplySds(c,sdscatprintf(sdsempty(),</span><br><span class="line">                    &quot;-%s %d %s:%d\r\n&quot;,</span><br><span class="line">                    (error_code == REDIS_CLUSTER_REDIR_ASK) ? &quot;ASK&quot; : &quot;MOVED&quot;,</span><br><span class="line">                    hashslot,n-&gt;ip,n-&gt;port));</span><br><span class="line"></span><br><span class="line">                return REDIS_OK;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            // 如果执行到这里，说明键 key 所在的槽由本节点处理</span><br><span class="line">            // 或者客户端执行的是无参数命令</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
注意上边的<code>getNodeByQuery</code>根据key的散列结果查询命令应该被打到的节点，可以看到这个函数里有对ASKING标识的特殊处理：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">clusterNode *getNodeByQuery(redisClient *c, struct redisCommand *cmd, robj **argv, int argc, int *hashslot, int *error_code) &#123;</span><br><span class="line"></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">    /* If we are receiving the slot, and the client correctly flagged the</span><br><span class="line">     * request as &quot;ASKING&quot;, we can serve the request. However if the request</span><br><span class="line">     * involves multiple keys and we don&#x27;t have them all, the only option is</span><br><span class="line">     * to send a TRYAGAIN error. */</span><br><span class="line">    if (importing_slot &amp;&amp;</span><br><span class="line">        (c-&gt;flags &amp; REDIS_ASKING || cmd-&gt;flags &amp; REDIS_CMD_ASKING))</span><br><span class="line">    &#123;</span><br><span class="line">        if (multiple_keys &amp;&amp; missing_keys) &#123;</span><br><span class="line">            if (error_code) *error_code = REDIS_CLUSTER_REDIR_UNSTABLE;</span><br><span class="line">            return NULL;</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            return myself;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="旧节点退出流程"><a href="#旧节点退出流程" class="headerlink" title="旧节点退出流程"></a>旧节点退出流程</h3><p>与新节点的加入相反的是，旧节点退出时需要把其上的数据迁移到其他节点上，确保该节点上的数据能够被正常访问。<br>槽的迁移过程和上边扩容中描述的没有区别，主要区别是在迁移完毕后需要轮询每个节点发送<code>cluster forget</code>命令，让它们能忘记下线的节点。<br>节点在接收<code>cluster forget</code>命令后，会将目标节点的状态从自己保存的集群状态中移除，并将其加入黑名单中60s，这期间其他节点不会再去更新自己维护的该节点的信息，也就是说这60秒内该节点无法重新加入集群内。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">def delnode_cluster_cmd(downNode):</span><br><span class="line">    # 下线节点不允许包含slots</span><br><span class="line">    if downNode.slots.length != 0</span><br><span class="line">        exit 1</span><br><span class="line">    end</span><br><span class="line">    # 向集群内节点发送cluster forget</span><br><span class="line">    for n in nodes:</span><br><span class="line">        if n.id == downNode.id:</span><br><span class="line">            # 不能对自己做forget操作</span><br><span class="line">            continue;</span><br><span class="line">        # 如果下线节点有从节点则把从节点指向其他主节点</span><br><span class="line">        if n.replicate &amp;&amp; n.replicate.nodeId == downNode.id :</span><br><span class="line">            # 指向拥有最少从节点的主节点</span><br><span class="line">            master = get_master_with_least_replicas();</span><br><span class="line">            n.cluster(&quot;replicate&quot;,master.nodeId);</span><br><span class="line">        #发送忘记节点命令</span><br><span class="line">        n.cluster(&#x27;forget&#x27;,downNode.id)</span><br><span class="line">    # 节点关闭</span><br><span class="line">    downNode.shutdown();</span><br></pre></td></tr></table></figure>

<h3 id="集群规模估算"><a href="#集群规模估算" class="headerlink" title="集群规模估算"></a>集群规模估算</h3><p>集群规模并不是没有限制的，理论上每个节点一个slot集群可以扩容到16384个节点，但是Redis官方给出的规模上限是一个集群1000个节点，因为<strong>实例间的通信开销会随着实例规模增加而增大</strong>。<br>下面来讨论下集群内部有哪些交互，并分析它们会对性能有什么样的影响。</p>
<h4 id="实例间数据的同步"><a href="#实例间数据的同步" class="headerlink" title="实例间数据的同步"></a>实例间数据的同步</h4><p>集群每个节点都会记录slot和实例间的映射关系，用于请求的重定向。<br>每个实例都需要通过Gossip协议将数据同步到其他节点，大致流程为：</p>
<ol>
<li>每个实例之间会按照<strong>一定的频率</strong>，从集群中<strong>随机挑选一些实例</strong>，把 PING 消息发送给挑选出来的实例，用来检测这些实例是否在线，并交换彼此的状态信息。PING 消息中封装了发送消息的实例自身的状态信息、部分其它实例的状态信息，以及 Slot 映射表。<br>发送的<strong>节点状态信息</strong>在源码中由<code>clusterMsgDataGossip</code>这个结构来表示，大小为104字节。每个实例在发送Gossip消息时，除了传递自身的状态信息，默认还会传递集群十分之一实例的状态信息，比如，对于一个包含了 1000 个实例的集群来说，每个实例发送一个 PING 消息时，会包含 100 个实例的状态信息，总的数据量是 10400 字节，再加上发送实例自身的信息，一个 Gossip 消息大约是 10KB。<br>另外，Slot映射表是一个16384位的bitmap，算上上面的10KB就是12KB的内容。</li>
<li>一个实例在接收到 PING 消息后，会给发送 PING 消息的实例，发送一个 PONG 消息。PONG 消息包含的内容和 PING 消息一样，也是12KB。</li>
<li>另外，上面是随机选节点发PING请求的，如果部分节点一直没有被选到，就会导致这些节点和其他节点不同步。<br>为了避免这种情况，Redis Cluster 的实例会按照每 100ms 一次的频率，扫描本地的实例列表，如果发现有实例最近一次接收 PONG 消息的时间，已经大于配置项 cluster-node-timeout 的一半了（cluster-node-timeout&#x2F;2），就会立刻给该实例发送 PING 消息，更新这个实例上的集群状态信息。<br>当集群规模扩大之后，因为网络拥塞或是不同服务器间的流量竞争，会导致实例间的网络通信延迟增加。如果有部分实例无法收到其它实例发送的 PONG 消息，就会引起实例之间频繁地发送 PING 消息，这又会对集群网络通信带来额外的开销了。</li>
</ol>
<p>从上可知，实例间的数据同步受到<strong>通信消息大小</strong>和<strong>通信频率</strong>这两方面的影响。<br>当集群规模扩大后，PING&#x2F;PONG会占用大量的集群内网络带宽，降低集群服务正常请求的吞吐量。<br>单实例<strong>每秒</strong>会发送的PING消息数量大致可以算出是（注意cron是100ms执行一次）：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PING 消息发送数量 = 1 + 10 * 实例数（最近一次接收 PONG 消息的时间超出 cluster-node-timeout/2）</span><br></pre></td></tr></table></figure>
<p>其中，1 是指单实例常规按照每 1 秒发送一个 PING 消息，10 是指每 1 秒内实例会执行 10 次检查，每次检查后会给 PONG 消息超时的实例发送消息。<br>假设单个实例检测发现，每 100 毫秒有 10 个实例的 PONG 消息接收超时，那么，这个实例每秒就会发送 101 个 PING 消息，约占 1.2MB&#x2F;s 带宽。如果集群中有 30 个实例按照这种频率发送消息，就会占用 36MB&#x2F;s 带宽，这就会挤占集群中用于服务正常请求的带宽。</p>
<p>因此实例间的通信开销优化主要是：</p>
<ol>
<li>减少实例传输的消息大小（PING&#x2F;PONG 消息、Slot 分配信息）<br>但是，因为集群实例依赖 PING、PONG 消息和 Slot 分配信息，来维持集群状态的统一，一旦减小了传递的消息大小，就会导致实例间的通信信息减少，不利于集群维护，所以，我们不能采用这种方式。</li>
<li>降低实例间发送消息的频率<br>从上面<code>PING消息发送数量</code>公式可以看出，每秒发送一条PING消息的频率不算高，如果要降低可能导致集群内数据同步延迟；每100ms做一次检测并给延迟超过<code>cluster-node-timeout/2</code>的节点发送PING消息，这个配置是可以适当调大的。<ul>
<li>如果配置得比较小，则在大规模集群中会频繁出现PONG超时的情况；</li>
<li>如果配置得过大，则如果真得发生了故障，我们反而需要等比较长的时间才能检测出来。<br>可以在调整前后使用tcpdump抓取实例发送心跳网络包的情况。<br><code>tcpdump host 192.168.10.3 port 16379 -i 网卡名 -w /tmp/r1.cap</code></li>
</ul>
</li>
</ol>
<h2 id="故障恢复（容错）"><a href="#故障恢复（容错）" class="headerlink" title="故障恢复（容错）"></a>故障恢复（容错）</h2><p>Redis故障恢复主要分为以下3个步骤：</p>
<ol>
<li>故障发现<br>采用多数派协议完成故障检测判断（即至少有半数以上节点认为某主节点故障后才真正判断节点故障）。</li>
<li>子节点选举<br>Redis Cluster中每个Master都会有1至多个Slave，通过复制实现高可用（故障转移），当Master有多个Slave，会采用Raft实现选举出一个主节点以实现故障恢复。</li>
<li>配置更新<br>故障转移后，那么之前的Master和其他Slave怎么处理？Redis会将这些节点成为新Master节点的子节点。</li>
</ol>
<h3 id="故障发现"><a href="#故障发现" class="headerlink" title="故障发现"></a>故障发现</h3><p>一些 CP 特性且中心化的集群来说，当出现节点宕机时经常需要选举新的 Leader 节点，但是 Redis-Cluster 是<strong>去中心化</strong>的，某个 Master 的宕机并不会影响其他节点的工作。但是，当节点失联时，需要考虑网络的抖动情况，毕竟不能因为某几个请求意外超时就推断集群失败了，部分节点判断一个节点失联只会标记这个节点状态为<strong>PFAIL（主观下线）</strong>，之后如果多数节点<strong>投票</strong>通过才会真正标记这个节点<strong>FAIL（下线）</strong>。<br>投票过程是集群中所有 master 参与的，每个节点都存有整个集群所有主节点及从节点的信息，它们之间通过互相 ping-pong 来判断节点是否可以连上，如果半数以上 master 节点与当前 master 节点通信超时（cluster-node-timeout），则认为当前 master 节点挂掉，标记这个节点状态为<strong>FAIL</strong>。</p>
<p>当 master 挂掉时，并不意味着集群已无法再提供服务了，集群要进入<code>fail（不可用）</code>状态需要满足以下条件之一：</p>
<ol>
<li>集群的任意 master 挂掉，且该 master 没有 slave 或 slave 全挂掉了，则集群进入 fail 状态。<br>这是因为，Cluster中所有slot是平均分配到每个Master的，如果有一个Master的slot不能用了、而且这个Master还没有Slave，那么集群就不能提供服务了，如果Master还有Slave，Slave可以代替Master继续向外提供服务，这个步骤称为<strong>slave promotion</strong>。<br>单独的一对Master-Slave挂掉，Redis还提供一个叫 <strong>Replica Migration</strong> 的解决方案：当集群中的某个Master节点没有Slave节点时（称之为 Orphaned Master），其他有富余Slave节点的主节点会向该节点迁移一个Slave节点以防该节点下线之后没有子节点来替换从而导致整个集群下线。</li>
<li>集群超过半数以上 master 挂掉，无论有无 slave 都进入 fail 状态。</li>
</ol>
<p>当集群不可用时，任何操作都将返回<code>((error) CLUSTERDOWN The cluster is down)</code>错误。需要注意的是，必须要 3 个或以上的主节点，否则在创建集群时会失败。</p>
<h4 id="PFAIL"><a href="#PFAIL" class="headerlink" title="PFAIL"></a>PFAIL</h4><p>1、Redis每个节点会不断向其他节点发送<code>PING</code>消息来检测其他节点是否可达，如果超时会先断开连接：<br>代码：<code>cluster.c/clusterCron</code><br><img src="/imgs/Redis/RedisCluster%E6%95%85%E9%9A%9C%E5%8F%91%E7%8E%B01.png" alt="RedisCluster故障发现1" title="RedisCluster故障发现1"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">/* This is executed 10 times every second */</span><br><span class="line">// 集群常规操作函数，默认每秒执行 10 次（每间隔 100 毫秒执行一次）</span><br><span class="line">void clusterCron(void) &#123;</span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">    while((de = dictNext(di)) != NULL) &#123;</span><br><span class="line">        clusterNode *node = dictGetVal(de);</span><br><span class="line">        now = mstime(); /* Use an updated time at every iteration. */</span><br><span class="line">        mstime_t delay;</span><br><span class="line"></span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line">        /* If we are waiting for the PONG more than half the cluster</span><br><span class="line">         * timeout, reconnect the link: maybe there is a connection</span><br><span class="line">         * issue even if the node is alive. */</span><br><span class="line">        // 判断连接的节点是否出事</span><br><span class="line">        if (node-&gt;link &amp;&amp; /* is connected */</span><br><span class="line">            now - node-&gt;link-&gt;ctime &gt;</span><br><span class="line">            server.cluster_node_timeout &amp;&amp; /* was not already reconnected */</span><br><span class="line">            // ping_sent记录发送命令的时间</span><br><span class="line">            node-&gt;ping_sent &amp;&amp; /* we already sent a ping */</span><br><span class="line">            node-&gt;pong_received &lt; node-&gt;ping_sent &amp;&amp; /* still waiting pong */</span><br><span class="line">            /* and we are waiting for the pong more than timeout/2 */</span><br><span class="line">            // PONG 到达的时间超过了 node_timeout 的一半</span><br><span class="line">            now - node-&gt;ping_sent &gt; server.cluster_node_timeout/2)</span><br><span class="line">        &#123;</span><br><span class="line">            /* Disconnect the link, it will be reconnected automatically. */</span><br><span class="line">            // 释放连接，此时node-&gt;link=NULL，下次 clusterCron() 会自动重连</span><br><span class="line">            freeClusterLink(node-&gt;link);</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        ...</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>2、此时节点A PING目标节点B失败，A会尝试重连，并将重连时间记录到ping_sent变量中：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line">/* This is executed 10 times every second */</span><br><span class="line">// 集群常规操作函数，默认每秒执行 10 次（每间隔 100 毫秒执行一次）</span><br><span class="line">void clusterCron(void) &#123;</span><br><span class="line"></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">    /* Check if we have disconnected nodes and re-establish the connection. */</span><br><span class="line">    // 向集群中的所有断线或者未连接节点发送消息</span><br><span class="line">    di = dictGetSafeIterator(server.cluster-&gt;nodes);</span><br><span class="line">    while((de = dictNext(di)) != NULL) &#123;</span><br><span class="line">        clusterNode *node = dictGetVal(de);</span><br><span class="line"></span><br><span class="line">        // 跳过当前节点以及没有地址的节点</span><br><span class="line">        if (node-&gt;flags &amp; (REDIS_NODE_MYSELF|REDIS_NODE_NOADDR)) continue;</span><br><span class="line"></span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line">        // 为未创建连接的节点创建连接</span><br><span class="line">        if (node-&gt;link == NULL) &#123;</span><br><span class="line">            int fd;</span><br><span class="line">            mstime_t old_ping_sent;</span><br><span class="line">            clusterLink *link;</span><br><span class="line"></span><br><span class="line">            fd = anetTcpNonBlockBindConnect(server.neterr, node-&gt;ip,</span><br><span class="line">                node-&gt;port+REDIS_CLUSTER_PORT_INCR,</span><br><span class="line">                    server.bindaddr_count ? server.bindaddr[0] : NULL);</span><br><span class="line">            if (fd == -1) &#123;</span><br><span class="line">                redisLog(REDIS_DEBUG, &quot;Unable to connect to &quot;</span><br><span class="line">                    &quot;Cluster Node [%s]:%d -&gt; %s&quot;, node-&gt;ip,</span><br><span class="line">                    node-&gt;port+REDIS_CLUSTER_PORT_INCR,</span><br><span class="line">                    server.neterr);</span><br><span class="line">                continue;</span><br><span class="line">            &#125;</span><br><span class="line">            link = createClusterLink(node);</span><br><span class="line">            link-&gt;fd = fd;</span><br><span class="line">            node-&gt;link = link;</span><br><span class="line">            aeCreateFileEvent(server.el,link-&gt;fd,AE_READABLE,</span><br><span class="line">                    clusterReadHandler,link);</span><br><span class="line">            /* Queue a PING in the new connection ASAP: this is crucial</span><br><span class="line">             * to avoid false positives in failure detection.</span><br><span class="line">             *</span><br><span class="line">             * If the node is flagged as MEET, we send a MEET message instead</span><br><span class="line">             * of a PING one, to force the receiver to add us in its node</span><br><span class="line">             * table. */</span><br><span class="line">            // 向新连接的节点发送 PING 命令，防止节点被识进入下线</span><br><span class="line">            // 如果节点被标记为 MEET ，那么发送 MEET 命令，否则发送 PING 命令</span><br><span class="line">            old_ping_sent = node-&gt;ping_sent;</span><br><span class="line">            clusterSendPing(link, node-&gt;flags &amp; REDIS_NODE_MEET ?</span><br><span class="line">                    CLUSTERMSG_TYPE_MEET : CLUSTERMSG_TYPE_PING);</span><br><span class="line"></span><br><span class="line">            // 这不是第一次发送 PING 信息，所以可以还原这个时间</span><br><span class="line">            // 等 clusterSendPing() 函数来更新它</span><br><span class="line">            if (old_ping_sent) &#123;</span><br><span class="line">                /* If there was an active ping before the link was</span><br><span class="line">                 * disconnected, we want to restore the ping time, otherwise</span><br><span class="line">                 * replaced by the clusterSendPing() call. */</span><br><span class="line">                node-&gt;ping_sent = old_ping_sent;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            /* We can clear the flag after the first packet is sent.</span><br><span class="line">             *</span><br><span class="line">             * 在发送 MEET 信息之后，清除节点的 MEET 标识。</span><br><span class="line">             *</span><br><span class="line">             * If we&#x27;ll never receive a PONG, we&#x27;ll never send new packets</span><br><span class="line">             * to this node. Instead after the PONG is received and we</span><br><span class="line">             * are no longer in meet/handshake status, we want to send</span><br><span class="line">             * normal PING packets. </span><br><span class="line">             *</span><br><span class="line">             * 如果当前节点（发送者）没能收到 MEET 信息的回复，</span><br><span class="line">             * 那么它将不再向目标节点发送命令。</span><br><span class="line">             *</span><br><span class="line">             * 如果接收到回复的话，那么节点将不再处于 HANDSHAKE 状态，</span><br><span class="line">             * 并继续向目标节点发送普通 PING 命令。</span><br><span class="line">             */</span><br><span class="line">            node-&gt;flags &amp;= ~REDIS_NODE_MEET;</span><br><span class="line"></span><br><span class="line">            redisLog(REDIS_DEBUG,&quot;Connecting with Node %.40s at %s:%d&quot;,</span><br><span class="line">                    node-&gt;name, node-&gt;ip, node-&gt;port+REDIS_CLUSTER_PORT_INCR);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    ...</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>3、节点A发现PING B的延时时间超过了node_timeout之后，就会标记该节点为PFAIL（Possible FAILure），即主观下线：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">void clusterCron(void) &#123;</span><br><span class="line">    </span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">    // 遍历所有节点，检查是否需要将某个节点标记为下线</span><br><span class="line">    /* Iterate nodes to check if we need to flag something as failing.</span><br><span class="line">     * This loop is also responsible to:</span><br><span class="line">     * 1) Check if there are orphaned masters (masters without non failing</span><br><span class="line">     *    slaves).</span><br><span class="line">     * 2) Count the max number of non failing slaves for a single master.</span><br><span class="line">     * 3) Count the number of slaves for our master, if we are a slave. */</span><br><span class="line">    orphaned_masters = 0;</span><br><span class="line">    max_slaves = 0;</span><br><span class="line">    this_slaves = 0;</span><br><span class="line">    di = dictGetSafeIterator(server.cluster-&gt;nodes);</span><br><span class="line">    while((de = dictNext(di)) != NULL) &#123;</span><br><span class="line">        </span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line">        /* Check only if we have an active ping for this instance. */</span><br><span class="line">        // 以下代码只在节点发送了 PING 命令的情况下执行</span><br><span class="line">        if (node-&gt;ping_sent == 0) continue;</span><br><span class="line"></span><br><span class="line">        /* Compute the delay of the PONG. Note that if we already received</span><br><span class="line">         * the PONG, then node-&gt;ping_sent is zero, so can&#x27;t reach this</span><br><span class="line">         * code at all. */</span><br><span class="line">        // 计算等待 PONG 回复的时长</span><br><span class="line">        delay = now - node-&gt;ping_sent;</span><br><span class="line"></span><br><span class="line">        // 等待 PONG 回复的时长超过了限制值，将目标节点标记为 PFAIL （疑似下线）</span><br><span class="line">        if (delay &gt; server.cluster_node_timeout) &#123;</span><br><span class="line">            /* Timeout reached. Set the node as possibly failing if it is</span><br><span class="line">             * not already in this state. */</span><br><span class="line">            if (!(node-&gt;flags &amp; (REDIS_NODE_PFAIL|REDIS_NODE_FAIL))) &#123;</span><br><span class="line">                redisLog(REDIS_DEBUG,&quot;*** NODE %.40s possibly failing&quot;,</span><br><span class="line">                    node-&gt;name);</span><br><span class="line">                // 打开疑似下线标记</span><br><span class="line">                node-&gt;flags |= REDIS_NODE_PFAIL;</span><br><span class="line">                update_state = 1;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="FAIL"><a href="#FAIL" class="headerlink" title="FAIL"></a>FAIL</h4><p><img src="/imgs/Redis/RedisCluster%E6%95%85%E9%9A%9C%E5%8F%91%E7%8E%B02.png" alt="RedisCluster故障发现2" title="RedisCluster故障发现2"><br>1、A将B标记为PFAIL后，A会通过<strong>Gossip</strong>通知到其他节点。</p>
<p>2、所有节点会维护一个下线报告列表（Fail Report），主要维护一个节点被哪些节点报告处于下线状态，此时，C会记录“B被A报告下线了”。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br></pre></td><td class="code"><pre><span class="line">int clusterProcessPacket(clusterLink *link) &#123;</span><br><span class="line"></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">    /* Process packets by type. */</span><br><span class="line">    // 根据消息的类型，处理节点</span><br><span class="line"></span><br><span class="line">    // 这是一条 PING 消息或者 MEET 消息</span><br><span class="line">    if (type == CLUSTERMSG_TYPE_PING || type == CLUSTERMSG_TYPE_MEET) &#123;</span><br><span class="line">        redisLog(REDIS_DEBUG,&quot;Ping packet received: %p&quot;, (void*)link-&gt;node);</span><br><span class="line"></span><br><span class="line">        /* Add this node if it is new for us and the msg type is MEET.</span><br><span class="line">         *</span><br><span class="line">         * 如果当前节点是第一次遇见这个节点，并且对方发来的是 MEET 信息，</span><br><span class="line">         * 那么将这个节点添加到集群的节点列表里面。</span><br><span class="line">         *</span><br><span class="line">         * In this stage we don&#x27;t try to add the node with the right</span><br><span class="line">         * flags, slaveof pointer, and so forth, as this details will be</span><br><span class="line">         * resolved when we&#x27;ll receive PONGs from the node. </span><br><span class="line">         *</span><br><span class="line">         * 节点目前的 flag 、 slaveof 等属性的值都是未设置的，</span><br><span class="line">         * 等当前节点向对方发送 PING 命令之后，</span><br><span class="line">         * 这些信息可以从对方回复的 PONG 信息中取得。</span><br><span class="line">         */</span><br><span class="line">        if (!sender &amp;&amp; type == CLUSTERMSG_TYPE_MEET) &#123;</span><br><span class="line">            clusterNode *node;</span><br><span class="line"></span><br><span class="line">            // 创建 HANDSHAKE 状态的新节点</span><br><span class="line">            node = createClusterNode(NULL,REDIS_NODE_HANDSHAKE);</span><br><span class="line"></span><br><span class="line">            // 设置 IP 和端口</span><br><span class="line">            nodeIp2String(node-&gt;ip,link);</span><br><span class="line">            node-&gt;port = ntohs(hdr-&gt;port);</span><br><span class="line"></span><br><span class="line">            // 将新节点添加到集群</span><br><span class="line">            clusterAddNode(node);</span><br><span class="line"></span><br><span class="line">            clusterDoBeforeSleep(CLUSTER_TODO_SAVE_CONFIG);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        /* Get info from the gossip section */</span><br><span class="line">        // 分析并取出消息中的 gossip 节点信息</span><br><span class="line">        clusterProcessGossipSection(hdr,link);</span><br><span class="line"></span><br><span class="line">        /* Anyway reply with a PONG */</span><br><span class="line">        // 向目标节点返回一个 PONG</span><br><span class="line">        clusterSendPing(link,CLUSTERMSG_TYPE_PONG);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void clusterProcessGossipSection(clusterMsg *hdr, clusterLink *link) &#123;</span><br><span class="line"></span><br><span class="line">    // 记录这条消息中包含了多少个节点的信息</span><br><span class="line">    uint16_t count = ntohs(hdr-&gt;count);</span><br><span class="line"></span><br><span class="line">    // 指向第一个节点的信息</span><br><span class="line">    clusterMsgDataGossip *g = (clusterMsgDataGossip*) hdr-&gt;data.ping.gossip;</span><br><span class="line"></span><br><span class="line">    // 取出发送者</span><br><span class="line">    clusterNode *sender = link-&gt;node ? link-&gt;node : clusterLookupNode(hdr-&gt;sender);</span><br><span class="line"></span><br><span class="line">    // 遍历所有节点的信息</span><br><span class="line">    while(count--) &#123;</span><br><span class="line">        sds ci = sdsempty();</span><br><span class="line"></span><br><span class="line">        // 分析节点的 flag</span><br><span class="line">        uint16_t flags = ntohs(g-&gt;flags);</span><br><span class="line"></span><br><span class="line">        // 信息节点</span><br><span class="line">        clusterNode *node;</span><br><span class="line"></span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line">        /* Update our state accordingly to the gossip sections */</span><br><span class="line">        // 使用消息中的信息对节点进行更新</span><br><span class="line">        node = clusterLookupNode(g-&gt;nodename);</span><br><span class="line">        // 节点已经存在于当前节点</span><br><span class="line">        if (node) &#123;</span><br><span class="line">            /* We already know this node.</span><br><span class="line">               Handle failure reports, only when the sender is a master. */</span><br><span class="line">            // 如果 sender 是一个主节点，那么我们需要处理下线报告</span><br><span class="line">            if (sender &amp;&amp; nodeIsMaster(sender) &amp;&amp; node != myself) &#123;</span><br><span class="line">                // 节点处于 FAIL 或者 PFAIL 状态</span><br><span class="line">                if (flags &amp; (REDIS_NODE_FAIL|REDIS_NODE_PFAIL)) &#123;</span><br><span class="line"></span><br><span class="line">                    // 添加 sender 对 node 的下线报告</span><br><span class="line">                    if (clusterNodeAddFailureReport(node,sender)) &#123;</span><br><span class="line">                        redisLog(REDIS_VERBOSE,</span><br><span class="line">                            &quot;Node %.40s reported node %.40s as not reachable.&quot;,</span><br><span class="line">                            sender-&gt;name, node-&gt;name);</span><br><span class="line">                    &#125;</span><br><span class="line"></span><br><span class="line">                    // 尝试将 node 标记为 FAIL</span><br><span class="line">                    markNodeAsFailingIfNeeded(node);</span><br><span class="line"></span><br><span class="line">                // 节点处于正常状态</span><br><span class="line">                &#125; else &#123;</span><br><span class="line"></span><br><span class="line">                    // 如果 sender 曾经发送过对 node 的下线报告</span><br><span class="line">                    // 那么清除该报告</span><br><span class="line">                    if (clusterNodeDelFailureReport(node,sender)) &#123;</span><br><span class="line">                        redisLog(REDIS_VERBOSE,</span><br><span class="line">                            &quot;Node %.40s reported node %.40s is back online.&quot;,</span><br><span class="line">                            sender-&gt;name, node-&gt;name);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            /* If we already know this node, but it is not reachable, and</span><br><span class="line">             * we see a different address in the gossip section, start an</span><br><span class="line">             * handshake with the (possibly) new address: this will result</span><br><span class="line">             * into a node address update if the handshake will be</span><br><span class="line">             * successful. */</span><br><span class="line">            // 如果节点之前处于 PFAIL 或者 FAIL 状态</span><br><span class="line">            // 并且该节点的 IP 或者端口号已经发生变化</span><br><span class="line">            // 那么可能是节点换了新地址，尝试对它进行握手</span><br><span class="line">            if (node-&gt;flags &amp; (REDIS_NODE_FAIL|REDIS_NODE_PFAIL) &amp;&amp;</span><br><span class="line">                (strcasecmp(node-&gt;ip,g-&gt;ip) || node-&gt;port != ntohs(g-&gt;port)))</span><br><span class="line">            &#123;</span><br><span class="line">                clusterStartHandshake(g-&gt;ip,ntohs(g-&gt;port));</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        // 当前节点不认识 node</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            /* If it&#x27;s not in NOADDR state and we don&#x27;t have it, we</span><br><span class="line">             * start a handshake process against this IP/PORT pairs.</span><br><span class="line">             *</span><br><span class="line">             * 如果 node 不在 NOADDR 状态，并且当前节点不认识 node </span><br><span class="line">             * 那么向 node 发送 HANDSHAKE 消息。</span><br><span class="line">             *</span><br><span class="line">             * Note that we require that the sender of this gossip message</span><br><span class="line">             * is a well known node in our cluster, otherwise we risk</span><br><span class="line">             * joining another cluster.</span><br><span class="line">             *</span><br><span class="line">             * 注意，当前节点必须保证 sender 是本集群的节点，</span><br><span class="line">             * 否则我们将有加入了另一个集群的风险。</span><br><span class="line">             */</span><br><span class="line">            if (sender &amp;&amp;</span><br><span class="line">                !(flags &amp; REDIS_NODE_NOADDR) &amp;&amp;</span><br><span class="line">                !clusterBlacklistExists(g-&gt;nodename))</span><br><span class="line">            &#123;</span><br><span class="line">                clusterStartHandshake(g-&gt;ip,ntohs(g-&gt;port));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        /* Next node */</span><br><span class="line">        // 处理下个节点的信息</span><br><span class="line">        g++;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>3、C添加下线报告之后，会进行B节点的客观下线状态（FAIL）判定。<br>当集群中有超过半数的节点都认为节点B处于PFAIL后才会判断B为FAIL，且需要注意的是，A将PFAIL通知给C后，C自己本身也得认为B处于PFAIL状态才会开始客观下线判定。<br>当C认为B正式FAIL后，它就会立刻向集群所有节点广播这个消息。<br><img src="/imgs/Redis/RedisCluster%E6%95%85%E9%9A%9C%E5%8F%91%E7%8E%B03.png" alt="RedisCluster故障发现3" title="RedisCluster故障发现3"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line">/* This function checks if a given node should be marked as FAIL.</span><br><span class="line"> * It happens if the following conditions are met:</span><br><span class="line"> *</span><br><span class="line"> * 此函数用于判断是否需要将 node 标记为 FAIL 。</span><br><span class="line"> *</span><br><span class="line"> * 将 node 标记为 FAIL 需要满足以下两个条件：</span><br><span class="line"> *</span><br><span class="line"> * 1) We received enough failure reports from other master nodes via gossip.</span><br><span class="line"> *    Enough means that the majority of the masters signaled the node is</span><br><span class="line"> *    down recently.</span><br><span class="line"> *    有半数以上的主节点将 node 标记为 PFAIL 状态。</span><br><span class="line"> * 2) We believe this node is in PFAIL state.</span><br><span class="line"> *    当前节点也将 node 标记为 PFAIL 状态。</span><br><span class="line"> *</span><br><span class="line"> * If a failure is detected we also inform the whole cluster about this</span><br><span class="line"> * event trying to force every other node to set the FAIL flag for the node.</span><br><span class="line"> *</span><br><span class="line"> * 如果确认 node 已经进入了 FAIL 状态，</span><br><span class="line"> * 那么节点还会向其他节点发送 FAIL 消息，让其他节点也将 node 标记为 FAIL 。</span><br><span class="line"> *</span><br><span class="line"> * Note that the form of agreement used here is weak, as we collect the majority</span><br><span class="line"> * of masters state during some time, and even if we force agreement by</span><br><span class="line"> * propagating the FAIL message, because of partitions we may not reach every</span><br><span class="line"> * node. However:</span><br><span class="line"> *</span><br><span class="line"> * 注意，集群判断一个 node 进入 FAIL 所需的条件是弱（weak）的，</span><br><span class="line"> * 因为节点们对 node 的状态报告并不是实时的，而是有一段时间间隔</span><br><span class="line"> * （这段时间内 node 的状态可能已经发生了改变），</span><br><span class="line"> * 并且尽管当前节点会向其他节点发送 FAIL 消息，</span><br><span class="line"> * 但因为网络分裂（network partition）的问题，</span><br><span class="line"> * 有一部分节点可能还是会不知道将 node 标记为 FAIL 。</span><br><span class="line"> *</span><br><span class="line"> * 不过：</span><br><span class="line"> *</span><br><span class="line"> * 1) Either we reach the majority and eventually the FAIL state will propagate</span><br><span class="line"> *    to all the cluster.</span><br><span class="line"> *    只要我们成功将 node 标记为 FAIL ，</span><br><span class="line"> *    那么这个 FAIL 状态最终（eventually）总会传播至整个集群的所有节点。</span><br><span class="line"> * 2) Or there is no majority so no slave promotion will be authorized and the</span><br><span class="line"> *    FAIL flag will be cleared after some time.</span><br><span class="line"> *    又或者，因为没有半数的节点支持，当前节点不能将 node 标记为 FAIL ，</span><br><span class="line"> *    所以对 FAIL 节点的故障转移将无法进行， FAIL 标识可能会在之后被移除。</span><br><span class="line"> *    </span><br><span class="line"> */</span><br><span class="line">void markNodeAsFailingIfNeeded(clusterNode *node) &#123;</span><br><span class="line">    int failures;</span><br><span class="line"></span><br><span class="line">    // 标记为 FAIL 所需的节点数量，需要超过集群节点数量的一半</span><br><span class="line">    int needed_quorum = (server.cluster-&gt;size / 2) + 1;</span><br><span class="line"></span><br><span class="line">    if (!nodeTimedOut(node)) return; /* We can reach it. */</span><br><span class="line">    if (nodeFailed(node)) return; /* Already FAILing. */</span><br><span class="line"></span><br><span class="line">    // 统计将 node 标记为 PFAIL 或者 FAIL 的节点数量（不包括当前节点）</span><br><span class="line">    failures = clusterNodeFailureReportsCount(node);</span><br><span class="line"></span><br><span class="line">    /* Also count myself as a voter if I&#x27;m a master. */</span><br><span class="line">    // 如果当前节点是主节点，那么将当前节点也算在 failures 之内</span><br><span class="line">    if (nodeIsMaster(myself)) failures++;</span><br><span class="line">    // 报告下线节点的数量不足节点总数的一半，不能将节点判断为 FAIL ，返回</span><br><span class="line">    if (failures &lt; needed_quorum) return; /* No weak agreement from masters. */</span><br><span class="line"></span><br><span class="line">    redisLog(REDIS_NOTICE,</span><br><span class="line">        &quot;Marking node %.40s as failing (quorum reached).&quot;, node-&gt;name);</span><br><span class="line"></span><br><span class="line">    /* Mark the node as failing. */</span><br><span class="line">    // 将 node 标记为 FAIL</span><br><span class="line">    node-&gt;flags &amp;= ~REDIS_NODE_PFAIL;</span><br><span class="line">    node-&gt;flags |= REDIS_NODE_FAIL;</span><br><span class="line">    node-&gt;fail_time = mstime();</span><br><span class="line"></span><br><span class="line">    /* Broadcast the failing node name to everybody, forcing all the other</span><br><span class="line">     * reachable nodes to flag the node as FAIL. */</span><br><span class="line">    // 如果当前节点是主节点的话，那么向其他节点发送报告 node 的 FAIL 信息</span><br><span class="line">    // 让其他节点也将 node 标记为 FAIL</span><br><span class="line">    if (nodeIsMaster(myself)) clusterSendFail(node-&gt;name);</span><br><span class="line">    clusterDoBeforeSleep(CLUSTER_TODO_UPDATE_STATE|CLUSTER_TODO_SAVE_CONFIG);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>4、当C标记了B为FAIL状态，则它会广播到整个集群中的所有节点（包括子节点），其他节点都会更新自己维护的节点B的状态信息为FAIL</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">/* Send a FAIL message to all the nodes we are able to contact.</span><br><span class="line"> *</span><br><span class="line"> * 向当前节点已知的所有节点发送 FAIL 信息。</span><br><span class="line"> */</span><br><span class="line">void clusterSendFail(char *nodename) &#123;</span><br><span class="line">    unsigned char buf[sizeof(clusterMsg)];</span><br><span class="line">    clusterMsg *hdr = (clusterMsg *) buf;</span><br><span class="line"></span><br><span class="line">    // 创建下线消息</span><br><span class="line">    clusterBuildMessageHdr(hdr, CLUSTERMSG_TYPE_FAIL);</span><br><span class="line"></span><br><span class="line">    // 记录命令</span><br><span class="line">    memcpy(hdr-&gt;data.fail.about.nodename, nodename, REDIS_CLUSTER_NAMELEN);</span><br><span class="line"></span><br><span class="line">    // 广播消息</span><br><span class="line">    clusterBroadcastMessage(buf, ntohl(hdr-&gt;totlen));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/* Send a message to all the nodes that are part of the cluster having</span><br><span class="line"> * a connected link.</span><br><span class="line"> *</span><br><span class="line"> * 向节点连接的所有其他节点发送信息。</span><br><span class="line"> */</span><br><span class="line">void clusterBroadcastMessage(void *buf, size_t len) &#123;</span><br><span class="line">    dictIterator *di;</span><br><span class="line">    dictEntry *de;</span><br><span class="line"></span><br><span class="line">    // 遍历所有已知节点</span><br><span class="line">    di = dictGetSafeIterator(server.cluster-&gt;nodes);</span><br><span class="line">    while ((de = dictNext(di)) != NULL) &#123;</span><br><span class="line">        clusterNode *node = dictGetVal(de);</span><br><span class="line"></span><br><span class="line">        // 不向未连接节点发送信息</span><br><span class="line">        if (!node-&gt;link) continue;</span><br><span class="line"></span><br><span class="line">        // 不向节点自身或者 HANDSHAKE 状态的节点发送信息</span><br><span class="line">        if (node-&gt;flags &amp; (REDIS_NODE_MYSELF | REDIS_NODE_HANDSHAKE))</span><br><span class="line">            continue;</span><br><span class="line"></span><br><span class="line">        // 发送信息</span><br><span class="line">        clusterSendMessage(node-&gt;link, buf, len);</span><br><span class="line">    &#125;</span><br><span class="line">    dictReleaseIterator(di);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="子节点选举（故障迁移）"><a href="#子节点选举（故障迁移）" class="headerlink" title="子节点选举（故障迁移）"></a>子节点选举（故障迁移）</h3><p>1、当B的两个子节点接收到B的FAIL状态消息时，它们会更新自己本地内存中的集群状态</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">int clusterProcessPacket(clusterLink *link) &#123;</span><br><span class="line"></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">    // 这是一条 FAIL 消息： sender 告知当前节点，某个节点已经进入 FAIL 状态。</span><br><span class="line">    else if (type == CLUSTERMSG_TYPE_FAIL) &#123;</span><br><span class="line">        clusterNode *failing;</span><br><span class="line"></span><br><span class="line">        if (sender) &#123;</span><br><span class="line"></span><br><span class="line">            // 获取下线节点的消息</span><br><span class="line">            failing = clusterLookupNode(hdr-&gt;data.fail.about.nodename);</span><br><span class="line">            // 下线的节点既不是当前节点，也没有处于 FAIL 状态</span><br><span class="line">            if (failing &amp;&amp;</span><br><span class="line">                !(failing-&gt;flags &amp; (REDIS_NODE_FAIL | REDIS_NODE_MYSELF))) &#123;</span><br><span class="line">                redisLog(REDIS_NOTICE,</span><br><span class="line">                         &quot;FAIL message received from %.40s about %.40s&quot;,</span><br><span class="line">                         hdr-&gt;sender, hdr-&gt;data.fail.about.nodename);</span><br><span class="line"></span><br><span class="line">                // 打开 FAIL 状态</span><br><span class="line">                failing-&gt;flags |= REDIS_NODE_FAIL;</span><br><span class="line">                failing-&gt;fail_time = mstime();</span><br><span class="line">                // 关闭 PFAIL 状态</span><br><span class="line">                failing-&gt;flags &amp;= ~REDIS_NODE_PFAIL;</span><br><span class="line">                clusterDoBeforeSleep(CLUSTER_TODO_SAVE_CONFIG |</span><br><span class="line">                                     CLUSTER_TODO_UPDATE_STATE);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            redisLog(REDIS_NOTICE,</span><br><span class="line">                     &quot;Ignoring FAIL message from unknonw node %.40s about %.40s&quot;,</span><br><span class="line">                     hdr-&gt;sender, hdr-&gt;data.fail.about.nodename);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>2、随后，在clusterCron定时任务中就会开始发起故障迁移，竞选成为新的Master</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line">void clusterCron(void) &#123;</span><br><span class="line"></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">    /* Abourt a manual failover if the timeout is reached. */</span><br><span class="line">    manualFailoverCheckTimeout();</span><br><span class="line"></span><br><span class="line">    // 如果当前节点是子节点</span><br><span class="line">    if (nodeIsSlave(myself)) &#123;</span><br><span class="line">        clusterHandleManualFailover();</span><br><span class="line">        // 处理集群子节点的故障迁移</span><br><span class="line">        clusterHandleSlaveFailover();</span><br><span class="line">        </span><br><span class="line">        /* If there are orphaned slaves, and we are a slave among the masters</span><br><span class="line">         * with the max number of non-failing slaves, consider migrating to</span><br><span class="line">         * the orphaned masters. Note that it does not make sense to try</span><br><span class="line">         * a migration if there is no master with at least *two* working</span><br><span class="line">         * slaves. */</span><br><span class="line">        if (orphaned_masters &amp;&amp; max_slaves &gt;= 2 &amp;&amp; this_slaves == max_slaves)</span><br><span class="line">            clusterHandleSlaveMigration(max_slaves);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // 更新集群状态</span><br><span class="line">    if (update_state || server.cluster-&gt;state == REDIS_CLUSTER_FAIL)</span><br><span class="line">        clusterUpdateState();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/* This function is called if we are a slave node and our master serving</span><br><span class="line"> * a non-zero amount of hash slots is in FAIL state.</span><br><span class="line"> *</span><br><span class="line"> * 如果当前节点是一个从节点，并且它正在复制的一个负责非零个槽的主节点处于 FAIL 状态，</span><br><span class="line"> * 那么执行这个函数。</span><br><span class="line"> *</span><br><span class="line"> * The gaol of this function is:</span><br><span class="line"> *</span><br><span class="line"> * 这个函数有三个目标：</span><br><span class="line"> *</span><br><span class="line"> * 1) To check if we are able to perform a failover, is our data updated?</span><br><span class="line"> *    检查是否可以对主节点执行一次故障转移，节点的关于主节点的信息是否准确和最新（updated）？</span><br><span class="line"> * 2) Try to get elected by masters.</span><br><span class="line"> *    选举一个新的主节点</span><br><span class="line"> * 3) Perform the failover informing all the other nodes.</span><br><span class="line"> *    执行故障转移，并通知其他节点</span><br><span class="line"> */</span><br><span class="line">void clusterHandleSlaveFailover(void) &#123;</span><br><span class="line">    mstime_t data_age;</span><br><span class="line">    mstime_t auth_age = mstime() - server.cluster-&gt;failover_auth_time;</span><br><span class="line">    int needed_quorum = (server.cluster-&gt;size / 2) + 1;</span><br><span class="line">    int manual_failover = server.cluster-&gt;mf_end != 0 &amp;&amp;</span><br><span class="line">                          server.cluster-&gt;mf_can_start;</span><br><span class="line">    int j;</span><br><span class="line">    mstime_t auth_timeout, auth_retry_time;</span><br><span class="line"></span><br><span class="line">    server.cluster-&gt;todo_before_sleep &amp;= ~CLUSTER_TODO_HANDLE_FAILOVER;</span><br><span class="line"></span><br><span class="line">    /* Compute the failover timeout (the max time we have to send votes</span><br><span class="line">     * and wait for replies), and the failover retry time (the time to wait</span><br><span class="line">     * before waiting again.</span><br><span class="line">     *</span><br><span class="line">     * Timeout is MIN(NODE_TIMEOUT*2,2000) milliseconds.</span><br><span class="line">     * Retry is two times the Timeout.</span><br><span class="line">     */</span><br><span class="line">    auth_timeout = server.cluster_node_timeout * 2;</span><br><span class="line">    if (auth_timeout &lt; 2000) auth_timeout = 2000;</span><br><span class="line">    auth_retry_time = auth_timeout * 2;</span><br><span class="line"></span><br><span class="line">    /* Pre conditions to run the function, that must be met both in case</span><br><span class="line">     * of an automatic or manual failover:</span><br><span class="line">     * 1) We are a slave.</span><br><span class="line">     * 2) Our master is flagged as FAIL, or this is a manual failover.</span><br><span class="line">     * 3) It is serving slots. */</span><br><span class="line">    if (nodeIsMaster(myself) ||</span><br><span class="line">        myself-&gt;slaveof == NULL ||</span><br><span class="line">        (!nodeFailed(myself-&gt;slaveof) &amp;&amp; !manual_failover) ||</span><br><span class="line">        myself-&gt;slaveof-&gt;numslots == 0)</span><br><span class="line">        return;</span><br><span class="line">        </span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>3、资格检查<br>Slave节点会不停的与Master节点通信来复制Master节点的数据，如果一个Slave节点长时间不与Master节点通信，那么很可能意味着该Slave节点上的数据已经落后Master节点过多（因为Master节点再不停的更新数据但是Slave节点并没有随之更新）。Redis认为，当一个Slave节点过长时间不与Master节点通信，那么该节点就不具备参与竞选的资格。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">void clusterHandleSlaveFailover(void) &#123;</span><br><span class="line">    </span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">    /* Set data_age to the number of seconds we are disconnected from</span><br><span class="line">     * the master. */</span><br><span class="line">    // 将 data_age 设置为从节点与主节点的断开秒数</span><br><span class="line">    if (server.repl_state == REDIS_REPL_CONNECTED) &#123;</span><br><span class="line">        data_age = (mstime_t) (server.unixtime - server.master-&gt;lastinteraction)</span><br><span class="line">                   * 1000;</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        data_age = (mstime_t) (server.unixtime - server.repl_down_since) * 1000;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    /* Remove the node timeout from the data age as it is fine that we are</span><br><span class="line">     * disconnected from our master at least for the time it was down to be</span><br><span class="line">     * flagged as FAIL, that&#x27;s the baseline. */</span><br><span class="line">    // node timeout 的时间不计入断线时间之内</span><br><span class="line">    if (data_age &gt; server.cluster_node_timeout)</span><br><span class="line">        data_age -= server.cluster_node_timeout;</span><br><span class="line"></span><br><span class="line">    /* Check if our data is recent enough. For now we just use a fixed</span><br><span class="line">     * constant of ten times the node timeout since the cluster should</span><br><span class="line">     * react much faster to a master down.</span><br><span class="line">     *</span><br><span class="line">     * Check bypassed for manual failovers. */</span><br><span class="line">    // 检查这个从节点的数据是否较新：</span><br><span class="line">    // 目前的检测办法是断线时间不能超过 node timeout 的十倍</span><br><span class="line">    if (data_age &gt;</span><br><span class="line">        ((mstime_t)server.repl_ping_slave_period * 1000) +</span><br><span class="line">        (server.cluster_node_timeout * REDIS_CLUSTER_SLAVE_VALIDITY_MULT))</span><br><span class="line">    &#123;</span><br><span class="line">        if (!manual_failover) return;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    ...</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>4、休眠时间计算<br>B的所有子节点（B1、B2）在判断自己具备选举资格时，就开始执行竞选，竞选协议是Raft，选举过程中，所有参与选举的节点首先随机休眠一段时间。<br>整个休眠时间由两个部分组成：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DELAY = 500 milliseconds + random delay between 0 and 500 milliseconds + SLAVE_RANK * 1000 milliseconds.</span><br></pre></td></tr></table></figure>
<ul>
<li>一部分为固定的500ms时间，这500ms主要是为了等待集群状态同步。上面提到节点C会向集群所有节点广播消息，那么这500ms就是等待确保集群的所有节点都收到了消息并更新了状态。</li>
<li>另一部分主要是一个随机的时间加上由该Slave节点的排名决定的附加时间。每个slave都会记录自己从主节点同步数据的复制偏移量。复制偏移量越大，说明该节点与主节点数据保持的越一致。那么显然我们选举的时候肯定是想选状态更新最近的子节点，所以我们按照更新状态的排序来确定休眠时间的附加部分。状态更新最近的节点SLAVE_RANK排名为1，那么其休眠的时间相应的也最短，也就意味着该节点最有可能获得大部分选票。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">void clusterHandleSlaveFailover(void) &#123;</span><br><span class="line"></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">    /* If the previous failover attempt timedout and the retry time has</span><br><span class="line">     * elapsed, we can setup a new one. */</span><br><span class="line">    if (auth_age &gt; auth_retry_time) &#123;</span><br><span class="line">        server.cluster-&gt;failover_auth_time = mstime() +</span><br><span class="line">                                             500 + /* Fixed delay of 500 milliseconds, let FAIL msg propagate. */</span><br><span class="line">                                             random() % 500; /* Random delay between 0 and 500 milliseconds. */</span><br><span class="line">        server.cluster-&gt;failover_auth_count = 0;</span><br><span class="line">        server.cluster-&gt;failover_auth_sent = 0;</span><br><span class="line">        server.cluster-&gt;failover_auth_rank = clusterGetSlaveRank();</span><br><span class="line">        /* We add another delay that is proportional to the slave rank.</span><br><span class="line">         * Specifically 1 second * rank. This way slaves that have a probably</span><br><span class="line">         * less updated replication offset, are penalized. */</span><br><span class="line">        server.cluster-&gt;failover_auth_time +=</span><br><span class="line">                server.cluster-&gt;failover_auth_rank * 1000;</span><br><span class="line">        /* However if this is a manual failover, no delay is needed. */</span><br><span class="line">        if (server.cluster-&gt;mf_end) &#123;</span><br><span class="line">            server.cluster-&gt;failover_auth_time = mstime();</span><br><span class="line">            server.cluster-&gt;failover_auth_rank = 0;</span><br><span class="line">        &#125;</span><br><span class="line">        redisLog(REDIS_WARNING,</span><br><span class="line">                 &quot;Start of election delayed for %lld milliseconds &quot;</span><br><span class="line">                 &quot;(rank #%d, offset %lld).&quot;,</span><br><span class="line">                 server.cluster-&gt;failover_auth_time - mstime(),</span><br><span class="line">                 server.cluster-&gt;failover_auth_rank,</span><br><span class="line">                 replicationGetSlaveOffset());</span><br><span class="line">        /* Now that we have a scheduled election, broadcast our offset</span><br><span class="line">         * to all the other slaves so that they&#x27;ll updated their offsets</span><br><span class="line">         * if our offset is better. */</span><br><span class="line">        clusterBroadcastPong(CLUSTER_BROADCAST_LOCAL_SLAVES);</span><br><span class="line">        return;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    ...</span><br><span class="line">    </span><br><span class="line">    /* Return ASAP if we can&#x27;t still start the election. */</span><br><span class="line">    // 如果执行故障转移的时间未到，先返回</span><br><span class="line">    if (mstime() &lt; server.cluster-&gt;failover_auth_time) return;</span><br><span class="line"></span><br><span class="line">    ...</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
5、发起拉票 &amp; 选举投票<br>B1唤醒后，会向其他所有节点发送拉票请求，即<code>CLUSTERMSG_TYPE_FAILOVER_AUTH_REQUEST</code>类型的消息。<br>其他主节点接收到拉票请求，且此时它还没有投出自己的票，则会将自己票投给发请求的B1，即回复<code>FAILOVER_AUTH_ACK</code>消息。<br>其他子节点没有投票的资格，因此即使接收到<code>CLUSTERMSG_TYPE_FAILOVER_AUTH_REQUEST</code>类型消息也会直接忽略。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">void clusterHandleSlaveFailover(void) &#123;</span><br><span class="line"></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">    /* Ask for votes if needed. */</span><br><span class="line">    // 向其他节点发送故障转移请求</span><br><span class="line">    if (server.cluster-&gt;failover_auth_sent == 0) &#123;</span><br><span class="line"></span><br><span class="line">        // 增加配置纪元</span><br><span class="line">        server.cluster-&gt;currentEpoch++;</span><br><span class="line"></span><br><span class="line">        // 记录发起故障转移的配置纪元</span><br><span class="line">        server.cluster-&gt;failover_auth_epoch = server.cluster-&gt;currentEpoch;</span><br><span class="line"></span><br><span class="line">        redisLog(REDIS_WARNING, &quot;Starting a failover election for epoch %llu.&quot;,</span><br><span class="line">                 (unsigned long long) server.cluster-&gt;currentEpoch);</span><br><span class="line"></span><br><span class="line">        // 向其他所有节点发送信息，看它们是否支持由本节点来对下线主节点进行故障转移</span><br><span class="line">        clusterRequestFailoverAuth();</span><br><span class="line"></span><br><span class="line">        // 打开标识，表示已发送信息</span><br><span class="line">        server.cluster-&gt;failover_auth_sent = 1;</span><br><span class="line"></span><br><span class="line">        // TODO:</span><br><span class="line">        // 在进入下个事件循环之前，执行：</span><br><span class="line">        // 1）保存配置文件</span><br><span class="line">        // 2）更新节点状态</span><br><span class="line">        // 3）同步配置</span><br><span class="line">        clusterDoBeforeSleep(CLUSTER_TODO_SAVE_CONFIG |</span><br><span class="line">                             CLUSTER_TODO_UPDATE_STATE |</span><br><span class="line">                             CLUSTER_TODO_FSYNC_CONFIG);</span><br><span class="line">        return; /* Wait for replies. */</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    ...</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
6、替换节点（failover）<br>当子节点接收到来自其他节点的ACK消息时会统计自己获得的票数，当达到集群Master总数的一半以上时，就会开始执行failover，即替换自己的主节点。<br>首先标记自己为主节点，然后将原来由节点B负责的slots标记为由自己负责，最后向整个集群广播现在自己是Master同时负责旧Master所有slots的信息。其他节点接收到该信息后会更新自己维护的B1的状态并标记B1为主节点，将节点B负责的slots的负责节点设置为B1节点。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">void clusterHandleSlaveFailover(void) &#123;</span><br><span class="line"></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">    /* Check if we reached the quorum. */</span><br><span class="line">    // 如果当前节点获得了足够多的投票，那么对下线主节点进行故障转移</span><br><span class="line">    if (server.cluster-&gt;failover_auth_count &gt;= needed_quorum) &#123;</span><br><span class="line">        // 旧主节点</span><br><span class="line">        clusterNode *oldmaster = myself-&gt;slaveof;</span><br><span class="line"></span><br><span class="line">        redisLog(REDIS_WARNING,</span><br><span class="line">                 &quot;Failover election won: I&#x27;m the new master.&quot;);</span><br><span class="line"></span><br><span class="line">        /* We have the quorum, perform all the steps to correctly promote</span><br><span class="line">         * this slave to a master.</span><br><span class="line">         *</span><br><span class="line">         * 1) Turn this node into a master. </span><br><span class="line">         *    将当前节点的身份由从节点改为主节点</span><br><span class="line">         */</span><br><span class="line">        clusterSetNodeAsMaster(myself);</span><br><span class="line">        // 让从节点取消复制，成为新的主节点</span><br><span class="line">        replicationUnsetMaster();</span><br><span class="line"></span><br><span class="line">        /* 2) Claim all the slots assigned to our master. */</span><br><span class="line">        // 接收所有主节点负责处理的槽</span><br><span class="line">        for (j = 0; j &lt; REDIS_CLUSTER_SLOTS; j++) &#123;</span><br><span class="line">            if (clusterNodeGetSlotBit(oldmaster, j)) &#123;</span><br><span class="line">                // 将槽设置为未分配的</span><br><span class="line">                clusterDelSlot(j);</span><br><span class="line">                // 将槽的负责人设置为当前节点</span><br><span class="line">                clusterAddSlot(myself, j);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        /* 3) Update my configEpoch to the epoch of the election. */</span><br><span class="line">        // 更新集群配置纪元</span><br><span class="line">        myself-&gt;configEpoch = server.cluster-&gt;failover_auth_epoch;</span><br><span class="line"></span><br><span class="line">        /* 4) Update state and save config. */</span><br><span class="line">        // 更新节点状态</span><br><span class="line">        clusterUpdateState();</span><br><span class="line">        // 并保存配置文件</span><br><span class="line">        clusterSaveConfigOrDie(1);</span><br><span class="line"></span><br><span class="line">        /* 5) Pong all the other nodes so that they can update the state</span><br><span class="line">         *    accordingly and detect that we switched to master role. */</span><br><span class="line">        // 向所有节点发送 PONG 信息</span><br><span class="line">        // 让它们可以知道当前节点已经升级为主节点了</span><br><span class="line">        clusterBroadcastPong(CLUSTER_BROADCAST_ALL);</span><br><span class="line"></span><br><span class="line">        /* 6) If there was a manual failover in progress, clear the state. */</span><br><span class="line">        // 如果有手动故障转移正在执行，那么清理和它有关的状态</span><br><span class="line">        resetManualFailover();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="配置更新"><a href="#配置更新" class="headerlink" title="配置更新"></a>配置更新</h3><p>上边我们已经通过故障发现和子节点选举机制用B1这个子节点替换掉了它的Master节点B，那么留下来的节点B和B2应该怎么处理呢？实际上Redis会让它们变成B1的Slave节点。<br>1、对B2来说，B1升级成Master后会给B2发送消息，让它知道自己已经升级成Master了。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">void clusterHandleSlaveFailover(void) &#123;</span><br><span class="line"></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">        /* 5) Pong all the other nodes so that they can update the state</span><br><span class="line">         *    accordingly and detect that we switched to master role. */</span><br><span class="line">        // 向所有节点发送 PONG 信息</span><br><span class="line">        // 让它们可以知道当前节点已经升级为主节点了</span><br><span class="line">        clusterBroadcastPong(CLUSTER_BROADCAST_ALL);</span><br><span class="line"></span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>2、对B来说，B1已经成为了Master，B从故障恢复后再次加入集群时，会成为B1的Slave。</p>
<h2 id="Cluster数据丢失隐患及处理方案"><a href="#Cluster数据丢失隐患及处理方案" class="headerlink" title="Cluster数据丢失隐患及处理方案"></a>Cluster数据丢失隐患及处理方案</h2><p>一种数据丢失的场景是主从复制时Master挂掉了，这点我在《<a href="https://tallate.github.io/edd4cfac.html#%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E4%B8%BB%E4%BB%8E%E6%95%B0%E6%8D%AE%E7%9A%84%E4%B8%80%E8%87%B4%E6%80%A7-%E6%95%B0%E6%8D%AE%E4%B8%A2%E5%A4%B1%E7%AA%97%E5%8F%A3%E7%9A%84%E5%AD%98%E5%9C%A8">Redis 复制</a>》讨论过。<br>另一种数据丢失的场景存在于Cluster集群中，并且并不是特别容易出现，也就是Cluster发生了脑裂，分区恢复时脑裂期间的数据被覆盖：</p>
<ol>
<li>主节点挂掉了，从节点选举出了一个新的主节点，但是此时客户端还在与老主节点通信，将数据写入到老的主节点上；<blockquote>
<p>这种情况是可能发生的，因为客户端会记忆槽所在的节点，而不是每次请求都通过重定向定位到槽实际所在的节点上。</p>
</blockquote>
</li>
<li>之后主从切换成功后，老的主节点会成功新主节点的Slave，并从新的主节点上获取数据，这时该节点上的数据会被清空，从而导致数据丢失。</li>
</ol>
<h3 id="为什么会发生脑裂？"><a href="#为什么会发生脑裂？" class="headerlink" title="为什么会发生脑裂？"></a>为什么会发生脑裂？</h3><p>在《<a target="_blank" rel="noopener" href="https://time.geekbang.org/column/article/303568">Redis核心技术与实战</a>》中提到了一种会导致脑裂的情况：</p>
<ol>
<li>Slave会定时地PING Master，发生的错误达到一定时间会被标记为主观下线，当标记主观下线的次数达到规定数量后，标记为客观下线；</li>
<li>但是Master实际上是“假故障”，即虽然响应Slave的心跳失败了，但是客户端还是可以和Master正常通信的。<br>比如宿主机上有一些其他进程将CPU打满了，在打满期间，Slave就会有可能将Master判断为下线，开始选举及主从切换。</li>
</ol>
<h3 id="为什么脑裂会导致数据丢失？"><a href="#为什么脑裂会导致数据丢失？" class="headerlink" title="为什么脑裂会导致数据丢失？"></a>为什么脑裂会导致数据丢失？</h3><p>主从切换后，从库会升级为新主库，这时如果老主库重新上线了，会成为新主库的Slave，执行全量同步，而全量同步执行的最后阶段，需要清空本地的数据，加载新主库发送过来的RDB文件，这期间写入的数据就会丢失了。</p>
<h3 id="如何解决这种脑裂问题？"><a href="#如何解决这种脑裂问题？" class="headerlink" title="如何解决这种脑裂问题？"></a>如何解决这种脑裂问题？</h3><p>可以通过两个配置来解决这个脑裂问题：</p>
<ul>
<li><code>min-slaves-to-write</code><br>这个配置项设置了主库能进行数据同步的最少从库数量</li>
<li><code>min-slaves-to-write</code><br>min-slaves-max-lag：这个配置项设置了主从库间进行数据复制时，从库给主库发送 ACK 消息的最大延迟（以秒为单位）</li>
</ul>
<p>我们可以把 min-slaves-to-write 和 min-slaves-max-lag 这两个配置项搭配起来使用，分别给它们设置一定的阈值，假设为 N 和 T。这两个配置项组合后的要求是，主库连接的从库中至少有 N 个从库，和主库进行数据复制时的 ACK 消息延迟不能超过 T 秒，否则，主库就不会再接收客户端的请求了。即使原主库是假故障，它在假故障期间也无法响应哨兵心跳，也不能和从库进行同步，自然也就无法和从库进行 ACK 确认了。这样一来，min-slaves-to-write 和 min-slaves-max-lag 的组合要求就无法得到满足，原主库就会被限制接收客户端请求，客户端也就不能在原主库中写入新数据了。等到新主库上线时，就只有新主库能接收和处理客户端请求，此时，新写的数据会被直接写到新主库中。而原主库会被哨兵降为从库，即使它的数据被清空了，也不会有新数据丢失。<br>举个例子：假设我们将min-slaves-to-write 设置为 1，把 min-slaves-max-lag 设置为 12s，把哨兵的 down-after-milliseconds 设置为 10s，主库因为某些原因卡住了 15s，导致哨兵判断主库客观下线，开始进行主从切换。同时，因为原主库卡住了 15s，没有一个从库能和原主库在 12s 内进行数据复制，原主库也无法接收客户端请求了。这样一来，主从切换完成后，也只有新主库能接收请求，不会发生脑裂，也就不会发生数据丢失的问题了。</p>
<h2 id="数据倾斜"><a href="#数据倾斜" class="headerlink" title="数据倾斜"></a>数据倾斜</h2><p>Cluster集群通过CRC16算法将key hash到节点槽上，这个过程还是存在很多不确定性，可能很多数据会被hash到固定的某几个槽上，造成数据分布的不均匀，或者某些key是热点数据，被访问得尤其频繁。</p>
<h3 id="数据倾斜的危害"><a href="#数据倾斜的危害" class="headerlink" title="数据倾斜的危害"></a>数据倾斜的危害</h3><p>数据倾斜的危害主要是保存热点数据的节点处理压力会增大，速度变慢，甚至内存资源耗尽而崩溃。</p>
<h3 id="数据倾斜的成因"><a href="#数据倾斜的成因" class="headerlink" title="数据倾斜的成因"></a>数据倾斜的成因</h3><p>数据倾斜的成因主要有3个：</p>
<ol>
<li>bigkey<br>bigkey一般是value值很大的string或保存了大量对象的集合类型。<br>bigkey可能会造成实例IO线程阻塞，影响其他请求的执行效率。<br>为了处理bigkey，设计的时候最好避免把过多的数据保存在同一个键值对中，如果是集合类型，还可以把bigkey拆分成多个小的集合类型数据，分散保存在不同的实例上。</li>
<li>slot分配不均衡<br>如果没有均衡地分配slot，就会有大量的数据被分配到同一个slot中，而同一个slot只会在一个实例上分布，并导致大量数据被集中到同一个实例上。</li>
<li>Hash Tag<br>hash tag指针对key的某个部分进行hash，比如user:123，可以加上hash tag后变成user:{123}，只针对123进行hash。<br>hash tag的意义主要在于可以将同类的数据hash到同一个槽上，便于范围查询。<br>hash tag的缺点也在于分布到同一槽内后，对该槽所在节点的压力会变大。</li>
</ol>
<h3 id="数据倾斜的解决办法"><a href="#数据倾斜的解决办法" class="headerlink" title="数据倾斜的解决办法"></a>数据倾斜的解决办法</h3><p>数据倾斜可以通过重分配slot来解决。<br>但是热点数据往往是少部分数据被频繁访问，这种情况下重分配slot是无法解决的，为此可以通过热点数据多副本的方法来解决，比如同一key添加一个前缀然后hash到其他slot上。<br>但是多副本只能用于只读热点key，对于有读有写的热点数据，就只能给实例本身增加资源了，比如改成配置更高的机器。</p>
<h2 id="QA"><a href="#QA" class="headerlink" title="QA"></a>QA</h2><ol>
<li>Redis Cluster哈希槽通过CRC16算法将key哈希到实例上的槽，这样做有什么好处？为什么不直接用一张表来存储key和哈希槽之间的对应关系？<br>如果用一张关系表来做映射，问题太多了，比如：key太多了怎么存关系？集群扩容、缩容、故障转移时怎么修改key和实例间的对应关系？<br>而引入哈希槽，实际上是将数据和节点解耦，客户端只需关注key被hash到哪个哈希槽，就算打到错误的节点上，也可以通过</li>
</ol>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li><a target="_blank" rel="noopener" href="http://redisdoc.com/topic/cluster-spec.html">Redis 集群规范</a></li>
<li><a target="_blank" rel="noopener" href="https://redissrc.readthedocs.io/en/latest/">redis源码解析</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/104641341">Redis集群详解（上）</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/105569485">Redis集群详解（中）</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/106110578">Redis集群（终篇）</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/zhaohongfei_358/article/details/102665730">Redis在线数据迁移工具redis-migrate-tool详解，轻松实现redis集群之间的数据同步</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/hellozhxy/article/details/103527186">CRDT——解决最终一致问题的利器</a></li>
</ol>
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kity@2.0.4/dist/kity.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text/javascript" src="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.6.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.6.0/dist/mindmap.min.css">
    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Redis/" rel="tag"># Redis</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/7731e967.html" rel="prev" title="发号器">
                  <i class="fa fa-angle-left"></i> 发号器
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/d368c702.html" rel="next" title="Redis高可用方案Sentinel">
                  Redis高可用方案Sentinel <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">tallate</span>
  </div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

  <a href="https://github.com/tallate" class="github-corner" title="在 GitHub 上关注我" aria-label="在 GitHub 上关注我" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>


  <script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"version":"7.1.2","options":null,"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.3.0/mermaid.min.js","integrity":"sha256-9y71g5Lz/KLsHjB8uXwnkuWDtAMDSzD/HdIbqhJfTAI="}}</script>
  <script src="/js/third-party/tags/mermaid.js"></script>





  





</body>
</html>
