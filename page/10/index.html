<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"tallate.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.18.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>

    <meta property="og:type" content="website">
<meta property="og:title" content="Tallate">
<meta property="og:url" content="https://tallate.github.io/page/10/index.html">
<meta property="og:site_name" content="Tallate">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="tallate">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://tallate.github.io/page/10/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"page/10/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Tallate</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Tallate</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">该吃吃该喝喝 啥事别往心里搁</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="tags fa-fw"></i>标签<span class="badge">83</span></a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="th fa-fw"></i>分类<span class="badge">25</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="archive fa-fw"></i>归档<span class="badge">189</span></a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">tallate</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">189</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">25</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">83</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/6ead94ff.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="tallate">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Tallate">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/6ead94ff.html" class="post-title-link" itemprop="url">JVM 与执行引擎</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2019-09-26 15:26:49" itemprop="dateCreated datePublished" datetime="2019-09-26T15:26:49+08:00">2019-09-26</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-07-07 01:56:20" itemprop="dateModified" datetime="2025-07-07T01:56:20+08:00">2025-07-07</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Java/" itemprop="url" rel="index"><span itemprop="name">Java</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <span id="more"></span>



<h2 id="栈帧结构"><a href="#栈帧结构" class="headerlink" title="栈帧结构"></a>栈帧结构</h2><p>栈帧主要包括了局部变量表、操作数栈、动态连接、方法返回地址等信息，在内存结构章节中我们已经探讨过栈结构，但是还未从实现层面来讨论过。</p>
<ol>
<li>局部变量表<br>用于存放方法参数和方法内部的局部变量。局部变量表的大小在方法的 Code 属性中就已经定义好了，为<strong>max_locals</strong>的值，局部变量表的单位为<strong>slot</strong>，32位以内的类型只占用一个<strong>slot</strong>（包括 returnAddress 类型），64 位的类型占用两个 slot。<ul>
<li>对于实例方法而言，索引为 0 的 slot 存放的是 this 引用，之后再依次存放方法参数、局部变量；</li>
<li>slot 可以被重用，当局部变量已经超出了作用域时，在作用域外再定义局部变量时，可以重用之前的 slot 空间。</li>
<li>同时，局部变量没有赋值是不能够使用的——会产生编译错误，这和类变量和实例变量是有不同的，如下面代码： <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">public void test() &#123;</span><br><span class="line">    int i;</span><br><span class="line">    System.out.println(i);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>操作数栈<br>执行方法时，存放操作数的栈，栈的深度在方法的 Code 属性中已经定义好了，为<strong>max_stack</strong>的值，32 位以内的类型占用一个栈单位，64 位的类型占用两个栈单位。操作数栈可以与其他栈的局部变量表共享区域，这样可以共用一部分数据。</li>
<li>动态连接<br>动态连接是为了支持在运行期间将符号引用转化为直接引用的操作。我们知道，每一个方法对应一个栈帧，而每一个栈帧，都包含指向对应方法的引用，这个引用就是为了支持动态连接，如 invokedynamic 指令。动态连接与静态解析对应，静态解析是在类加载（解析阶段）或者第一次使用时将符号引用转化为直接引用，动态连接则是每一次运行的时候都需要进行转化(invokedynamic 指令)。</li>
<li>方法返回地址<br>正常方法返回，返回地址为到调用该方法的指令的下一条指令的地址；异常返回，返回地址由异常表确定。方法返回时，需要恢复上层方法的局部变量表、操作数栈、将返回值压入调用者栈帧的操作数栈、设置 PC 值。</li>
</ol>
<h2 id="方法的调用和执行"><a href="#方法的调用和执行" class="headerlink" title="方法的调用和执行"></a>方法的调用和执行</h2><p>方法<strong>调用</strong>决定了调用哪个方法，并创建对应的栈帧，接下来会开始方法的<strong>执行</strong>。</p>
<h3 id="解析"><a href="#解析" class="headerlink" title="解析"></a>解析</h3><p>在程序执行前就已经确定了方法调用的<strong>版本</strong>，即编译期就确定了调用方法版本，这个版本在运行时是不可变的。</p>
<ul>
<li><strong>静态方法</strong>、<strong>私有方法</strong>、<strong>final方法</strong>在编译时就可以确定具体的调用版本，静态方法直接与类型相关、私有方法在外部不可访问、final 不可被继承，也可唯一确定，这些方法称为<strong>非虚方法</strong>，翻译成字节码是 invokestatic(调用静态方法)、invokespecial(调用实例构造器<init>方法、私有方法、父类方法)，在类加载的解析阶段就可以进行解析，如下方法调用在编译期就可以确定方法调用的版本。  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">class Father &#123;</span><br><span class="line">    public static void print(String str) &#123;</span><br><span class="line">        System.out.println(&quot;father &quot; + str);</span><br><span class="line">    &#125;</span><br><span class="line">    private void show(String str) &#123;</span><br><span class="line">        System.out.println(&quot;father &quot; + str);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">class Son extends Father &#123;</span><br><span class="line">&#125;</span><br><span class="line">public class Test &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        Son.print(&quot;coder&quot;); // 调用的是Father的print()方法</span><br><span class="line">        //Father fa = new Father();</span><br><span class="line">        //fa.show(&quot;cooooder&quot;); // 私有方法无法调用</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>其他方法称为<strong>虚方法</strong>。</li>
</ul>
<h3 id="分派"><a href="#分派" class="headerlink" title="分派"></a>分派</h3><p>分派调用与多态密切相关，分为<strong>静态分派</strong>、<strong>动态分派</strong>、<strong>单分派</strong>、<strong>多分派</strong>。</p>
<h4 id="静态分派"><a href="#静态分派" class="headerlink" title="静态分派"></a>静态分派</h4><p>与静态分派相关的就是方法的<strong>重载</strong>，重载时根据参数的静态类型引用类型而非实际类型决定调用哪个版本。<br>选取的过程共分为三个阶段：</p>
<ol>
<li>在不考虑对基本类型自动装拆箱（auto-boxing，auto-unboxing），以及可变长参数的情况下选取重载方法；</li>
<li>如果在第 1 个阶段中没有找到适配的方法，那么在允许自动装拆箱，但不允许可变长参数的情况下选取重载方法；</li>
<li>如果在第 2 个阶段中没有找到适配的方法，那么在允许自动装拆箱以及可变长参数的情况下选取重载方法。</li>
</ol>
<p>如果 Java 编译器在同一个阶段中找到了多个适配的方法，那么它会在其中选择一个最为贴切的，而决定贴切程度的一个关键就是形式参数类型的继承关系。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * 重载方法在编译器就可以进行确定，不需要等到运行期间</span><br><span class="line"> */</span><br><span class="line">public class StaticDispatch &#123;</span><br><span class="line">    static class Human &#123;</span><br><span class="line">    &#125;</span><br><span class="line">    static class Women extends Human &#123;</span><br><span class="line">    &#125;</span><br><span class="line">    static class Men extends Human &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public void sayHello(Human human) &#123;</span><br><span class="line">        System.out.println(&quot;say human&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">    public void sayHello(Women women) &#123;</span><br><span class="line">        System.out.println(&quot;say women&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">    public void sayHello(Men men) &#123;</span><br><span class="line">        System.out.println(&quot;say men&quot;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        StaticDispatch ds = new StaticDispatch();</span><br><span class="line">        Human women = new Women();</span><br><span class="line">        Human men = new Men();</span><br><span class="line">        // 编译时确定方法的调用版本是以Human作为参数的方法</span><br><span class="line">        ds.sayHello(women);</span><br><span class="line">        ds.sayHello(men);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="动态分派"><a href="#动态分派" class="headerlink" title="动态分派"></a>动态分派</h4><p>与动态分派相关的就是方法的<strong>重写</strong>，在子类中我们会重写父类的方法，而在调用的时候根据实际类型来选择适合的调用版本。<br>    <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">public class DynamicDispatch &#123;</span><br><span class="line">    abstract static class Human &#123;</span><br><span class="line">        abstract public void sayHello();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    static class Women extends Human &#123;</span><br><span class="line">        @Override</span><br><span class="line">        public void sayHello() &#123;</span><br><span class="line">            System.out.println(&quot;say women&quot;);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    static class Men extends Human &#123;</span><br><span class="line">        @Override</span><br><span class="line">        public void sayHello() &#123;</span><br><span class="line">            System.out.println(&quot;say men&quot;);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; </span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        Human women = new Women();</span><br><span class="line">        Human men = new Men();</span><br><span class="line">        women.sayHello(); // 实际类型是Women</span><br><span class="line">        men.sayHello(); // 实际类型是Men</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h4 id="单分派与多分派"><a href="#单分派与多分派" class="headerlink" title="单分派与多分派"></a>单分派与多分派</h4><p>方法的接收者(方法的所有者)与方法的参数统称为方法的<strong>宗量</strong>，根据分派基于多少种宗量，可以将分派划分为<strong>单分派</strong>和<strong>多分派</strong>。<br>单分派根据一个宗量确定调用方法的版本；多分派根据多个宗量确定调用方法的版本。<br>    <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">public class Dispatch &#123;</span><br><span class="line">    static class QQ &#123;&#125;;</span><br><span class="line">    static class _360&#123;&#125;;</span><br><span class="line"></span><br><span class="line">    public static class Father &#123;</span><br><span class="line">        public void hardChoice(QQ arg) &#123;</span><br><span class="line">            System.out.println(&quot;father choose qq&quot;);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        public void hardChoice(_360 arg) &#123;</span><br><span class="line">            System.out.println(&quot;father choose 360&quot;);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static class Son extends Father &#123;</span><br><span class="line">        public void hardChoice(QQ arg) &#123;</span><br><span class="line">            System.out.println(&quot;son choose qq&quot;);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        public void hardChoice(_360 arg) &#123;</span><br><span class="line">            System.out.println(&quot;son choose 360&quot;);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        Father father = new Father();</span><br><span class="line">        Father son = new Son();</span><br><span class="line">        father.hardChoice(new _360());</span><br><span class="line">        son.hardChoice(new QQ());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>静态分派过程如下，在编译期阶段，会根据静态类型与参数类型确定调用版本，产生两条分别指向 Father.hardChoice(QQ)和 Father.hardChoice(_360)的指令，可以知道，在编译期，是由多个宗量确定调用版本，是静态多分派。<br>动态分派过程如下，在运行期，在执行 hardChoice(QQ)或者 hardChoice(_360)时，已经确定了参数必须为 QQ、_360，方法签名确定，静态类型和实际类型此时都不会对方法本身产生任何影响，而虚拟机会根据实际类型来确定调用版本，只根据一个宗量进行确定，因此，在运行时，是动态单分派。<br>在面向对象编程中我们会很频繁地使用到动态分配，虚拟机采用在类的方法区建立一个<strong>虚方法表（非虚方法不会出现在表中）</strong>来实现。<br><img src="/imgs/JVM/%E5%8A%A8%E6%80%81%E5%88%86%E6%B4%BE%E7%9A%84%E5%AE%9E%E7%8E%B0.png" alt="动态分派的实现" title="动态分派的实现"></p>
<ul>
<li>只有<strong>虚方法</strong>才会出现在虚方法表中，也就是说<strong>静态方法</strong>、<strong>私有方法</strong>、<strong>final 方法</strong>是不会出现在这张表中的。</li>
<li>从 Object 类继承的方法都会指向 Object 类型数据中各方法的实际入口地址。</li>
<li>类自身的方法会指向类的数据类型中方法的实际入口地址。</li>
<li>父类的没有被重写的方法在虚方法表中的索引与子类方法表中的索引相同，这样，当类型变化时，只需要改变方法表就行，索引还是相同。</li>
<li>方法表一般在类加载的连接阶段进行初始化，准备了类变量的初始值后，方法表也初始化完毕。</li>
</ul>
<h3 id="方法退出"><a href="#方法退出" class="headerlink" title="方法退出"></a>方法退出</h3><p>当一个方法开始执行后，只有两种方式可以退出：</p>
<ol>
<li>第一种方式是执行引擎遇到任意一个方法返回的字节码指令，这种方式称为<strong>正常完成出口</strong>；</li>
<li>另外一种退出方式是，在方法执行过程中遇到异常，且该异常没有被被捕获，称为<strong>异常完成出口</strong>。</li>
</ol>
<p>无论是哪种退出方式，在方法退出后，都需要返回到该方法被调用的位置（地址），让程序继续执行。一般来说，方法执行前，会保存调用者当前的 PC 计数器中的值，当方法正常退出时，将该 PC 计数器的值会作为返回地址，返回给调用者。在方法异常退出时，返回地址是通过<strong>异常处理器表</strong>来确定的。</p>
<p>方法退出的过程实际上就等于把当前栈帧出栈，一般过程为：</p>
<ol>
<li>恢复上层方法的局部变量表和操作数栈</li>
<li>把返回值压入调用者栈帧的操作数栈中</li>
<li>调整 PC 计数器的值，以指向方法调用指令后面的一条指令</li>
</ol>
<h3 id="动态类型语言支持"><a href="#动态类型语言支持" class="headerlink" title="动态类型语言支持"></a>动态类型语言支持</h3><p>Java 是一种静态类型语言，它与 Python、JavaScript 等动态类型语言的主要区别是：</p>
<ul>
<li>静态类型语言的类型检查主要过程是在编译期进行而不是运行期。</li>
</ul>
<p>静态类型语言与动态类型语言的比较如下：</p>
<ul>
<li>静态类型语言在编译期确定类型，最显著的好处是编译器可以提供严谨的类型检查，这样与类型相关的问题能在编码的时候就及时发现，利于稳定性及代码达到更大规模。</li>
<li>动态类型语言在运行期确定类型，这可以为开发人员提供更大的灵活性，某些在静态类型语言中需用大量“臃肿”代码来实现的功能，由动态类型语言来实现可能会更加清晰和简洁，从而提升开发效率。</li>
</ul>
<p>在 JDK1.7 以前的字节码指令集中，4 条方法调用指令（invokevirtual、invokespecial、invokestatic、invokeinterface）的第一个参数都是被调用的方法的符号引用（CONSTANT_Methodref_info 或者 CONSTANT_InterfaceMethodref_info 常量），前面已经提到过，方法的符号引用在编译时产生，而动态类型语言只有在运行期才能确定接收者类型。<br>Java 不像 C&#x2F;C++那样有 Function Pointer 或者 C#里的 Delegate。在 Java 中要实现类似的功能可以有以下两种方式：</p>
<ol>
<li>实现一个函数接口，比如 Comparator</li>
<li>MethodHandle，它的实现原理是第 5 条方法调用的字节码指令 invokedynamic，与其他 invoke*指令的最大差别是它的分派逻辑不是由虚拟机决定的，而是由程序员决定的。</li>
</ol>
<p>MethodHandle 的例子：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">import java.lang.invoke.MethodHandle;</span><br><span class="line">import java.lang.invoke.MethodType;</span><br><span class="line"></span><br><span class="line">import static java.lang.invoke.MethodHandles.lookup;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * @author hgc</span><br><span class="line"> * @date 2/16/20</span><br><span class="line"> */</span><br><span class="line">public class MethodHandleTest &#123;</span><br><span class="line"></span><br><span class="line">    static class ClassA &#123;</span><br><span class="line">        public void println(String s) &#123;</span><br><span class="line">            System.out.println(s);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    private static MethodHandle getPrintlnMH(Object reveiver) throws NoSuchMethodException, IllegalAccessException &#123;</span><br><span class="line">        // MethodType代表方法类型，包含了方法的返回值（methodType()的第一个参数）和具体参数（methodType()第二个及之后的参数）</span><br><span class="line">        MethodType mt = MethodType.methodType(void.class, String.class);</span><br><span class="line">        // lookup()方法来自于MethodHandles.lookup，这句的作用是在指定类中查找符合给定方法名称、方法类型，并且符合调用权限的方法句柄</span><br><span class="line">        // 因为这里调用的是一个虚方法，按照Java语言的规则，方法第一个参数是隐式的，代表该方法的接收者，也即是this指向的对象，这个参数以前是放在参数列表中进行传递的，而现在提供了bindTo()方法来完成这件事</span><br><span class="line">        return lookup().findVirtual(reveiver.getClass(), &quot;println&quot;, mt).bindTo(reveiver);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) throws Throwable &#123;</span><br><span class="line">        Object obj = System.currentTimeMillis() % 2 == 0 ? System.out : new ClassA();</span><br><span class="line">        getPrintlnMH(obj).invokeExact(&quot;icyfenix&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>MethodHandle 与反射（Reflection）的区别是：</p>
<ul>
<li>Reflection API 的设计初衷是只为 Java 服务，而 MethodHandle 则设计为可服务于所有 Java 虚拟机之上的语言，当然也包括 Java 语言。</li>
<li>MethodHandle 与 Reflection 机制都是在模拟方法调用，但 Reflection 是在模拟代码层次的方法调用，而 MethodHandle 则是在模拟字节码层次的方法调用。<br>MethodHandles.lookup 中的 3 个方法——findStatic()、findVirtual()、findSpecial()对应了 invokestatic、invokevirtual + invokeinterface 和 invokespecial 这几条字节码指令的执行权限校验行为，而这些底层细节在使用 Reflection API 时无需考虑。</li>
<li>Reflection 中的 Method 比 MethodHandle 对象包含的信息多，Reflection 是重量级的，MethodHandle 是轻量级的。</li>
<li>MethodHandle 模拟了字节码的方法指令调用，所以理论上虚拟机在这方面做的各种优化（如方法内联）在 MethodHandle 上也可以采用类似思路来支持，而通过反射去调用方法则不行。</li>
</ul>
<p>至于 MethodHandle 是如何实现的，可以参考《深入理解 Java 虚拟机》，大致上就是运行期去常量表里根据用户指定的参数找方法。</p>
<p>###基于栈的字节码解释执行引擎<br>JVM 的指令都是基于栈的，比如<code>iadd</code>表示弹出栈顶的两个元素，然后求出二者的和后重新压入栈中。<br>基于栈的指令集与基于寄存器的指令集各有优势：</p>
<ul>
<li>基于栈的指令集的主要优点就是可移植。<br>寄存器是由硬件直接提供的，基于寄存器的指令集由于直接依赖这些硬件寄存器则不可避免地要受到硬件的约束。<br>如果使用栈架构的指令集，用户程序不会直接使用这些寄存器，就可以由虚拟机实现来自行决定把一些访问最频繁的数据（程序计数器、栈顶缓存等）放到寄存器中以获取尽量好的性能，这样实现起来也更加简单一些。</li>
<li>栈架构的指令集还有一些其他优点，比如代码相对来说更加紧凑（字节码中每个字节就对应一条指令，而多地址指令集中还需要存放参数）、编译器实现更加简单（不需要考虑空间分配的问题，所需空间都在栈上操作）等。</li>
<li>栈架构指令集的主要缺点是执行速度相对来说会稍慢一些。所有主流物理机的指令集都是寄存器架构也从侧面印证了这一点。<br>一方面，虽然栈架构指令集的代码非常紧凑，但是完成相同功能所需的指令数量一般会比寄存器架构多。比如出栈入栈操作本身就产生了相当多的指令数量。<br>另一方面，栈实现在内存之中，频繁的栈访问也就意味着频繁的内存访问，相对于处理器来说，内存始终是执行速度的瓶颈。尽管虚拟机可以采取栈顶缓存的手段，把最常用的操作映射到寄存器中避免直接内存访问，但这也只能是优化措施而不是解决本质问题的方法。</li>
</ul>
<h2 id="QA"><a href="#QA" class="headerlink" title="QA"></a>QA</h2><ol>
<li>哪个方法会被调用？<br>重载会触发静态分派，会根据传参的静态类型来决定调用哪个方法，因此会调用 print(Father)，但输出时调用了 Child 类的 toString 方法，因为方法被重写了，会触发方法的动态分派，根据传参的实际类型来决定调用哪个方法。  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">public class DynamicDispatchTest &#123;</span><br><span class="line"></span><br><span class="line">    public void print(Father father) &#123;</span><br><span class="line">        System.out.println(father);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public void print(Child child) &#123;</span><br><span class="line">        System.out.println(child);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static class Father &#123;</span><br><span class="line"></span><br><span class="line">        @Override</span><br><span class="line">        public String toString() &#123;</span><br><span class="line">            return &quot;Father&quot;;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static class Child extends Father &#123;</span><br><span class="line"></span><br><span class="line">        @Override</span><br><span class="line">        public String toString() &#123;</span><br><span class="line">            return &quot;Child&quot;;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        Father father = new Child();</span><br><span class="line">        DynamicDispatchTest dynamicDispatchTest = new DynamicDispatchTest();</span><br><span class="line">        dynamicDispatchTest.print(father);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ol>
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kity@2.0.4/dist/kity.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text/javascript" src="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.6.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.6.0/dist/mindmap.min.css">
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/e94a0a.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="tallate">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Tallate">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/e94a0a.html" class="post-title-link" itemprop="url">Redis 应用</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2019-09-25 13:21:48" itemprop="dateCreated datePublished" datetime="2019-09-25T13:21:48+08:00">2019-09-25</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-07-07 01:56:20" itemprop="dateModified" datetime="2025-07-07T01:56:20+08:00">2025-07-07</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%BC%93%E5%AD%98/" itemprop="url" rel="index"><span itemprop="name">缓存</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <span id="more"></span>


<h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><h3 id="搭建环境"><a href="#搭建环境" class="headerlink" title="搭建环境"></a>搭建环境</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker run --name myredis -d -p6379:6379 redis</span><br><span class="line">docker exec -it myredis redis-cli</span><br></pre></td></tr></table></figure>
<h3 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"># exists 查看某个key是否存在</span><br><span class="line">exists aa</span><br><span class="line">SET 创建一个key；</span><br><span class="line">GET 获取一个key的值；</span><br><span class="line">DEL ***一个key；</span><br><span class="line">TYPE 获取一个key的类型；</span><br><span class="line">EXISTS 判断一个key是否存在，0：存在，1，不存在；</span><br><span class="line"># KEYS 获取给定模糊匹配的key，但要谨慎使用，因为线上的key一般非常多</span><br><span class="line">keys *</span><br><span class="line">keys a?</span><br><span class="line">EXPIRE 设置一个key过期的秒数；</span><br><span class="line">PERSTST ***一个key过期的秒数；</span><br><span class="line">PEXPIRE 设置一个key过期的毫秒数；</span><br><span class="line">RENAME 将一个key重命名；</span><br><span class="line">RENAMENX 将一个key重命名，且新的key必须是不存在的可以；</span><br><span class="line">TTL 获取key的有效时间，以秒为单位，-1表示永不过期，-2表示已过期、已转移</span><br><span class="line"># dbsize 查看当前库中key数量</span><br><span class="line">dbsize</span><br><span class="line"># flushdb 清除数据库（内存）</span><br><span class="line">flushdb</span><br><span class="line"># move 移动key到另一个库</span><br><span class="line">move aa 2</span><br></pre></td></tr></table></figure>
<h3 id="容量预估"><a href="#容量预估" class="headerlink" title="容量预估"></a>容量预估</h3><p>在实际部署前一般都会先对所需容量进行一个评估，这样可以尽量避免在上线后容量不够还要扩容、或者容量过大造成浪费。<br>官方提供了一个<a target="_blank" rel="noopener" href="http://www.redis.cn/redis_memory/">容量预估工具</a>，一些博客比如<a target="_blank" rel="noopener" href="https://gameinstitute.qq.com/community/detail/114987">Redis 容量评估模型</a>贴近 Redis 底层数据结构给出了容量的评估分析，可以作为一个参考，但是业务架构一直在变，实际的容量监控还是必须的，我们下面还会谈到这方面的工具。</p>
<h2 id="使用Redis-Cluster"><a href="#使用Redis-Cluster" class="headerlink" title="使用Redis Cluster"></a>使用Redis Cluster</h2><h3 id="搭建Redis-Cluster集群"><a href="#搭建Redis-Cluster集群" class="headerlink" title="搭建Redis Cluster集群"></a>搭建Redis Cluster集群</h3><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_42815754/article/details/82912130">redis集群搭建</a></p>
<p>1、安装<br>到官网找到：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget http://download.redis.io/releases/redis-4.0.8.tar.gz</span><br><span class="line">make &amp;&amp; make install # 默认安装目录为/usr/local/bin</span><br></pre></td></tr></table></figure>
<p>ruby</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yum install ruby</span><br><span class="line">yum install rubygems</span><br></pre></td></tr></table></figure>
<p>还有gem文件在<a target="_blank" rel="noopener" href="https://rubygems.org/gems/redis/versions/4.0.1">此处下载</a>，安装：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gem install /usr/local/redis-3.0.0.gem</span><br></pre></td></tr></table></figure>
<p>2、创建 redis 节点<br>在一个目录（比如编译目录）下创建 redis_cluster 目录，再在这个目录下创建 7001、7002、7003、7004、7005、7006 的子目录，拷贝配置文件 redis.conf 到各个这些子目录中，并编辑以下内容</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">port 7001 //端口7001,7002,7003        </span><br><span class="line">bind 本机ip //默认ip为127.0.0.1 需要改为其他节点机器可访问的ip 否则创建集群时无法访问对应的端口，无法创建集群</span><br><span class="line">daemonize yes //redis后台运行</span><br><span class="line">pidfile /var/run/redis_7001.pid //pidfile文件对应7001,7002,7003</span><br><span class="line">logfile /tmp/redis_7001.log // 日志文件</span><br><span class="line">cluster-enabled yes //开启集群 把注释#去掉</span><br><span class="line">cluster-config-file nodes_7001.conf //集群的配置 配置文件首次启动自动生成 7001,7002,7003</span><br><span class="line">cluster-node-timeout 15000 //请求超时 默认15秒，可自行设置</span><br><span class="line">appendonly yes //aof日志开启 有需要就开启，它会每次写操作都记录一条日志</span><br></pre></td></tr></table></figure>
<p>3、创建集群<br>先安装 ruby，因为 redis 的集群协调程序是用 ruby 写的</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install ruby ruby-devel rubygems rpm-build</span><br></pre></td></tr></table></figure>
<p>再安装gem，在编译目录下执行</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gem install redis</span><br></pre></td></tr></table></figure>
<p>运行每个redis实例：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-server redis.conf</span><br></pre></td></tr></table></figure>
<p>复制编译目录下的src目录中的redis-trib.rb到&#x2F;usr&#x2F;local&#x2F;bin，然后运行<br>在编译目录的src子目录下执行，其中host为各redis节点的绑定ip（如果绑定的ip是0.0.0.0则必须指定为对外开放的ip，否则会默认绑定127.0.0.1，在slot重定向时会报错），设置每个主分片有一个副本分片</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./redis-trib.rb create --replicas 1 host1:port1 host2:port2 ...</span><br></pre></td></tr></table></figure>
<p>4、测试<br>为了连到集群上，需要在 redis-cli 请求后加上-c 参数，比如</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -h 192.168.31.245 -c -p 7002</span><br></pre></td></tr></table></figure>
<p>在普通set和get时，redis会自动计算出目标地址。<br>5、Java客户端连接</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">public class RedissonTest &#123;</span><br><span class="line"></span><br><span class="line">    private static final Random random = new Random();</span><br><span class="line"></span><br><span class="line">    static int succeed = 0;</span><br><span class="line"></span><br><span class="line">    static int failed = 0;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) throws InterruptedException &#123;</span><br><span class="line">        Config config = new Config();</span><br><span class="line">        config.useClusterServers()</span><br><span class="line">                .setScanInterval(2000)</span><br><span class="line">                .addNodeAddress(&quot;redis://127.0.0.1:7001&quot;, &quot;redis://127.0.0.1:7002&quot;, &quot;127.0.0.1:7003&quot;)</span><br><span class="line">                .addNodeAddress(&quot;redis://127.0.0.1:7004&quot;, &quot;redis://127.0.0.1:7005&quot;, &quot;127.0.0.1:7006&quot;);</span><br><span class="line">        RedissonClient redissonClient = Redisson.create(config);</span><br><span class="line">        while (true) &#123;</span><br><span class="line">            try &#123;</span><br><span class="line">                RBucket&lt;Object&gt; bucket = redissonClient.getBucket(Integer.toString(random.nextInt()));</span><br><span class="line">                bucket.get();</span><br><span class="line">                succeed++;</span><br><span class="line">                log.info(&quot;调用成功, 当前 succeed:&#123;&#125;, failed:&#123;&#125;&quot;, succeed, failed);</span><br><span class="line">            &#125; catch (Exception e) &#123;</span><br><span class="line">                failed++;</span><br><span class="line">                log.info(&quot;调用失败, 当前 succeed:&#123;&#125;, failed:&#123;&#125;&quot;, succeed, failed, e.getMessage());</span><br><span class="line">            &#125;</span><br><span class="line">            Thread.sleep(500);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="info-命令中涉及集群部署的部分"><a href="#info-命令中涉及集群部署的部分" class="headerlink" title="info 命令中涉及集群部署的部分"></a>info 命令中涉及集群部署的部分</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># Replication</span><br><span class="line"># 当前副本角色，如果实例不是任何节点的从节点，则该值是“master”，如果实例从某个节点同步数据，则是“slave”</span><br><span class="line">role:master</span><br><span class="line"># 已连接的从节点数</span><br><span class="line">connected_slaves:2</span><br><span class="line"># 每个从节点的信息，包括ID、地址、端口号、状态</span><br><span class="line">slave0:ip=10.32.140.18,port=6222,state=online,offset=1745391794554,lag=0</span><br><span class="line">slave1:ip=10.32.140.15,port=6212,state=online,offset=1745391807778,lag=0</span><br><span class="line">master_replid:6a64bcbbcae91324e72e24745392275e2f1382ea</span><br><span class="line">master_replid2:0000000000000000000000000000000000000000</span><br><span class="line">master_repl_offset:1745391878919</span><br><span class="line">second_repl_offset:-1</span><br><span class="line">repl_backlog_active:1</span><br><span class="line">repl_backlog_size:16777216</span><br><span class="line">repl_backlog_first_byte_offset:1745375101704</span><br><span class="line">repl_backlog_histlen:16777216</span><br></pre></td></tr></table></figure>

<h3 id="cluster-info-命令"><a href="#cluster-info-命令" class="headerlink" title="cluster info 命令"></a>cluster info 命令</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">10.32.140.15:6212&gt; cluster info</span><br><span class="line"># ok状态表示集群可以正常接受查询请求。fail 状态表示，至少有一个哈希槽没有被绑定（说明有哈希槽没有被绑定到任意一个节点），或者在错误的状态（节点可以提供服务但是带有FAIL 标记），或者该节点无法联系到多数master节点。</span><br><span class="line">cluster_state:ok</span><br><span class="line"># 已分配到集群节点的哈希槽数量（不是没有被绑定的数量）。16384个哈希槽全部被分配到集群节点是集群正常运行的必要条件.</span><br><span class="line">cluster_slots_assigned:16384</span><br><span class="line"># 哈希槽状态不是FAIL 和 PFAIL 的数量</span><br><span class="line">cluster_slots_ok:16384</span><br><span class="line"># 哈希槽状态是 PFAIL的数量。只要哈希槽状态没有被升级到FAIL状态，这些哈希槽仍然可以被正常处理。PFAIL状态表示我们当前不能和节点进行交互，但这种状态只是临时的错误状态</span><br><span class="line">cluster_slots_pfail:0</span><br><span class="line"># 哈希槽状态是FAIL的数量。如果值不是0，那么集群节点将无法提供查询服务，除非cluster-require-full-coverage被设置为no</span><br><span class="line">cluster_slots_fail:0</span><br><span class="line"># 集群中节点数量，包括处于握手状态还没有成为集群正式成员的节点</span><br><span class="line">cluster_known_nodes:9</span><br><span class="line"># 至少包含一个哈希槽且能够提供服务的master节点数量</span><br><span class="line">cluster_size:3</span><br><span class="line"># 集群本地Current Epoch变量的值。这个值在节点故障转移过程时有用，它总是递增和唯一的</span><br><span class="line">cluster_current_epoch:3</span><br><span class="line"># 当前正在使用的节点的Config Epoch值. 这个是关联在本节点的版本值</span><br><span class="line">cluster_my_epoch:2</span><br><span class="line">cluster_stats_messages_ping_sent:27870482</span><br><span class="line">cluster_stats_messages_pong_sent:27072640</span><br><span class="line">cluster_stats_messages_meet_sent:4</span><br><span class="line">cluster_stats_messages_sent:54943126</span><br><span class="line">cluster_stats_messages_ping_received:27072636</span><br><span class="line">cluster_stats_messages_pong_received:27865273</span><br><span class="line">cluster_stats_messages_meet_received:4</span><br><span class="line">cluster_stats_messages_fail_received:4</span><br><span class="line">cluster_stats_messages_publish_received:7514286</span><br><span class="line">cluster_stats_messages_received:62452203</span><br></pre></td></tr></table></figure>

<h3 id="cluster-nodes"><a href="#cluster-nodes" class="headerlink" title="cluster nodes"></a>cluster nodes</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 节点ID，IP地址：端口号，标识，上一次发送 ping 包的时间，上一次收到 pong 包的时间，连接状态，节点使用的哈希槽</span><br><span class="line">127.0.0.1:7001&gt; cluster nodes</span><br><span class="line">fcdcafe5482daa80d0a382f675e8caced2d6ce63 127.0.0.1:7001@17001 myself,slave b2d0be87492d75bce14d3e50f687ce8a7872ef73 0 1603765953000 7 connected</span><br><span class="line">75d6d1e3d4d64eb6fb85d1ac7d883ecef4ac5e7e 127.0.0.1:7002@17002 master - 0 1603765955026 2 connected 5461-10922</span><br><span class="line">b2d0be87492d75bce14d3e50f687ce8a7872ef73 127.0.0.1:7004@17004 master - 0 1603765952012 7 connected 0-5460</span><br><span class="line">8bf573a595a3955293e37f2e34e20c4cfb469060 127.0.0.1:7003@17003 master - 0 1603765954021 3 connected 10923-16383</span><br><span class="line">5d599dea56108003633cd27d13abf87a9ef07d52 127.0.0.1:7005@17005 slave 75d6d1e3d4d64eb6fb85d1ac7d883ecef4ac5e7e 0 1603765953000 2 connected</span><br><span class="line">68e6ddbf689bc6d51ebfadd24064fc6cc8204210 127.0.0.1:7006@17006 slave 8bf573a595a3955293e37f2e34e20c4cfb469060 0 1603765954000 3 connected</span><br></pre></td></tr></table></figure>

<h3 id="测试结果预期"><a href="#测试结果预期" class="headerlink" title="测试结果预期"></a>测试结果预期</h3><p>测试一些Cluster宕机的情况，预期会有以下结论：</p>
<ol>
<li>关闭任意一主，会导致部分写操作失败，是由于从节点不能执行写操作，在Slave升级为Master期间会有少量的失败。</li>
<li>关闭从节点对于整个集群没有影响。</li>
<li>如果半数以上 Master 处于关闭状态那么整个集群处于不可用状态。<br>原因：Redis Cluster的选举需要有Master参与，如果多半的Master都挂掉了，也就不能再支持选举新Master了。</li>
<li>关闭任意一对主从节点会导致部分（大约为整个集群的1&#x2F;3）失败。<br>Master宕机了，且没有替补的Slave，则分配给这个Master的slot就不可用了。</li>
</ol>
<h3 id="测试-压测"><a href="#测试-压测" class="headerlink" title="测试 - 压测"></a>测试 - 压测</h3><h3 id="测试-宕机1台Master"><a href="#测试-宕机1台Master" class="headerlink" title="测试 - 宕机1台Master"></a>测试 - 宕机1台Master</h3><p>下面的命令将7001干掉后测试集群的主从迁移情况。<br>刚开始集群7001、7002、7003是Master：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:7001&gt; cluster nodes</span><br><span class="line">5d599dea56108003633cd27d13abf87a9ef07d52 127.0.0.1:7005@17005 slave 75d6d1e3d4d64eb6fb85d1ac7d883ecef4ac5e7e 0 1603615592617 2 connected</span><br><span class="line">fcdcafe5482daa80d0a382f675e8caced2d6ce63 127.0.0.1:7001@17001 myself,master - 0 1603615591000 1 connected 0-5460</span><br><span class="line">b2d0be87492d75bce14d3e50f687ce8a7872ef73 127.0.0.1:7004@17004 slave fcdcafe5482daa80d0a382f675e8caced2d6ce63 0 1603615591614 1 connected</span><br><span class="line">8bf573a595a3955293e37f2e34e20c4cfb469060 127.0.0.1:7003@17003 master - 0 1603615591000 3 connected 10923-16383</span><br><span class="line">75d6d1e3d4d64eb6fb85d1ac7d883ecef4ac5e7e 127.0.0.1:7002@17002 master - 0 1603615592000 2 connected 5461-10922</span><br><span class="line">68e6ddbf689bc6d51ebfadd24064fc6cc8204210 127.0.0.1:7006@17006 slave 8bf573a595a3955293e37f2e34e20c4cfb469060 0 1603615593620 3 connected</span><br></pre></td></tr></table></figure>
<p>将7001 kill掉后，请求7001服务器的请求都会失败，大约20秒后请求恢复，且观察日志可以发现，原来7001的Slave-7004现在替补上来成为了Master：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">18:29:28.186 [main] INFO  c.t.l.r.RedissonTest - 调用成功, 当前 succeed:15, failed:0</span><br><span class="line">18:29:33.475 [main] INFO  c.t.l.r.RedissonTest - 调用失败, 当前 succeed:15, failed:1</span><br><span class="line">18:29:38.750 [main] INFO  c.t.l.r.RedissonTest - 调用失败, 当前 succeed:15, failed:2</span><br><span class="line">18:29:39.253 [main] INFO  c.t.l.r.RedissonTest - 调用成功, 当前 succeed:16, failed:2</span><br><span class="line">18:29:39.756 [main] INFO  c.t.l.r.RedissonTest - 调用成功, 当前 succeed:17, failed:2</span><br><span class="line">18:29:40.259 [main] INFO  c.t.l.r.RedissonTest - 调用成功, 当前 succeed:18, failed:2</span><br><span class="line">18:29:40.763 [main] INFO  c.t.l.r.RedissonTest - 调用成功, 当前 succeed:19, failed:2</span><br><span class="line">18:29:45.271 [redisson-netty-2-4] INFO  o.r.c.MasterSlaveEntry - master 127.0.0.1/127.0.0.1:7004 used as slave</span><br><span class="line">18:29:45.274 [redisson-netty-2-14] INFO  o.r.c.p.PubSubConnectionPool - 1 connections initialized for 127.0.0.1/127.0.0.1:7004</span><br><span class="line">18:29:45.280 [redisson-netty-2-4] WARN  o.r.c.ClusterConnectionManager - slave: redis://127.0.0.1:7001 has down for slot ranges: [[0-5460]]</span><br><span class="line">18:29:45.285 [redisson-netty-2-28] INFO  o.r.c.p.SlaveConnectionPool - 24 connections initialized for 127.0.0.1/127.0.0.1:7004</span><br></pre></td></tr></table></figure>
<p>之后重启7001后，发现7001重新加入到了集群中：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">18:34:18.539 [redisson-netty-2-29] INFO  o.r.c.p.PubSubConnectionPool - 1 connections initialized for 127.0.0.1/127.0.0.1:7001</span><br><span class="line">18:34:18.542 [redisson-netty-2-4] INFO  o.r.c.MasterSlaveEntry - master 127.0.0.1/127.0.0.1:7004 excluded from slaves</span><br><span class="line">18:34:18.542 [redisson-netty-2-4] INFO  o.r.c.ClusterConnectionManager - slave: redis://127.0.0.1:7001 has up for slot ranges: [[0-5460]]</span><br><span class="line">18:34:18.544 [redisson-netty-2-6] INFO  o.r.c.p.SlaveConnectionPool - 24 connections initialized for 127.0.0.1/127.0.0.1:7001</span><br></pre></td></tr></table></figure>

<h3 id="测试-宕机2台Master"><a href="#测试-宕机2台Master" class="headerlink" title="测试 - 宕机2台Master"></a>测试 - 宕机2台Master</h3><p>把两台Master干掉后，两个Master均进入fail状态，这时集群也会进入fail状态，选举不会成功。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">localhost:7001&gt; cluster nodes</span><br><span class="line">fcdcafe5482daa80d0a382f675e8caced2d6ce63 127.0.0.1:7001@17001 myself,slave b2d0be87492d75bce14d3e50f687ce8a7872ef73 0 1603622378000 7 connected</span><br><span class="line">75d6d1e3d4d64eb6fb85d1ac7d883ecef4ac5e7e 127.0.0.1:7002@17002 master - 0 1603622381510 2 connected 5461-10922</span><br><span class="line">b2d0be87492d75bce14d3e50f687ce8a7872ef73 127.0.0.1:7004@17004 master - 0 1603622379504 7 connected 0-5460</span><br><span class="line">8bf573a595a3955293e37f2e34e20c4cfb469060 127.0.0.1:7003@17003 master - 0 1603622380507 3 connected 10923-16383</span><br><span class="line">5d599dea56108003633cd27d13abf87a9ef07d52 127.0.0.1:7005@17005 slave 75d6d1e3d4d64eb6fb85d1ac7d883ecef4ac5e7e 0 1603622378498 2 connected</span><br><span class="line">68e6ddbf689bc6d51ebfadd24064fc6cc8204210 127.0.0.1:7006@17006 slave 8bf573a595a3955293e37f2e34e20c4cfb469060 0 1603622380000 3 connected</span><br></pre></td></tr></table></figure>
<p>集群fail后，客户端之后的请求也都失败了。</p>
<h2 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">set key value ex nx</span><br><span class="line">do sth...</span><br><span class="line">del key</span><br></pre></td></tr></table></figure>
<ol>
<li>为什么要加过期时间？<br>怕中间遇到异常退出，del 没有执行，导致陷入死锁。<br>set 命令现在支持加 ex 和 nx 参数，既保证原子性，又支持加过期时间。</li>
<li>过早过期释放别人的锁<br>业务执行时间过长，锁过期了，可能导致其他线程先获取到了锁，这样当前线程 del 的时候相当于将别人的锁释放掉了。<br>可以给 value 设置一个随机数，释放前检查一下，这是个“读后写”的过程，为了保证其原子性，一般会使用 Lua 脚本来实现（类似 Redisson 中的实现）。<br>Redisson 中的解决方案是加一个“看门狗”，定时刷新过期时间。</li>
<li>重入性<br>为了实现可重入性，一般是在客户端使用 ThreadLocal 存储当前持有锁的计数。<br>在 Redisson 中，可重入锁是通过在 Lua 脚本中对客户端线程 ID 进行计数来实现的。</li>
</ol>
<h2 id="延时队列"><a href="#延时队列" class="headerlink" title="延时队列"></a>延时队列</h2><h3 id="异步消息队列"><a href="#异步消息队列" class="headerlink" title="异步消息队列"></a>异步消息队列</h3><p>可以使用 list 数据结构来实现异步消息队列，使用 rpush&#x2F;lpush 操作入队列，使用 lpop 和 rpop 来出队列。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">rpush notify-queue a b</span><br><span class="line">llen notify-queue</span><br><span class="line">lpop notify-queue</span><br><span class="line">llen notify-queue</span><br><span class="line">lpop notify-queue</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<ol>
<li>如果队列空了怎么办？<br>客户端通过轮询队列 pop 获取消息处理，如果队列空了，那么就会陷入 pop 的死循环。<br>一般的解决办法是<code>sleep</code>，每次 pop 后可以暂停个 1 秒。<br>但是<code>sleep</code>同样会带来延迟增大的问题，因此，更好的解决办法是<code>blpop / brpop</code>，即阻塞读： <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">// 等待一秒若还没有数据则直接返回</span><br><span class="line">blpop notify-queue 1</span><br></pre></td></tr></table></figure></li>
<li>空闲连接<br>如果线程一直阻塞，则 Redis 的客户端连接将成为闲置连接，闲置过久，服务器一般会主动断开连接，减少闲置资源占用。这个时候 blpop&#x2F;brpop 会抛出异常来，这时要<strong>注意对异常的捕获和重试</strong>。</li>
<li>锁冲突处理<br>加锁失败一般有 3 种处理方式：<ul>
<li>直接抛出异常，由用户稍后重试；<br> 适合由用户直接发起的请求，比如商城下单，下单失败后由用户决定是否重新请求。</li>
<li>sleep<br> sleep 会阻塞消息处理线程，会导致后续消息处理出现延迟，不适合高并发（锁冲突频繁）或队列消息较多的情况，并且，如果是由于死锁导致的加锁不成功，sleep 将导致线程一直处于阻塞状态、后续的消息永远得不到处理。</li>
<li>延时队列<br> 将当前冲突的请求扔到另一个队列延后处理以避开冲突，适合异步消息处理的场景。</li>
</ul>
</li>
</ol>
<p>下面的实现例子来自《Redis 深度历险》：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line">public class RedisDelayingQueue&lt;T&gt; &#123;</span><br><span class="line"></span><br><span class="line">  static class TaskItem&lt;T&gt; &#123;</span><br><span class="line">    public String id;</span><br><span class="line">    public T msg;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  // fastjson 序列化对象中存在 generic 类型时，需要使用 TypeReference</span><br><span class="line">  private Type TaskType = new TypeReference&lt;TaskItem&lt;T&gt;&gt;() &#123;</span><br><span class="line">  &#125;.getType();</span><br><span class="line"></span><br><span class="line">  private Jedis jedis;</span><br><span class="line">  private String queueKey;</span><br><span class="line"></span><br><span class="line">  public RedisDelayingQueue(Jedis jedis, String queueKey) &#123;</span><br><span class="line">    this.jedis = jedis;</span><br><span class="line">    this.queueKey = queueKey;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  public void delay(T msg) &#123;</span><br><span class="line">    TaskItem&lt;T&gt; task = new TaskItem&lt;T&gt;();</span><br><span class="line">    task.id = UUID.randomUUID().toString();</span><br><span class="line">    task.msg = msg;</span><br><span class="line">    String s = JSON.toJSONString(task);</span><br><span class="line">    // key是当前时间</span><br><span class="line">    jedis.zadd(queueKey, System.currentTimeMillis() + 5000, s); // 塞入延时队列 ,5s 后再试</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  public void loop() &#123;</span><br><span class="line">    while (!Thread.interrupted()) &#123;</span><br><span class="line">      // 取时间范围是0到当前时间内的一条记录</span><br><span class="line">      // 第3个参数0表示不记分数，</span><br><span class="line">      Set&lt;String&gt; values = jedis.zrangeByScore(queueKey, 0, System.currentTimeMillis(), 0, 1);</span><br><span class="line">      if (values.isEmpty()) &#123;</span><br><span class="line">        try &#123;</span><br><span class="line">          // 暂停一会，避免浪费CPU</span><br><span class="line">          Thread.sleep(500);</span><br><span class="line">        &#125; catch (InterruptedException e) &#123;</span><br><span class="line">          break;</span><br><span class="line">        &#125;</span><br><span class="line">        continue;</span><br><span class="line">      &#125;</span><br><span class="line">      String s = values.iterator().next();</span><br><span class="line">      // 说明抢到了</span><br><span class="line">      if (jedis.zrem(queueKey, s) &gt; 0) &#123;</span><br><span class="line">        TaskItem&lt;T&gt; task = JSON.parseObject(s, TaskType);</span><br><span class="line">        this.handleMsg(task.msg);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  public void handleMsg(T msg) &#123;</span><br><span class="line">    System.out.println(msg);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  public static void main(String[] args) &#123;</span><br><span class="line">    Jedis jedis = new Jedis();</span><br><span class="line">    RedisDelayingQueue&lt;String&gt; queue = new RedisDelayingQueue&lt;&gt;(jedis, &quot;q-demo&quot;);</span><br><span class="line">    Thread producer = new Thread() &#123;</span><br><span class="line"></span><br><span class="line">      public void run() &#123;</span><br><span class="line">        for (int i = 0; i &lt; 10; i++) &#123;</span><br><span class="line">          queue.delay(&quot;codehole&quot; + i);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">    &#125;;</span><br><span class="line">    Thread consumer = new Thread() &#123;</span><br><span class="line"></span><br><span class="line">      public void run() &#123;</span><br><span class="line">        queue.loop();</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">    &#125;;</span><br><span class="line">    producer.start();</span><br><span class="line">    consumer.start();</span><br><span class="line">    try &#123;</span><br><span class="line">      producer.join();</span><br><span class="line">      Thread.sleep(6000);</span><br><span class="line">      consumer.interrupt();</span><br><span class="line">      consumer.join();</span><br><span class="line">    &#125; catch (InterruptedException e) &#123;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>一些优化点：</p>
<ol>
<li>注意<code>zrangeByScore</code>和<code>zrem</code>不是一个原子操作，可能会有多个线程争抢同一个 key，这可以通过 lua 脚本来优化。</li>
<li>使用 Redis 作为消息队列并不能保证 100%的可靠性，因为 rem 执行后如果客户端崩溃了消息就丢失了，或者 Redis 崩溃了消息也有可能丢失（这个可以通过主备来避免）。</li>
</ol>
<h2 id="阻塞队列"><a href="#阻塞队列" class="headerlink" title="阻塞队列"></a>阻塞队列</h2><p>使用Redis实现队列可以利用lpop&#x2F;rpush或rpop&#x2F;lpush，但是这两组命令在遇到队列为空或满时还是会直接返回，如果要实现阻塞队列的阻塞等待能力，可以：<br>1、使用lua脚本轮询<br>lua脚本中先检测队列是否为空&#x2F;满，在不空&#x2F;不满的情况下才执行后续的操作。<br>如果为空&#x2F;满，则客户端先等待一会再执行一次该lua脚本。<br>缺点是会有很多空轮询。<br>2、使用blpop命令<br>在list结构尚不存在元素的情况下，blpop命令会先将客户端挂起，等待：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">void blockForKeys(redisClient *c, robj **keys, int numkeys, mstime_t timeout, robj *target) &#123;</span><br><span class="line">    </span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">    // 关联阻塞客户端和键的相关信息</span><br><span class="line">    for (j = 0; j &lt; numkeys; j++) &#123;</span><br><span class="line"></span><br><span class="line">        /* If the key already exists in the dict ignore it. */</span><br><span class="line">        // c-&gt;bpop.keys 是一个集合（值为 NULL 的字典）</span><br><span class="line">        // 它记录所有造成客户端阻塞的键</span><br><span class="line">        // 以下语句在键不存在于集合的时候，将它添加到集合</span><br><span class="line">        if (dictAdd(c-&gt;bpop.keys,keys[j],NULL) != DICT_OK) continue;</span><br><span class="line"></span><br><span class="line">        incrRefCount(keys[j]);</span><br><span class="line"></span><br><span class="line">        /* And in the other &quot;side&quot;, to map keys -&gt; clients */</span><br><span class="line">        // c-&gt;db-&gt;blocking_keys 字典的键为造成客户端阻塞的键</span><br><span class="line">        // 而值则是一个链表，链表中包含了所有被阻塞的客户端</span><br><span class="line">        // 以下程序将阻塞键和被阻塞客户端关联起来</span><br><span class="line">        de = dictFind(c-&gt;db-&gt;blocking_keys,keys[j]);</span><br><span class="line">        if (de == NULL) &#123;</span><br><span class="line">            // 链表不存在，新创建一个，并将它关联到字典中</span><br><span class="line">            int retval;</span><br><span class="line"></span><br><span class="line">            /* For every key we take a list of clients blocked for it */</span><br><span class="line">            l = listCreate();</span><br><span class="line">            retval = dictAdd(c-&gt;db-&gt;blocking_keys,keys[j],l);</span><br><span class="line">            incrRefCount(keys[j]);</span><br><span class="line">            redisAssertWithInfo(c,keys[j],retval == DICT_OK);</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            l = dictGetVal(de);</span><br><span class="line">        &#125;</span><br><span class="line">        // 将客户端填接到被阻塞客户端的链表中</span><br><span class="line">        listAddNodeTail(l,c);</span><br><span class="line">    &#125;</span><br><span class="line">    blockClient(c,REDIS_BLOCKED_LIST);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行指令结束后，处理解除了阻塞的键。<br><code>redis.c</code>：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">int processCommand(redisClient *c) &#123;</span><br><span class="line"></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">    /* Exec the command */</span><br><span class="line">    if (c-&gt;flags &amp; REDIS_MULTI &amp;&amp;</span><br><span class="line">        c-&gt;cmd-&gt;proc != execCommand &amp;&amp; c-&gt;cmd-&gt;proc != discardCommand &amp;&amp;</span><br><span class="line">        c-&gt;cmd-&gt;proc != multiCommand &amp;&amp; c-&gt;cmd-&gt;proc != watchCommand)</span><br><span class="line">    &#123;</span><br><span class="line">        // 在事务上下文中</span><br><span class="line">        // 除 EXEC 、 DISCARD 、 MULTI 和 WATCH 命令之外</span><br><span class="line">        // 其他所有命令都会被入队到事务队列中</span><br><span class="line">        queueMultiCommand(c);</span><br><span class="line">        addReply(c,shared.queued);</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        // 执行命令</span><br><span class="line">        call(c,REDIS_CALL_FULL);</span><br><span class="line"></span><br><span class="line">        c-&gt;woff = server.master_repl_offset;</span><br><span class="line">        // 处理那些解除了阻塞的键</span><br><span class="line">        if (listLength(server.ready_keys))</span><br><span class="line">            handleClientsBlockedOnLists();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    return REDIS_OK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以看到，执行命令的末尾需要处理解除了阻塞的键，遍历这些键然后唤醒等待的客户端。<br><code>t_list.c</code>：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br></pre></td><td class="code"><pre><span class="line">/* 这个函数会在 Redis 每次执行完单个命令、事务块或 Lua 脚本之后调用。</span><br><span class="line"> *</span><br><span class="line"> * 对所有被阻塞在某个客户端的 key 来说，只要这个 key 被执行了某种 PUSH 操作</span><br><span class="line"> * 那么这个 key 就会被放到 serve.ready_keys 去。</span><br><span class="line"> * </span><br><span class="line"> * 这个函数会遍历整个 serve.ready_keys 链表，</span><br><span class="line"> * 并将里面的 key 的元素弹出给被阻塞客户端，</span><br><span class="line"> * 从而解除客户端的阻塞状态。</span><br><span class="line"> *</span><br><span class="line"> * 函数会一次又一次地进行迭代，</span><br><span class="line"> * 因此它在执行 BRPOPLPUSH 命令的情况下也可以正常获取到正确的新被阻塞客户端。</span><br><span class="line"> */</span><br><span class="line">void handleClientsBlockedOnLists(void) &#123;</span><br><span class="line"></span><br><span class="line">    // 遍历整个 ready_keys 链表</span><br><span class="line">    while(listLength(server.ready_keys) != 0) &#123;</span><br><span class="line">        list *l;</span><br><span class="line"></span><br><span class="line">        /* Point server.ready_keys to a fresh list and save the current one</span><br><span class="line">         * locally. This way as we run the old list we are free to call</span><br><span class="line">         * signalListAsReady() that may push new elements in server.ready_keys</span><br><span class="line">         * when handling clients blocked into BRPOPLPUSH. */</span><br><span class="line">        // 备份旧的 ready_keys ，再给服务器端赋值一个新的</span><br><span class="line">        l = server.ready_keys;</span><br><span class="line">        server.ready_keys = listCreate();</span><br><span class="line"></span><br><span class="line">        while(listLength(l) != 0) &#123;</span><br><span class="line"></span><br><span class="line">            // 取出 ready_keys 中的首个链表节点</span><br><span class="line">            listNode *ln = listFirst(l);</span><br><span class="line"></span><br><span class="line">            // 指向 readyList 结构</span><br><span class="line">            readyList *rl = ln-&gt;value;</span><br><span class="line"></span><br><span class="line">            /* First of all remove this key from db-&gt;ready_keys so that</span><br><span class="line">             * we can safely call signalListAsReady() against this key. */</span><br><span class="line">            // 从 ready_keys 中移除就绪的 key</span><br><span class="line">            dictDelete(rl-&gt;db-&gt;ready_keys,rl-&gt;key);</span><br><span class="line"></span><br><span class="line">            /* If the key exists and it&#x27;s a list, serve blocked clients</span><br><span class="line">             * with data. */</span><br><span class="line">            // 获取键对象，这个对象应该是非空的，并且是列表</span><br><span class="line">            robj *o = lookupKeyWrite(rl-&gt;db,rl-&gt;key);</span><br><span class="line">            if (o != NULL &amp;&amp; o-&gt;type == REDIS_LIST) &#123;</span><br><span class="line">                dictEntry *de;</span><br><span class="line"></span><br><span class="line">                /* We serve clients in the same order they blocked for</span><br><span class="line">                 * this key, from the first blocked to the last. */</span><br><span class="line">                // 取出所有被这个 key 阻塞的客户端</span><br><span class="line">                de = dictFind(rl-&gt;db-&gt;blocking_keys,rl-&gt;key);</span><br><span class="line">                if (de) &#123;</span><br><span class="line">                    list *clients = dictGetVal(de);</span><br><span class="line">                    int numclients = listLength(clients);</span><br><span class="line"></span><br><span class="line">                    while(numclients--) &#123;</span><br><span class="line">                        // 取出客户端</span><br><span class="line">                        listNode *clientnode = listFirst(clients);</span><br><span class="line">                        redisClient *receiver = clientnode-&gt;value;</span><br><span class="line"></span><br><span class="line">                        // 设置弹出的目标对象（只在 BRPOPLPUSH 时使用）</span><br><span class="line">                        robj *dstkey = receiver-&gt;bpop.target;</span><br><span class="line"></span><br><span class="line">                        // 从列表中弹出元素</span><br><span class="line">                        // 弹出的位置取决于是执行 BLPOP 还是 BRPOP 或者 BRPOPLPUSH</span><br><span class="line">                        int where = (receiver-&gt;lastcmd &amp;&amp;</span><br><span class="line">                                     receiver-&gt;lastcmd-&gt;proc == blpopCommand) ?</span><br><span class="line">                                    REDIS_HEAD : REDIS_TAIL;</span><br><span class="line">                        robj *value = listTypePop(o,where);</span><br><span class="line"></span><br><span class="line">                        // 还有元素可弹出（非 NULL）</span><br><span class="line">                        if (value) &#123;</span><br><span class="line">                            /* Protect receiver-&gt;bpop.target, that will be</span><br><span class="line">                             * freed by the next unblockClient()</span><br><span class="line">                             * call. */</span><br><span class="line">                            if (dstkey) incrRefCount(dstkey);</span><br><span class="line"></span><br><span class="line">                            // 取消客户端的阻塞状态</span><br><span class="line">                            unblockClient(receiver);</span><br><span class="line"></span><br><span class="line">                            // 将值 value 推入到造成客户端 receiver 阻塞的 key 上</span><br><span class="line">                            if (serveClientBlockedOnList(receiver,</span><br><span class="line">                                rl-&gt;key,dstkey,rl-&gt;db,value,</span><br><span class="line">                                where) == REDIS_ERR)</span><br><span class="line">                            &#123;</span><br><span class="line">                                /* If we failed serving the client we need</span><br><span class="line">                                 * to also undo the POP operation. */</span><br><span class="line">                                    listTypePush(o,value,where);</span><br><span class="line">                            &#125;</span><br><span class="line"></span><br><span class="line">                            if (dstkey) decrRefCount(dstkey);</span><br><span class="line">                            decrRefCount(value);</span><br><span class="line">                        &#125; else &#123;</span><br><span class="line">                            // 如果执行到这里，表示还有至少一个客户端被键所阻塞</span><br><span class="line">                            // 这些客户端要等待对键的下次 PUSH</span><br><span class="line">                            break;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                </span><br><span class="line">                // 如果列表元素已经为空，那么从数据库中将它删除</span><br><span class="line">                if (listTypeLength(o) == 0) dbDelete(rl-&gt;db,rl-&gt;key);</span><br><span class="line">                /* We don&#x27;t call signalModifiedKey() as it was already called</span><br><span class="line">                 * when an element was pushed on the list. */</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            /* Free this item. */</span><br><span class="line">            decrRefCount(rl-&gt;key);</span><br><span class="line">            zfree(rl);</span><br><span class="line">            listDelNode(l,ln);</span><br><span class="line">        &#125;</span><br><span class="line">        listRelease(l); /* We have the new list on place at this point. */</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h2 id="位图"><a href="#位图" class="headerlink" title="位图"></a>位图</h2><h3 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h3><p>位图数据结构与 java 中的 Set 类似，占用空间小，但是并不能防止冲突，适合数据离散性比较大且对数据准确性不高的场景。</p>
<ol>
<li>统计月活<br>统计月活的时候我们需要对 userId 进行去重，每个用户就可以定位到这个位图上的一个确定的位置上，0 表示不活跃，1 表示活跃，遍历一次就可以知道月活用户数有多少。</li>
</ol>
<h3 id="使用-1"><a href="#使用-1" class="headerlink" title="使用"></a>使用</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">set s a</span><br><span class="line">getbit s 2</span><br><span class="line">setbit s 6 1</span><br><span class="line">get s</span><br></pre></td></tr></table></figure>
<p>注意下标并不是从低位到高位递增的，而是反过来的，a 的 ASCII 码值是<code>01100001</code>，<code>setbit s 6 1</code>设置第 7 位为 1 后值就变成了 c。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">// 指定范围内1的个数</span><br><span class="line">bitcount s 0 7</span><br><span class="line">// 第一个1的位置</span><br><span class="line">bitpos s 1</span><br><span class="line">// 下标0到7范围内第一个1的位置</span><br><span class="line">bitpos s 1 0 7</span><br></pre></td></tr></table></figure>
<p>比如用位数组记录用户登录的日期，bitcount 可以用于统计用户一共签到了多少天，bitpos 可以用于查找用户从哪一天开始第一次签到。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">// 从第一个位（0）开始取4个位，结果是无符号数（u）</span><br><span class="line">bitfield s get u4 0</span><br><span class="line">// 从第三个位（2）开始取3个位，结果是有符号数（i）</span><br><span class="line">bitfield s get i3 2</span><br><span class="line">// 一次性执行多个子命令</span><br><span class="line">bitfield s get u4 0 get u3 2 get i4 0 get i3 2</span><br></pre></td></tr></table></figure>
<p>如果 s 的值是 c，二进制值是<code>0110 0011</code>，取前 4 位结果是 6（0110）。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">// +1，结果为0，因为溢出了</span><br><span class="line">bitfield s incrby u2 1 1</span><br><span class="line">// 不执行，返回nil</span><br><span class="line">bitfield s overflow fail incrby u2 1 1</span><br><span class="line">// 结果为3</span><br><span class="line">bitfield s overflow sat incrby u2 1 1</span><br></pre></td></tr></table></figure>
<p>位的增加操作有 3 种策略：</p>
<ol>
<li>默认的 wrap：</li>
<li>fail：失败报错不执行</li>
<li>sat：饱和截断，如果有溢出就停留在最大最小值。</li>
</ol>
<h2 id="HyperLogLog"><a href="#HyperLogLog" class="headerlink" title="HyperLogLog"></a>HyperLogLog</h2><p>HyperLogLog 主要用于大数据量的计数，比如访问频繁的页面需要统计 UV（一天内访问的用户数），不同于 PV，UV 需要去重。<br>HyperLogLog 只能粗略统计，理论上会有不到 1%的误差。</p>
<h3 id="使用-2"><a href="#使用-2" class="headerlink" title="使用"></a>使用</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">pfadd s user1</span><br><span class="line">pfcount s</span><br><span class="line">pfadd s user1</span><br><span class="line">pfadd s user2</span><br><span class="line">// 结果仍然为2</span><br><span class="line">pfcount s</span><br><span class="line">// 将两个计数器累加</span><br><span class="line">pfmerge s b</span><br></pre></td></tr></table></figure>


<h2 id="布隆过滤器"><a href="#布隆过滤器" class="headerlink" title="布隆过滤器"></a>布隆过滤器</h2><p>HyperLogLog 可以用于计数，但是不能用于判断一个值是否存在于该结构里，这时最好使用布隆过滤器（Bloom Filter）：</p>
<ol>
<li>去重；</li>
<li>支持 contains 判断；</li>
<li>节省空间；</li>
<li>不精确，存在误判的可能（当布隆过滤器说某个值存在时，这个值可能不存在，当它说不存在时，那就肯定不存在，这个问题是由 hash 函数的冲突引起的）；</li>
<li>不支持计数。</li>
</ol>
<h3 id="使用-3"><a href="#使用-3" class="headerlink" title="使用"></a>使用</h3><p>插入值并且判断该值是否存在于 bf 对象内：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">bf.add s user1</span><br><span class="line">bf.add s user2</span><br><span class="line">bf.madd s user3 user4</span><br><span class="line">bf.exists s user1</span><br><span class="line">bf.mexists s user1 user5</span><br></pre></td></tr></table></figure>
<p>第一次 bf.add 会创建一个默认参数的布隆过滤器，也可以显式创建：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">// 创建一个名为key的布隆过滤器，错误率0.1，预计放入的元素数量为10</span><br><span class="line">bf.reserve key 0.1 10</span><br></pre></td></tr></table></figure>
<ul>
<li>错误率越低，需要的空间越大，默认值为 0.01<br>对于不需要非常精确的场合，错误率设置得稍大一点也无伤大雅。</li>
<li>当实际数量超出预计放入数量时，误判率会上升，默认值为 100<br>该值设置得过大，会浪费存储空间，估计得过小，就会影响准确率，最理想的情况下是略大于实际元素数量。</li>
</ul>
<p>当实际元素数超出初始化大小时，应该对布隆过滤器进行重建，重新分配一个 size 更大的过滤器，再将所有的历史元素批量 add 进去（比如如果布隆过滤器保存的是 userId，那么就需要把历史 userId 重新保存到一个新的布隆过滤器中）。</p>
<h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><p>布隆过滤器本身是一个大型的位数组和几个不同的无偏 hash 函数。</p>
<blockquote>
<p>无偏指的是该 hash 函数能把值分布得比较均匀。</p>
</blockquote>
<ul>
<li>add：使用这些 hash 函数计算 hash(key)%length(bit_arr)，每个 hash 函数都可以得到一个位置，将这些位置置为 1；</li>
<li>exists：同样用这些 hash 函数计算位置，如果有一个不为 1 说明 key 不存在，如果都为 1 也不一定说明 key 一定存在，因为这些位置可能会被其他 key 设置到。</li>
</ul>
<h2 id="GeoHash"><a href="#GeoHash" class="headerlink" title="GeoHash"></a>GeoHash</h2><h3 id="一种简单的方法"><a href="#一种简单的方法" class="headerlink" title="一种简单的方法"></a>一种简单的方法</h3><p>找一个节点附近的所有节点，可以近似看做以该节点为中心的一个矩形范围内有哪些节点，可以用类似下面的 SQL 来查询：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select id from positions where x0-r &lt; x &lt; x0+r and y0-r &lt; y &lt; y0+r</span><br></pre></td></tr></table></figure>
<p>对 x 和 y 字段加索引后该 SQL 的性能也不会太差。</p>
<h3 id="GeoHash-1"><a href="#GeoHash-1" class="headerlink" title="GeoHash"></a>GeoHash</h3><p>GeoHash 的基本思想是“降维”，将二维坐标映射到直线上的一个点，要寻找二维平面上的“附近的人”就相当于在直线上找相邻的点。<br>GeoHash 本质是一个 zset（带 score 的 set），底层结构是 skiplist：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">geoadd company 116.489033 40.007669 meituan</span><br><span class="line">geoadd company 116.562108 39.787602 jd 116.334255 40.027400 xiaomi</span><br><span class="line">// geoadd指令添加一个节点，因为geo存储结构上使用的是zset，因此可以使用zset相关的指令来操作，比如可以使用zrem指令来删除</span><br><span class="line">zrem company jd</span><br><span class="line">geoadd company 116.562108 39.787602 jd</span><br><span class="line">// 计算两个节点之间的距离</span><br><span class="line">geodist company meituan jd</span><br><span class="line">// 单位km</span><br><span class="line">geodist company meituan jd km</span><br><span class="line">// 获取节点位置</span><br><span class="line">geopos company meituan jd</span><br><span class="line">// 获取元素的hash值</span><br><span class="line">geohash company meituan</span><br><span class="line">// 查询指定元素附近的其他元素</span><br><span class="line">// 范围20公里内最多3个元素按距离正序排列，</span><br><span class="line">georadiusbymember company meituan 20 km count 3 asc</span><br></pre></td></tr></table></figure>

<p>GeoHash 算法的执行流程如下：</p>
<ol>
<li>将坐标编码为一个 52 位整数，这个整数也可以还原为原坐标；</li>
<li>zset 的 value 是元素的 key（即上面的 meituan、jd 等），score 是 GeoHash 的 52 位整数值，通过 zset 的 score 排序即可得到坐标附近的其它元素。</li>
</ol>
<p>其中主要问题是坐标是如何编码的，编码后为什么可以通过比较大小来判断是否相邻？<br>GeoHash 算法的原理是按经纬度区间对半分来进行编码，比如，维度的区间是<code>(-90, 90)</code>，如果坐标的维度值大于 0，则记 1，否则记 0，进一步的，如果坐标维度大于 45，则记 1，否则记 0，以此类推，对于<code>39.918118</code>来说，最后的编码值就是<code>10111000110001011011</code>。</p>
<blockquote>
<p>一般实现中还会进行 BASE64 编码，本质是一样的，只是编码后占用的空间更小了。</p>
</blockquote>
<h2 id="Scan"><a href="#Scan" class="headerlink" title="Scan"></a>Scan</h2><p>扫描大量 key 找到目标 key 的需求有两种实现方法：</p>
<ol>
<li>keys 命令<br>不支持分页，一次性吐出所有满足条件的 key，如果数据量过大、耗时过长，可能导致服务端卡顿。<blockquote>
<p>因为 Redis 是单线程模型。</p>
</blockquote>
</li>
<li>scan<br>和 keys 命令一样提供模式匹配，但它是通过游标扫描的，每次只扫描指定数量的数据，并将其中匹配的结果返回。</li>
</ol>
<h3 id="使用-4"><a href="#使用-4" class="headerlink" title="使用"></a>使用</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># 从cursor=0开始，匹配&quot;key99*&quot;，共扫描1000条</span><br><span class="line">scan 0 match key99* count 1000</span><br><span class="line">1) &quot;11928&quot;</span><br><span class="line">2)  1) &quot;key9956&quot;</span><br><span class="line">    2) &quot;key9993&quot;</span><br><span class="line">    3) &quot;key9911&quot;</span><br><span class="line">    4) &quot;key996&quot;</span><br><span class="line">    5) &quot;key9933&quot;</span><br><span class="line">    6) &quot;key9962&quot;</span><br><span class="line">    7) &quot;key991&quot;</span><br><span class="line">    8) &quot;key9981&quot;</span><br><span class="line">    9) &quot;key9990&quot;</span><br><span class="line">   10) &quot;key9946&quot;</span><br><span class="line">   11) &quot;key9971&quot;</span><br><span class="line">   12) &quot;key99&quot;</span><br><span class="line">   13) &quot;key9951&quot;</span><br></pre></td></tr></table></figure>
<p>返回值中，第一个”11928”是结果中最后一条的 cursor，下一次遍历时可以使用该值作为初始 cursor。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scan 11928 match key99* count 10</span><br><span class="line">1) &quot;3480&quot;</span><br><span class="line">2) (empty list or set)</span><br></pre></td></tr></table></figure>
<p>结果为空集合并不意味着遍历结束了，只有 cursor&#x3D;0 才是遍历结束的标识。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">scan 11928 match key99* count 10000</span><br><span class="line">1) &quot;0&quot;</span><br><span class="line">2)  1) &quot;key9952&quot;</span><br><span class="line">    2) &quot;key9961&quot;</span><br><span class="line">    3) &quot;key9988&quot;</span><br><span class="line">    4) &quot;key9931&quot;</span><br><span class="line">    5) &quot;key9998&quot;</span><br><span class="line">    ...忽略更多的</span><br></pre></td></tr></table></figure>
<h3 id="原理-1"><a href="#原理-1" class="headerlink" title="原理"></a>原理</h3><p>Redis 中所有 key 都存储在一个非常大的字典中，这个字典的结构和 Java 的 HashMap 类似：<br><img src="/imgs/Redis/Redis-%E5%AD%97%E5%85%B8.png" alt="Redis-字典" title="Redis-字典"></p>
<ol>
<li>一维数组大小为 2^n（n &gt;&#x3D; 0），扩容一次大小翻倍，保存的是所有 key 的下标，或者称为槽（slot）；</li>
<li>二维链表保存的是所有的 key，不同 key 是有可能被 hash 到同一个槽上的，这时这个槽里所有元素都会被模式匹配过滤后一次性返回。</li>
</ol>
<p>scan 的遍历并不是从 0 开始递增，而是通过二进制高位进位加法来遍历，比如遍历顺序：</p>
<ol>
<li>0000 -&gt; 0</li>
<li>1000 -&gt; 8</li>
<li>0100 -&gt; 4</li>
<li>1100 -&gt; 12</li>
<li>以此类推</li>
</ol>
<p><img src="/imgs/Redis/Redis-%E9%AB%98%E4%BD%8D%E9%80%92%E5%A2%9E%E9%81%8D%E5%8E%86.png" alt="Redis-高位递增遍历" title="Redis-高位递增遍历"><br>这种遍历方式的好处是可以避免扩容缩容后相同元素被反复遍历到。<br>因为槽数组的长度总是 2 的 n 次方，因此取模运算等价于位与操作，比如原来数组长度为 8，15（1111）会被 hash 到 7 号槽，而扩容后数组长度变成 16，增加了一个高位的 1，15（1111）会被 hash 到 15 号槽。<br>因此从低到高的遍历方式可能会导致重复遍历，而从高到低的方式则可以避免。</p>
<p>Redis 的 rehash 是渐进式的，在 rehash 的过程中，操作需要同时访问新旧的两个数组结构，如果旧的找不到就需要再到新的下面去找，scan 同理。</p>
<h3 id="大-key-问题"><a href="#大-key-问题" class="headerlink" title="大 key 问题"></a>大 key 问题</h3><p>大 key 会导致数据迁移和扩容时需要分配更大的一块内存空间，导致卡顿，删除时，同样需要一次性回收大 key，卡顿会再一次产生。<br>为了定位大 key，可以使用 redis-cli 的扫描功能</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -h 127.0.0.1 -p 7001 –-bigkeys</span><br><span class="line"># 如果担心这个指令会大幅抬升 Redis 的 ops 导致线上报警，还可以增加一个休眠参数</span><br><span class="line"># 每隔100条scan指令就会休眠0.1s</span><br><span class="line">redis-cli -h 127.0.0.1 -p 7001 –-bigkeys -i 0.1</span><br></pre></td></tr></table></figure>


<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kity@2.0.4/dist/kity.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text/javascript" src="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.6.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.6.0/dist/mindmap.min.css">
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/3a140985.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="tallate">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Tallate">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/3a140985.html" class="post-title-link" itemprop="url">并发和同步策略</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2019-09-24 23:54:49" itemprop="dateCreated datePublished" datetime="2019-09-24T23:54:49+08:00">2019-09-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-07-07 01:56:20" itemprop="dateModified" datetime="2025-07-07T01:56:20+08:00">2025-07-07</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Java/" itemprop="url" rel="index"><span itemprop="name">Java</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>通过操作 Thread、Object 的 API 和内置锁我们可以解决大部分的线程协调问题，但这绝不是最优雅的方式，接下来我们就来见识一下 JUC 中的各种高效线程同步工具。</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/3a140985.html#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/3b3d260d.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="tallate">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Tallate">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/3b3d260d.html" class="post-title-link" itemprop="url">并发和中间件</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2019-09-22 21:07:49" itemprop="dateCreated datePublished" datetime="2019-09-22T21:07:49+08:00">2019-09-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-07-07 01:56:20" itemprop="dateModified" datetime="2025-07-07T01:56:20+08:00">2025-07-07</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Java/" itemprop="url" rel="index"><span itemprop="name">Java</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <span id="more"></span>


<h2 id="RPC"><a href="#RPC" class="headerlink" title="RPC"></a>RPC</h2><h3 id="客户端-OR-服务端-异步"><a href="#客户端-OR-服务端-异步" class="headerlink" title="客户端 OR 服务端 异步"></a>客户端 OR 服务端 异步</h3><p>客户端异步比较常见，因为任何网络调用基本都可以方便地包装成异步调用，朴实无华且枯燥，下载这段代码是一个简单的 demo：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">public class ClientAsync &#123;</span><br><span class="line"></span><br><span class="line">    private static class ClientAsyncExecutor &#123;</span><br><span class="line"></span><br><span class="line">        private ExecutorService threadPool;</span><br><span class="line">        private Supplier&lt;String&gt; dataSupplier;</span><br><span class="line">        private Consumer&lt;String&gt; callback;</span><br><span class="line"></span><br><span class="line">        public ClientAsyncExecutor(ExecutorService threadPool,</span><br><span class="line">                Supplier&lt;String&gt; dataSupplier,</span><br><span class="line">                Consumer&lt;String&gt; callback) &#123;</span><br><span class="line">            this.threadPool = threadPool;</span><br><span class="line">            this.dataSupplier = dataSupplier;</span><br><span class="line">            this.callback = callback;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        public void call() &#123;</span><br><span class="line">            threadPool.submit(() -&gt; &#123;</span><br><span class="line">                String data = dataSupplier.get();</span><br><span class="line">                callback.accept(data);</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) throws InterruptedException &#123;</span><br><span class="line">        ExecutorService threadPool = Executors.newCachedThreadPool();</span><br><span class="line">        ClientAsyncExecutor executor = new ClientAsyncExecutor(</span><br><span class="line">                threadPool,</span><br><span class="line">                () -&gt; &#123;</span><br><span class="line">                    try &#123;</span><br><span class="line">                        Thread.sleep(3000);</span><br><span class="line">                    &#125; catch (InterruptedException e) &#123;</span><br><span class="line">                        e.printStackTrace();</span><br><span class="line">                    &#125;</span><br><span class="line">                    return &quot;done&quot;;</span><br><span class="line">                &#125;,</span><br><span class="line">                res -&gt; System.out.println(&quot;结果：&quot; + res));</span><br><span class="line">        executor.call();</span><br><span class="line">        System.out.println(&quot;call returned&quot;);</span><br><span class="line">        threadPool.shutdown();</span><br><span class="line">        threadPool.awaitTermination(10000, TimeUnit.SECONDS);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>客户端异步是一种伪异步，本质上仍是同步调用，只不过等待是放到另外一个线程中去做的，如果这样等待的线程比较多，对客户端的线程池容易造成压力，。<br>服务端的异步实现起来就比较费劲了，因为客户端需要额外提供一个入口来接收服务端执行完毕的结果：<br><img src="/imgs/%E5%B9%B6%E5%8F%91/%E6%9C%8D%E5%8A%A1%E7%AB%AF%E5%BC%82%E6%AD%A5.png" alt="服务端异步" title="服务端异步"></p>
<h3 id="良好习惯"><a href="#良好习惯" class="headerlink" title="良好习惯"></a>良好习惯</h3><p>不论是桌面应用还是 Web 应用，多线程代码都是比较难玩得转的，玩不明白的结果就是一大堆令人毛骨悚然且难以捉摸、难以调试的问题——实际上，一旦你意识到正在处理一个并发问题，你可能就不得不完全放弃调试了，并转而手动检查代码。<br>鉴于此，我们当然是希望尽量避免并发问题的，理想情况下希望完全避免多线程错误，同样，不存在那种一刀切的方法，但这有一些调试和防止多线程错误的实际考虑因素：</p>
<ol>
<li>避免全局状态<br>首先，牢记 “全局状态” 问题。如果你正创建一个多线程应用，那么应该密切关注任何可能全局修改的内容，如果可能的话，将他们全部删掉，如果部分全局变量确实有理由保留，那么应该仔细保证其并发安全，并对程序性能进行跟踪，以确定不会因为引入新的等待时间而导致系统性能降低（并发修改时需要同步多个线程）。</li>
<li>避免可变性<br>这点直接来自于 函数式编程，并且适用于 OOP，声明应该避免类和对象状态的改变。简而言之，这意味着放弃 setter 方法，并在需要避免可变性的类或字段上拥有私有的 final 字段，它们的值唯一发生变化的时间是在构造期间。这样，你可以确定不会出现争用问题，且访问对象属性将始终提供正确的值。</li>
<li>日志及报警<br>评估你的程序可能会在何处发生异常，并预先记录所有关键数据。如果发生错误，你将很高兴可以得到信息说明收到了哪些请求，并可更好地了解你的应用程序为什么会出现错误。需要再次注意的是，日志记录引入了额外的文件 I&#x2F;O，可能会严重影响应用的性能，因此请不要滥用日志。<br>在记日志的基础上，有必要根据 SLA 记录一些指标的报警阈值，比如订单中心下单失败，考虑可能是网络出现抖动引起超时（如果用到三方服务这个问题会更明显），因此报警阈值可以稍微调高一些，比如 1 分钟 3 次失败就打电话报警。</li>
<li>复用现存实现<br>每当你需要创建自己的线程时（例如：向不同的服务发出异步请求），复用现有的安全实现来代替创建自己的解决方案。这在很大程度上意味着要使用 ExecutorService 和 Java 8 简洁的函数式 CompletableFuture 来创建线程。Spring 还允许通过 DeferredResult 类来进行异步请求处理。</li>
</ol>
<h3 id="反模式-异步狂热"><a href="#反模式-异步狂热" class="headerlink" title="反模式-异步狂热"></a>反模式-异步狂热</h3><p>上边我们已经讨论过异步存在的优势和劣势，实际上在我读过的项目代码中，确实存在不少那种不异步不开心的“炫技代码”，给维护带来很大困难。<br>下面是一个非常直观的方法：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">public String punch(People t) &#123;</span><br><span class="line">    return &quot;Oh, No&quot;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>经过一个莫名其妙的异步包装，原来的可扩展性、性能均没有提升，甚至性能成功降低了：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">public Function doPunch(People t) &#123;</span><br><span class="line">    return t -&gt; &#123;</span><br><span class="line">        return &quot;Oh, No&quot;;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public String punch(People t) &#123;</span><br><span class="line">    Function f = doPunch(t);</span><br><span class="line">    return f.apply(t);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>实际情况可能会复杂得多，这样的代码不够简单直观、容易暗藏 Bug、不符合 KISS 原则，但是即便如此，还是有很多人会觉得特别绕的代码能体现一个人的水平、对代码的驾驭能力、能灵活运用设计模式的能力，我觉得大部分情况下事实并非如此。</p>
<h2 id="Spring-DeferredResult"><a href="#Spring-DeferredResult" class="headerlink" title="Spring - DeferredResult"></a>Spring - DeferredResult</h2><p>TODO</p>
<h2 id="Hystrix-Command"><a href="#Hystrix-Command" class="headerlink" title="Hystrix - Command"></a>Hystrix - Command</h2><p>Hystrix 的 Command 框架在 CompletableFuture 的基础上提供了合并请求的特性：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line">public class BatchGetDataCommand extends HystrixCommand&lt;List&lt;Double&gt;&gt; &#123;</span><br><span class="line"></span><br><span class="line">    private Collection&lt;CollapsedRequest&lt;Double, Long&gt;&gt; requests;</span><br><span class="line"></span><br><span class="line">    public BatchGetDataCommand(Collection&lt;CollapsedRequest&lt;Double, Long&gt;&gt; requests) &#123;</span><br><span class="line">        super(Setter.withGroupKey(</span><br><span class="line">                HystrixCommandGroupKey.Factory.asKey(&quot;batchGetData&quot;)));</span><br><span class="line">        this.requests = requests;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    protected List&lt;Double&gt; run() throws Exception &#123;</span><br><span class="line">        // TODO: 做些批量查询操作，这里作为示范直接返回</span><br><span class="line">        return requests.stream()</span><br><span class="line">                .map(CollapsedRequest::getArgument)</span><br><span class="line">                .map(arg -&gt; (double) arg)</span><br><span class="line">                .collect(Collectors.toList());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public class SimpleGetDataCommand extends HystrixCollapser&lt;List&lt;Double&gt;, Double, Long&gt; &#123;</span><br><span class="line"></span><br><span class="line">    private Long id;</span><br><span class="line"></span><br><span class="line">    public SimpleGetDataCommand(Long id) &#123;</span><br><span class="line">        super(HystrixCollapser.Setter</span><br><span class="line">                .withCollapserKey(HystrixCollapserKey.Factory.asKey(&quot;getData&quot;))</span><br><span class="line">                .andCollapserPropertiesDefaults(HystrixCollapserProperties.Setter()</span><br><span class="line">                        .withMaxRequestsInBatch(2)</span><br><span class="line">                        .withTimerDelayInMilliseconds(5)</span><br><span class="line">                        // 允许缓存request的结果</span><br><span class="line">                        .withRequestCacheEnabled(true))</span><br><span class="line">                .andScope(Scope.REQUEST));</span><br><span class="line">        this.id = id;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public Long getRequestArgument() &#123;</span><br><span class="line">        return id;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    protected HystrixCommand&lt;List&lt;Double&gt;&gt; createCommand(Collection&lt;CollapsedRequest&lt;Double, Long&gt;&gt; collapsedRequests) &#123;</span><br><span class="line">        return new BatchGetDataCommand(collapsedRequests);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    protected void mapResponseToRequests(final List&lt;Double&gt; batchResponse, Collection&lt;CollapsedRequest&lt;Double, Long&gt;&gt; collapsedRequests) &#123;</span><br><span class="line">        final AtomicInteger count = new AtomicInteger();</span><br><span class="line">        collapsedRequests.forEach(request -&gt; &#123;</span><br><span class="line">            request.setResponse(</span><br><span class="line">                    batchResponse.get(count.getAndIncrement()));</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        HystrixRequestContext context = HystrixRequestContext.initializeContext();</span><br><span class="line">        try &#123;</span><br><span class="line">            // Hystrix内部将多个查询合并成一个</span><br><span class="line">            SimpleGetDataCommand command1 = new SimpleGetDataCommand(1L);</span><br><span class="line">            SimpleGetDataCommand command2 = new SimpleGetDataCommand(2L);</span><br><span class="line">            // 这里需要先使用queue而不是execute</span><br><span class="line">            Future&lt;Double&gt; f1 = command1.queue();</span><br><span class="line">            Future&lt;Double&gt; f2 = command2.queue();</span><br><span class="line">            System.out.println(f1.get());</span><br><span class="line">            System.out.println(f2.get());</span><br><span class="line">        &#125; catch (InterruptedException | ExecutionException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; finally &#123;</span><br><span class="line">            context.shutdown();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h2 id="任务调度"><a href="#任务调度" class="headerlink" title="任务调度"></a>任务调度</h2><h3 id="补偿执行"><a href="#补偿执行" class="headerlink" title="补偿执行"></a>补偿执行</h3><p>异常订单表，定时任务</p>
<h3 id="定时任务的实现"><a href="#定时任务的实现" class="headerlink" title="定时任务的实现"></a>定时任务的实现</h3><p>无分布式的，HashTimeWheelTimer<br>分布式情况下，可以先用 Redis，当复杂时再用 RabbitMQ 等消息队列中间件。</p>
<h3 id="消息-OR-定时任务"><a href="#消息-OR-定时任务" class="headerlink" title="消息 OR 定时任务"></a>消息 OR 定时任务</h3><p>很多异步实现的功能既可以通过消息实现又可以通过定时任务来实现，我经历过很多需要抉择的情况，甚至也碰到过对此都不大清楚的架构师，我认为对此没有唯一的答案，只能根据具体业务场景来分析，一些要点可供参考。</p>
<ul>
<li><p>分布式</p>
</li>
<li><p>并发安全</p>
</li>
<li><p>运维便利性<br>消息本质上是把任务暂存在队列服务里，统计某段时间内发生了什么、会发生什么就比较困难了，因为往往消息队列都会有自定义的数据格式，判断一条消息是否被消费往往得通过日志来判断。<br>定时任务一般都会有执行记录，什么时间会执行任务也可以直接用 cron 表达式计算出来，缺点是使用定时任务意味着需要自己维护很多东西，比如在数据库里维护一个队列保存消息，保存有创建时间、重试次数、重试时间等，失败 N 次后还需要存一份失败记录。</p>
</li>
</ul>
<p>以一个“通知拉取”的场景举例，A 系统需要从 B 系统拉取数据，但并不是定时地直接调 B 的接口，而是先由 B 通知 A 哪些数据发生了变更，然后由 A 去拉取这些数据的变更部分：</p>
<ul>
<li>如果使用消息队列来实现：</li>
<li>如果使用定时任务实现：</li>
</ul>
<h3 id="使用-Thread-实现任务调度"><a href="#使用-Thread-实现任务调度" class="headerlink" title="使用 Thread 实现任务调度"></a>使用 Thread 实现任务调度</h3><p>实现任务调度最简单的方式可以直接利用 Thread：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">BlockingQueue&lt;String&gt; queue = new ArrayBlockingQueue&lt;&gt;(10);</span><br><span class="line">Thread thread = new Thread(() -&gt; &#123;</span><br><span class="line">    while (true) &#123;</span><br><span class="line">        String task = &quot;&quot;;</span><br><span class="line">        try &#123;</span><br><span class="line">            task = queue.take();</span><br><span class="line">        &#125; catch (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(task);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br><span class="line">thread.start();</span><br><span class="line">queue.put(&quot;hello&quot;);</span><br></pre></td></tr></table></figure>
<h3 id="Timer"><a href="#Timer" class="headerlink" title="Timer"></a>Timer</h3><p>Timer 内部通过一个 TimerThread 来循环执行提交给 Timer 的任务，因此任务是<strong>串行的</strong>，前一个任务的延迟会影响后续的所有任务。<br>Timer 可以看做一种简化版的 ScheduledExecutor，下面是一种 Demo 实现：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">public class DemoTimer &#123;</span><br><span class="line">    private static ScheduledExecutorService timer = Executors.newScheduledThreadPool(1);</span><br><span class="line"></span><br><span class="line">    public static void setTimeout(final Runnable function, long time,</span><br><span class="line">                                  TimeUnit timeUnit, final Executor executor) &#123;</span><br><span class="line">        Preconditions.checkArgument(time &gt;= 0);</span><br><span class="line">        Preconditions.checkNotNull(function);</span><br><span class="line">        Preconditions.checkNotNull(timeUnit);</span><br><span class="line">        Preconditions.checkNotNull(executor);</span><br><span class="line">        timer.schedule(() -&gt; executor.execute(function), time, timeUnit);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="ScheduledExecutor"><a href="#ScheduledExecutor" class="headerlink" title="ScheduledExecutor"></a>ScheduledExecutor</h3><p>ScheduledExecutor 能提供一种更灵活的周期性任务处理功能，</p>
<h3 id="Quartz"><a href="#Quartz" class="headerlink" title="Quartz"></a>Quartz</h3><h3 id="Spring-Task"><a href="#Spring-Task" class="headerlink" title="Spring Task"></a>Spring Task</h3><h3 id="Quartz-集群版"><a href="#Quartz-集群版" class="headerlink" title="Quartz 集群版"></a>Quartz 集群版</h3><h3 id="tbschedule"><a href="#tbschedule" class="headerlink" title="tbschedule"></a>tbschedule</h3><h3 id="xxl-job"><a href="#xxl-job" class="headerlink" title="xxl-job"></a>xxl-job</h3><h3 id="Elastic-Job"><a href="#Elastic-Job" class="headerlink" title="Elastic-Job"></a>Elastic-Job</h3><p><img src="/imgs/%E5%B9%B6%E5%8F%91/Elastic-Job%E6%9E%B6%E6%9E%84.png" alt="Elastic-Job架构" title="Elastic-Job架构"><br>Elastic-Job 分为 Elastic-Job-Lite 和 Elastic-Job-Console 两个模块。Elastic-Job-Lite 实现了分布式任务调度、动态扩容缩容、任务分片、失效转移等功能。<br>如上图所示，Elastic-Job-Lite 采用去中心化的调度方式，由 Elastic-Job-Lite 的客户端定时自动触发任务调度，通过任务分片的概念实现服务器负载的动态扩容和缩容，并且使用 ZooKeeper 作为分布式任务调度的注册中心；当某任务实例崩溃后，自动失效转移，实现高可用。</p>
<h2 id="消息队列（MQ）原理"><a href="#消息队列（MQ）原理" class="headerlink" title="消息队列（MQ）原理"></a>消息队列（MQ）原理</h2><p>MQ 有很多优势，当我们选择 MQ 时，主要是为了：</p>
<ul>
<li>解耦……<br>比如 A 系统要将用户提交的数据推送到 B、C 两个系统的时候，最初的想法很有可能是直接用 http 或 rpc 调用实现。像这样的下游系统后来又会多出 D、E、F…，对 A 系统的压力就会越来越大，更复杂的场景中，数据通过接口传给其他系统有时候还要考虑重试、超时等一些异常情况。<br>这时，对 A 来说更好的方案是将消息发送给 mq，不管有哪个下游系统需要这个数据都可以直接订阅这个 subject。</li>
<li>异步<br>当请求比较复杂，而其中有部分数据没必要实时更新时，可以用 mq 实现异步化。比如取消订单后需要做订单状态的更新、对账、退款等操作，而其中只有状态的变更是有必要实时反馈给用户的，那么后续的所有操作就完全可以做成异步的。</li>
<li>削峰填谷<br>消息队列作为缓冲队列应对突发流量时，并不能使处理速度变快，而是使处理速度变平滑，从而不会因瞬时压力过大而压垮应用。<br>举个例子，比如我们的订单系统，在下单的时候就会往数据库写数据。但是数据库只能支撑每秒 1000 左右的并发写入，并发量再高就容易宕机。<br>低峰期的时候并发也就 100 多个，但是在高峰期时候，并发量会突然激增到 5000 以上，这个时候数据库肯定死了。<br>但是使用了 MQ 之后，情况就变了，消息被 MQ 保存起来了，然后系统就可以按照自己的消费能力来消费，比如每秒 1000 个数据，这样慢慢写入数据库，这样就不会打死数据库了。<br>如果没有用 MQ 的情况下，并发量高峰期的时候是有一个“顶峰”的，然后高峰期过后又是一个低并发的“谷”。<br>但是使用了 MQ 之后，限制消费消息的速度为 1000，但是这样一来，高峰期产生的数据势必会被积压在 MQ 中，高峰就被“削”掉了。<br>但是因为消息积压，在高峰期过后的一段时间内，消费消息的速度还是会维持在 1000QPS，直到消费完积压的消息,这就叫做“填谷”。</li>
</ul>
<h3 id="高可用"><a href="#高可用" class="headerlink" title="高可用"></a>高可用</h3><p>使用了 MQ 之后，我们肯定是希望 MQ 有高可用特性，因为不可能接受机器宕机了，就无法收发消息的情况。<br>这一块我们也是基于 RabbitMQ 这种经典的 MQ 来说明一下：<br>RabbitMQ 是比较有代表性的，因为是基于主从做高可用性的，我们就以他为例子讲解第一种 MQ 的高可用性怎么实现。<br>rabbitmq 有三种模式：单机模式，普通集群模式，镜像集群模式<br>单机模式<br>单机模式就是 demo 级别的，就是说只有一台机器部署了一个 RabbitMQ 程序。<br>这个会存在单点问题，宕机就玩完了，没什么高可用性可言。一般就是你本地启动了玩玩儿的，没人生产用单机模式。<br>普通集群模式<br>这个模式的意思就是在多台机器上启动多个 rabbitmq 实例。类似的 master-slave 模式一样。<br>但是创建的 queue，只会放在一个 master rabbtimq 实例上，其他实例都同步那个接收消息的 RabbitMQ 元数据。<br>在消费消息的时候，如果你连接到的 RabbitMQ 实例不是存放 Queue 数据的实例，这个时候 RabbitMQ 就会从存放 Queue 数据的实例上拉去数据，然后返回给客户端。<br>总的来说，这种方式有点麻烦，没有做到真正的分布式，每次消费者连接一个实例后拉取数据，如果连接到不是存放 queue 数据的实例，这个时候会造成额外的性能开销。如果从放 Queue 的实例拉取，会导致单实例性能瓶颈。<br>如果放 queue 的实例宕机了，会导致其他实例无法拉取数据，这个集群都无法消费消息了，没有做到真正的高可用。<br>所以这个事儿就比较尴尬了，这就没有什么所谓的高可用性可言了，这方案主要是提高吞吐量的，就是说让集群中多个节点来服务某个 queue 的读写操作。<br>镜像集群模式<br>镜像集群模式才是真正的 rabbitmq 的高可用模式，跟普通集群模式不一样的是：创建的 queue 无论元数据还是 queue 里的消息都会存在于多个实例上，<br>每次写消息到 queue 的时候，都会自动把消息到多个实例的 queue 里进行消息同步。<br>这样的话任何一个机器宕机了别的实例都可以用提供服务，这样就做到了真正的高可用了。<br>但是也存在着不好之处：</p>
<ul>
<li>性能开销过高，消息需要同步所有机器，会导致网络带宽压力和消耗很重</li>
<li>扩展性低：无法解决某个 queue 数据量特别大的情况，导致 queue 无法线性拓展。 就算加了机器，那个机器也会包含 queue 的所有数据，queue 的数据没有做到分布式存储。<br>对于 RabbitMQ 的高可用一般的做法都是开启镜像集群模式，这样起码来说做到了高可用，一个节点宕机了，其他节点可以继续提供服务。</li>
</ul>
<h3 id="高性能"><a href="#高性能" class="headerlink" title="高性能"></a>高性能</h3><ul>
<li>对于内存操作的线程分离，大部分中间件做法是将数据文件缓存与内存中，通过异步线程 flush 至硬盘</li>
<li>合理的存储引擎对应不同的服务场景 B+树，hash，LSM</li>
<li>对于消息队列，选取顺序读写磁盘的方式，可以高效的提升磁盘 IO 速度</li>
<li>顺序写磁盘可以带来足够的写入速度，其读取方式为二分查找 </li>
<li>对于 LSM 存储引擎，同样采用顺序写磁盘方式，牺牲一部分读性能从而获得更优越的写性能</li>
</ul>
<h3 id="消息队列如何选型"><a href="#消息队列如何选型" class="headerlink" title="消息队列如何选型"></a>消息队列如何选型</h3><h3 id="异步处理"><a href="#异步处理" class="headerlink" title="异步处理"></a>异步处理</h3><h3 id="延时消费"><a href="#延时消费" class="headerlink" title="延时消费"></a>延时消费</h3><h3 id="应用隔离（系统解耦）"><a href="#应用隔离（系统解耦）" class="headerlink" title="应用隔离（系统解耦）"></a>应用隔离（系统解耦）</h3><p>比如有两个主题的消息，其中 A 主题的消息特别多，别的消息就会来不及处理。<br>这种情况有点类似于服务治理中的隔离策略：一个服务出错不能影响别的服务不可用。一般会采用线程池、信号量来实现。<br>MQ 消息中的主题隔离</p>
<h3 id="数据同步"><a href="#数据同步" class="headerlink" title="数据同步"></a>数据同步</h3><blockquote>
<p>Canel 订阅数据库 binlog 可以实现数据库数据变更捕获，然后业务端订阅 Canel 进行业务处理，这种方式可以保证一致性，且不会有乱序问题。</p>
</blockquote>
<h3 id="数据异构"><a href="#数据异构" class="headerlink" title="数据异构"></a>数据异构</h3><h3 id="反模式-为了撇清关系所以使用-MQ-消息"><a href="#反模式-为了撇清关系所以使用-MQ-消息" class="headerlink" title="反模式-为了撇清关系所以使用 MQ 消息"></a>反模式-为了撇清关系所以使用 MQ 消息</h3><h3 id="反模式-为了解耦过度使用-MQ-消息"><a href="#反模式-为了解耦过度使用-MQ-消息" class="headerlink" title="反模式-为了解耦过度使用 MQ 消息"></a>反模式-为了解耦过度使用 MQ 消息</h3><h3 id="反模式-利用数据差异化来触发事件"><a href="#反模式-利用数据差异化来触发事件" class="headerlink" title="反模式-利用数据差异化来触发事件"></a>反模式-利用数据差异化来触发事件</h3><p>公司里有几位老员工基于 MQ 监听器组件开发了一套 MQ 客户端，这套 MQ 客户端的核心就是能通过修改数据来触发监听对应字段修改事件的监听器，这样可以避免定义一大堆主题，看起来似乎变简单了对吗？但是经过一段时间的维护发现情况并非如此，大量监听器不再根据主题来相互关联，而是数据中的一大堆字段，最开始的一批开发爽了，因为需要定义的主题少了，少了很多手动发消息的代码，但是后续维护的人就糟了，试想，每次希望修改某个字段的时候都需要把监听该字段修改事件的监听器都找一遍。<br>两条业务同时修改</p>
<h3 id="MQ-存在的缺陷"><a href="#MQ-存在的缺陷" class="headerlink" title="MQ 存在的缺陷"></a>MQ 存在的缺陷</h3><p>上边已经说过了优点，那么 mq 又有哪些缺点呢？</p>
<ul>
<li>系统可用性降低<br>上面的说解耦的场景，本来 A 系统的哥们要把系统关键数据发送给 B、C 系统的，现在突然加入一个 MQ，现在 BC 系统接收数据要通过 MQ 来接收。<br>万一 MQ 挂了怎么办？这就引出一个问题，加入了 MQ 之后，系统的可用性是不是就降低了？<br>因为多了一个风险因素：MQ 可能会挂掉。只要 MQ 挂了，数据没了，系统运行就不对了。</li>
<li>系统复杂度提高<br>本来我的系统通过接口调用一下就能完事的，但是加入一个 MQ 之后，需要考虑消息重复消费、消息丢失、甚至消息顺序性的问题<br>为了解决这些问题，又需要引入很多复杂的机制，这样一来是不是系统的复杂度提高了。</li>
<li>数据一致性问题<br>本来好好的，A 系统调用 BC 系统接口，如果 BC 系统出错了，会抛出异常，返回给 A 系统让 A 系统知道，这样的话就可以做回滚操作了<br>但是使用了 MQ 之后，A 系统发送完消息就完事了，认为成功了。而刚好 C 系统写数据库的时候失败了，但是 A 认为 C 已经成功了？这样一来数据就不一致了。</li>
</ul>
<h3 id="并发修改"><a href="#并发修改" class="headerlink" title="并发修改"></a>并发修改</h3><p>消息从发出到被消费会有一小段时间，这一段时间内数据可能会经过其他线程的多次修改，所以在消息消费方的编程中尤其需要注意并发修改的问题。<br>如果是同步操作——比如用户购买商品扣款的场景——需要在比较高并发的情况下才会出现并发问题，但是如果功能是基于消息实现的，由于消息消费具有不确定性，这种风险会被放大。<br><img src="/imgs/%E5%B9%B6%E5%8F%91/%E5%B9%B6%E5%8F%91%E6%89%A3%E6%AC%BE.png" alt="并发扣款" title="并发扣款"></p>
<ul>
<li>这些并发查询是在不同的站点实例 &#x2F; 服务实例上完成的，进程内互斥锁无法解决问题。</li>
<li>不确定性来自于很多方面，比如同一主题的消息可能被多个业务线的触发、被重试、被手动重发。</li>
</ul>
<p>解决这种不一致问题的解决办法一般是加锁，因为异步处理并没有直接被用户感知，因此对效率并没有特别高的要求，悲观锁或乐观锁都是可行的。</p>
<blockquote>
<p>悲观锁会牺牲一定的吞吐量，乐观锁实现起来比较有技巧性、且可能会和业务数据耦合。</p>
</blockquote>
<p>以乐观锁为例：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">// 查询订单，Order中包含了版本信息</span><br><span class="line">Order order = queryOrder();</span><br><span class="line">// 这里使用状态机校验订单状态</span><br><span class="line">if (isStatusInvalid(order)) &#123;</span><br><span class="line">    记一下日志</span><br><span class="line">    return ;</span><br><span class="line">&#125;</span><br><span class="line">// 扭转状态的同时也做了版本的校验，相当于一个原子操作，如果校验失败则抛出异常、交给外层MQ组件重试</span><br><span class="line">changeOrderStatus(order, targetStatus);</span><br></pre></td></tr></table></figure>

<h3 id="At-Least-Once（消息丢失）"><a href="#At-Least-Once（消息丢失）" class="headerlink" title="At-Least-Once（消息丢失）"></a>At-Least-Once（消息丢失）</h3><p>有很多情况可能发生 MQ 消息的丢失：</p>
<ul>
<li>生产者向 MQ 发送消息时，网络传输出现问题；</li>
<li>消息在 MQ 中存储时，发生磁盘故障等不可控问题；</li>
<li>消费者从 MQ 接收消息时，网络传输出现问题；</li>
</ul>
<p>一般 MQ 中间件都会保证<strong>At-Least-Once</strong>的消费，就需要避免消息丢失的情况，有两种方式可以解决这种情况：</p>
<p>事务方式：<br>在生产者发送消息之前，通过<code>channel.txSelect</code>开启一个事务，接着发送消息<br>如果消息没有成功被 RabbitMQ 接收到，生产者会收到异常，此时就可以进行事务回滚<code>channel.txRollback</code>然后重新发送。假如 RabbitMQ 收到了这个消息，就可以提交事务<code>channel.txCommit</code>。<br>但是这样一来，生产者的吞吐量和性能都会降低很多，现在一般不这么干。</p>
<p>另外一种方式就是通过 confirm 机制：<br>这个 confirm 模式是在生产者哪里设置的，就是每次写消息的时候会分配一个唯一的 id，然后 RabbitMQ 收到之后会回传一个 ack，告诉生产者这个消息 ok 了。<br>如果 rabbitmq 没有处理到这个消息，那么就回调一个 nack 的接口，这个时候生产者就可以重发。<br>事务机制和 cnofirm 机制最大的不同在于事务机制是同步的，提交一个事务之后会阻塞在那儿<br>但是 confirm 机制是异步的，发送一个消息之后就可以发送下一个消息，然后那个消息 rabbitmq 接收了之后会异步回调你一个接口通知你这个消息接收到了。<br>所以一般在生产者这块避免数据丢失，都是用 confirm 机制的。</p>
<p>Rabbitmq 弄丢了数据<br>RabbitMQ 集群也会弄丢消息，这个问题在官方文档的教程中也提到过，就是说在消息发送到 RabbitMQ 之后，默认是没有落地磁盘的，万一 RabbitMQ 宕机了，这个时候消息就丢失了。<br>所以为了解决这个问题，RabbitMQ 提供了一个持久化的机制，消息写入之后会持久化到磁盘<br>这样哪怕是宕机了，恢复之后也会自动恢复之前存储的数据，这样的机制可以确保消息不会丢失。<br>设置持久化有两个步骤：</p>
<ul>
<li>第一个是创建 queue 的时候将其设置为持久化的，这样就可以保证 rabbitmq 持久化 queue 的元数据，但是不会持久化 queue 里的数据</li>
<li>第二个是发送消息的时候将消息的 deliveryMode 设置为 2，就是将消息设置为持久化的，此时 rabbitmq 就会将消息持久化到磁盘上去。<br>但是这样一来可能会有人说：万一消息发送到 RabbitMQ 之后，还没来得及持久化到磁盘就挂掉了，数据也丢失了，怎么办？<br>对于这个问题，其实是配合上面的 confirm 机制一起来保证的，就是在消息持久化到磁盘之后才会给生产者发送 ack 消息。<br>万一真的遇到了那种极端的情况，生产者是可以感知到的，此时生产者可以通过重试发送消息给别的 RabbitMQ 节点<br>消费端弄丢了数据<br>RabbitMQ 消费端弄丢了数据的情况是这样的：在消费消息的时候，刚拿到消息，结果进程挂了，这个时候 RabbitMQ 就会认为你已经消费成功了，这条数据就丢了。<br>对于这个问题，要先说明一下 RabbitMQ 消费消息的机制：在消费者收到消息的时候，会发送一个 ack 给 RabbitMQ，告诉 RabbitMQ 这条消息被消费到了，这样 RabbitMQ 就会把消息删除。<br>但是默认情况下这个发送 ack 的操作是自动提交的，也就是说消费者一收到这个消息就会自动返回 ack 给 RabbitMQ，所以会出现丢消息的问题。<br>所以针对这个问题的解决方案就是：关闭 RabbitMQ 消费者的自动提交 ack,在消费者处理完这条消息之后再手动提交 ack。<br>这样即使遇到了上面的情况，RabbitMQ 也不会把这条消息删除，会在你程序重启之后，重新下发这条消息过来。</li>
</ul>
<h3 id="消息重复"><a href="#消息重复" class="headerlink" title="消息重复"></a>消息重复</h3><p>一般情况下 MQ 除了不保证消息的有序性外、还不保证消息不重复。<br>因为在「网络不可达」的情况下，MQ 不能确认消息接收方收到了消息必然会重试。重试除了本文讲的幂等处理外，还可以采用每个消息有唯一的 ID+去重表实现。</p>
<h3 id="消息的有序性"><a href="#消息的有序性" class="headerlink" title="消息的有序性"></a>消息的有序性</h3><p>因为 MQ 消息在服务器上是分区存储的，每个分区自己是有序的。分区被接收端消费的时候。一般也是多个接收端一起消费。中间的每个环节都是只能保证局部有序。如果想全局有序。就需要分区只有一个，并且接收端服务器是单点，而且一次只处理一个请求。<br>TODO: TCP 是怎么做的。</p>
<h3 id="消息积压"><a href="#消息积压" class="headerlink" title="消息积压"></a>消息积压</h3><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><h3 id="任务调度-1"><a href="#任务调度-1" class="headerlink" title="任务调度"></a>任务调度</h3><ol>
<li>cron<br><a target="_blank" rel="noopener" href="https://linuxtools-rst.readthedocs.io/zh_CN/latest/tool/crontab.html">crontab 定时任务</a></li>
<li><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/989298cf5314">中心化-去中心化调度设计</a><br>xxl-job 和 elastic-job 在设计上的本质区别是中心化还是去中心化。</li>
</ol>
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kity@2.0.4/dist/kity.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text/javascript" src="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.6.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.6.0/dist/mindmap.min.css">
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/a894e74e.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="tallate">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Tallate">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/a894e74e.html" class="post-title-link" itemprop="url">Disruptor 原理</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2019-09-22 15:26:49" itemprop="dateCreated datePublished" datetime="2019-09-22T15:26:49+08:00">2019-09-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-07-07 01:56:20" itemprop="dateModified" datetime="2025-07-07T01:56:20+08:00">2025-07-07</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Java/" itemprop="url" rel="index"><span itemprop="name">Java</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <span id="more"></span>


<h1 id="Disruptor-相对于传统方式（普通）的优点"><a href="#Disruptor-相对于传统方式（普通）的优点" class="headerlink" title="Disruptor 相对于传统方式（普通）的优点"></a>Disruptor 相对于传统方式（普通）的优点</h1><ol>
<li>无锁<br>相对 Lock 来说效率更高（线程不需要挂起，只涉及到一次内存交换速度快），但是同时会带来 ABA 问题，且多线程下竞争容易产生空转。</li>
<li>所有访问者都记录自己的序号的实现方式，允许多个生产者与多个消费者共享相同的数据结构。</li>
<li>在每个对象中都能跟踪序列号（ring buffer，claim Strategy，生产者和消费者），加上神奇的 cache line padding，就意味着没有为伪共享和非预期的竞争。</li>
</ol>
<h1 id="如何使用-Disruptor"><a href="#如何使用-Disruptor" class="headerlink" title="如何使用 Disruptor"></a>如何使用 Disruptor</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">public class LongEvent &#123;</span><br><span class="line"></span><br><span class="line">    private long value;</span><br><span class="line"></span><br><span class="line">    public void set(long value) &#123;</span><br><span class="line">        this.value = value;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public long getValue() &#123;</span><br><span class="line">        return this.value;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">public class LongEventFactory implements EventFactory&lt;LongEvent&gt; &#123;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public LongEvent newInstance() &#123;</span><br><span class="line">        return new LongEvent();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">public class LongEventHandler implements EventHandler&lt;LongEvent&gt; &#123;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void onEvent(LongEvent event, long sequence, boolean endOfBatch) throws Exception &#123;</span><br><span class="line">        System.out.println(&quot;Event:  &quot; + event.getValue() + &quot; sequence:+&quot; + sequence + &quot; endOfBatch:&quot; + endOfBatch);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">public class LongEventHandler implements EventHandler&lt;LongEvent&gt; &#123;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void onEvent(LongEvent event, long sequence, boolean endOfBatch) throws Exception &#123;</span><br><span class="line">        System.out.println(&quot;Event:  &quot; + event.getValue() + &quot; sequence:+&quot; + sequence + &quot; endOfBatch:&quot; + endOfBatch);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">public class LongEventProducer &#123;</span><br><span class="line"></span><br><span class="line">    private final RingBuffer&lt;LongEvent&gt; ringBuffer;</span><br><span class="line"></span><br><span class="line">    public LongEventProducer(RingBuffer&lt;LongEvent&gt; ringBuffer) &#123;</span><br><span class="line">        this.ringBuffer = ringBuffer;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public void onData(ByteBuffer bb) &#123;</span><br><span class="line">        // Grab the next sequence</span><br><span class="line">        long sequence = ringBuffer.next();</span><br><span class="line">        try &#123;</span><br><span class="line">            // Get the entry in the Disruptor</span><br><span class="line">            LongEvent event = ringBuffer.get(sequence);</span><br><span class="line">            // for the sequence Fill with data</span><br><span class="line">            event.set(bb.getLong(0));</span><br><span class="line">        &#125; finally &#123;</span><br><span class="line">            ringBuffer.publish(sequence);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">public class LongEventMain &#123;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        // Executor that will be used to construct new threads for consumers</span><br><span class="line">        Executor executor = Executors.newCachedThreadPool();</span><br><span class="line"></span><br><span class="line">        // The factory for the event</span><br><span class="line">        LongEventFactory factory = new LongEventFactory();</span><br><span class="line"></span><br><span class="line">        // Specify the size of the ring buffer, must be power of 2.</span><br><span class="line">        int bufferSize = 1024;</span><br><span class="line"></span><br><span class="line">        // Construct the Disruptor</span><br><span class="line">        Disruptor&lt;LongEvent&gt; disruptor = new Disruptor&lt;&gt;(factory, bufferSize, executor);</span><br><span class="line"></span><br><span class="line">        // Connect the handler</span><br><span class="line">        disruptor.handleEventsWith(new LongEventHandler());</span><br><span class="line"></span><br><span class="line">        // Start the Disruptor, starts all threads running</span><br><span class="line">        disruptor.start();</span><br><span class="line"></span><br><span class="line">        // Get the ring buffer from the Disruptor to be used for publishing.</span><br><span class="line">        RingBuffer&lt;LongEvent&gt; ringBuffer = disruptor.getRingBuffer();</span><br><span class="line"></span><br><span class="line">        LongEventProducer producer = new LongEventProducer(ringBuffer);</span><br><span class="line"></span><br><span class="line">        ByteBuffer bb = ByteBuffer.allocate(8);</span><br><span class="line">        for (long l = 0; true; l++) &#123;</span><br><span class="line">            bb.putLong(0, l);</span><br><span class="line">            producer.onData(bb);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h1 id="QA"><a href="#QA" class="headerlink" title="QA"></a>QA</h1><ol>
<li><a target="_blank" rel="noopener" href="http://ifeve.com/disruptor/">并发框架 Disruptor 译文</a></li>
</ol>
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kity@2.0.4/dist/kity.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text/javascript" src="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.6.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.6.0/dist/mindmap.min.css">
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/edd4cfac.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="tallate">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Tallate">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/edd4cfac.html" class="post-title-link" itemprop="url">Redis 复制</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2019-09-22 12:21:48" itemprop="dateCreated datePublished" datetime="2019-09-22T12:21:48+08:00">2019-09-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-07-07 01:56:20" itemprop="dateModified" datetime="2025-07-07T01:56:20+08:00">2025-07-07</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%BC%93%E5%AD%98/" itemprop="url" rel="index"><span itemprop="name">缓存</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <span id="more"></span>

<h2 id="使用主从复制"><a href="#使用主从复制" class="headerlink" title="使用主从复制"></a>使用主从复制</h2><ol>
<li>运行 Master<br>调整 Master 内存中保存的缓冲积压部分（replication backlog），以便执行部分重同步。 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 缓冲区越大，可断开连接再重连执行部分重同步的时间越长，缓冲区会在每次连接时分配。</span><br><span class="line">repl-backlog-size 1mb</span><br><span class="line">repl-backlog-ttl 3600</span><br></pre></td></tr></table></figure></li>
<li>运行 Slave<br>先在配置文件中设置 Master 和 logfile 路径再运行 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">slaveof 172.16.205.141 6379</span><br><span class="line">logfile &quot;/usr/redis/log/slave.log&quot;</span><br></pre></td></tr></table></figure></li>
<li>级联复制（从从复制）<br>之前是所有 Slave 连到一个 Master 上，这是一种中心化的办法，对 Master 的负担较大，事实上我们完全可以不全部连到 Master 上，而是 Master-&gt;Slave1-&gt;Slave2 这样传递。<br>实现级联复制也较简单，只用修改 Slave2 配置文件的<code>slaveof</code>属性即可。</li>
<li>Master write，Slave read<br>通过程序（客户端）实现数据的读写分离，即在程序中判断请求是读是写，让 Master 负责处理写请求，Slave 负责处理读请求；通过扩展 Slave 处理更多的并发请求，减轻 Master 端的负载。</li>
</ol>
<h3 id="只读-Slave"><a href="#只读-Slave" class="headerlink" title="只读 Slave"></a>只读 Slave</h3><p>Redis2.6 之后，Redis 支持只读模式，可以使用<code>slave-read-only</code>配置来控制这个行为。<br>只读模式下的 slave 将会拒绝所有写入命令，因此实践中不可能由于某种出错而将数据写入 slave 。但这并不意味着该特性旨在将一个 slave 实例暴露到 Internet ，或者更广泛地说，将之暴露在存在不可信客户端的网络，因为像 DEBUG 或者 CONFIG 这样的管理员命令仍在启用。但是，在 redis.conf 文件中使用 rename-command 指令可以禁用上述管理员命令以提高只读实例的安全性。</p>
<h2 id="同步复制和异步复制"><a href="#同步复制和异步复制" class="headerlink" title="同步复制和异步复制"></a>同步复制和异步复制</h2><p>Redis 使用默认的<strong>异步复制</strong>，其特点是低延迟和高性能，不会影响 Redis 主线程的响应效率。</p>
<ul>
<li>Redis 复制在 master 侧是非阻塞的。这意味着 master 在一个或多个 slave 进行初次同步或者是部分重同步时，可以继续处理查询请求。</li>
<li>复制在 slave 侧大部分也是非阻塞的。当 slave 进行初次同步时，它可以使用旧数据集处理查询请求，假设你在 redis.conf 中配置了让 Redis 这样做的话。否则，你可以配置如果复制流断开， Redis slave 会返回一个 error 给客户端。但是，在初次同步之后，旧数据集必须被删除，同时加载新的数据集。 slave 在这个短暂的时间窗口内（如果数据集很大，会持续较长时间），会阻塞到来的连接请求。自 Redis 4.0 开始，可以配置 Redis 使删除旧数据集的操作在另一个不同的线程中进行，但是，加载新数据集的操作依然需要在主线程中进行并且会阻塞 slave 。</li>
</ul>
<blockquote>
<p>Redis 虽然声称是单线程模型，但是很多功能仍然是采用多线程实现的。</p>
</blockquote>
<h2 id="什么时候触发复制"><a href="#什么时候触发复制" class="headerlink" title="什么时候触发复制"></a>什么时候触发复制</h2><ul>
<li>当一个 Master 和一个 Slave 实例连接正常时，Master 通过向 Slave 发送命令流来<strong>增量同步</strong>自身数据集的改变情况，包括客户端的写入、key 的过期等；</li>
<li>Master 与 Slave 之间因为网络问题或宕机，之后 Slave 重新连上 Master 时会尝试进行<strong>部分重同步</strong>，即只获取在断开连接期间内丢失的命令流；<br>为此，slave 会记住旧 master 的旧 <strong>replication ID</strong> 和<strong>复制偏移量</strong>，因此即使询问旧的 replication ID，其也可以将部分复制缓冲提供给连接的 slave 。</li>
<li>当无法进行部分重同步时，Slave 会请求进行全量重同步。Master 需要创建所有数据的快照，将之发送给 Slave，之后在数据集发生更改时持续发送命令流到 Slave。</li>
</ul>
<h2 id="主从复制原理"><a href="#主从复制原理" class="headerlink" title="主从复制原理"></a>主从复制原理</h2><p>当用户往 Master 端写入数据时，通过<code>Redis Sync</code>机制将数据文件发送至 Slave，Slave 也会执行相同的操作确保数据一致。</p>
<ol>
<li>同一个 Master 可以拥有多个 Slaves。Master 下的 Slave 还可以接受同一架构中其它 Slave 的链接与同步请求，实现数据的<strong>级联复制</strong>，即 Master-&gt;Slave-&gt;Slave 模式；<br><code>repl-diskless-sync-delay</code>参数可以延迟启动数据传输，目的可以在第一个 slave 就绪后，等待更多的 slave 就绪。<br><strong>主从复制最好配置成级联复制，因为这样更容易解决单点问题，避免Master承受过大的复制压力</strong>。</li>
<li>Master 以<strong>非阻塞</strong>的方式同步数据至 slave，这将意味着 Master 会继续处理一个或多个 slave 的读写请求；</li>
<li>Slave 端同步数据也可以修改为非阻塞的方式，当 slave 在执行新的同步时，它仍可以用旧的数据信息来提供查询；否则，当 slave 与 master 失去联系时，slave 会返回一个错误给客户端；</li>
<li>主从复制可以做到<strong>读写分离</strong>，保证了可扩展性，即多个 slave 专门提供只读查询与数据的冗余，Master 端专门提供写操作；</li>
<li>通过配置禁用 Master 数据持久化机制，将其数据持久化操作交给 Slaves 完成，避免在 Master 中要有独立的进程来完成此操作。</li>
<li>Redis 主从复制的性能问题，为了主从复制的速度和连接的稳定性，Slave 和 Master 最好在同一个局域网内。</li>
</ol>
<p>标识同步进程：</p>
<ol>
<li>每个 Master 都有一个<code>Replication ID</code>：这是一个较大的伪随机字符串，标记了一个给定的数据集。</li>
<li>每个 Master 持有一个偏移量<code>offset</code>，Master 将自己产生的复制流发送给 slave 时，发送多少个字节的数据，自身的偏移量就会增加多少，目的是当有新的操作修改自己的数据集时，它可以以此更新 Slave 的状态。即使没有 Slave 连接到 Master，offset 也会自增，所以基本上每一对 <code>&lt;Replication ID, offset&gt;</code> 都会标识一个 Master 数据集的确切版本。</li>
<li>Slave 也维护了一个复制偏移量<code>offset</code>，代表从库同步的字节数，从库每收到主节点传来的 N 个字节数据时，从库的 offset 增加 N。<br>Master 和 Slave 的<code>offset</code>总是不断增大，这也是判断主从数据是否同步的标志，若主从的 offset 相同则表示数据同步量，不通则表示数据不同步。</li>
</ol>
<p>复制积压缓冲区<br>主节点(master)响应写命令时，不但会把命名发送给从节点，还会写入复制积压缓冲区，用于复制命令丢失的数据补救。<br>Slave 连接中断时主节点仍然可以响应命令，但因复制连接中断命令无法发送给 Slave。之后，当 Slave 重启并触发部分复制时，Master 可以将复制积压缓冲区的内容同步给 Slave，从而提高复制效率；</p>
<p>部分重同步过程：</p>
<ol>
<li>当 Slave 连接到 Master，发送一个<code>PSYNC</code>命令表明自己记录的旧的 Master <code>Replication ID</code>和它们至今为止处理的偏移量<code>offset</code>；</li>
<li>Master 仅发送 Slave 所需的增量部分的命令流，即上次同步偏移量<code>offset</code>之后执行的写命令；</li>
<li>但是如果 master 的缓冲区中没有足够的命令积压缓冲记录，或者如果 slave 引用了不再知道的历史记录（replication ID），则会转而进行一个全量重同步：在这种情况下， slave 会得到一个完整的数据集副本，从头开始。</li>
</ol>
<p>全量同步（完整重同步）：</p>
<ol>
<li>Slave 向 Master 发送<code>PSYNC</code>命令；</li>
<li>Master 执行<code>BGSAVE</code>命令，开启一个后台进程用于生成一个 RDB 文件；</li>
<li>同时它开始缓冲所有从客户端接收到的新的写入命令；</li>
<li>当后台保存完成时， master 将数据集文件传输给 slave， slave 将之保存在磁盘上，然后加载文件到内存；</li>
<li>再然后 master 会将所有缓冲的写命令发给 slave，这个过程以指令流的形式完成并且和 Redis 协议本身的格式相同。<blockquote>
<p>可以通过<code>telnet</code>连接到 Redis 服务器上然后发送<code>SYNC</code>命令来模拟这个过程，但是因为<code>SYNC</code>功能有限（比如不支持部分重同步），现在的版本用<code>PSYNC</code>作为代替。<br>正常情况下，全量同步会先在磁盘上创建一个 RDB 文件，传输时将其加载进内存，然后 Slave 对此进行数据的同步，如果磁盘性能很低，这个过程压力会比较大，<code>Redis 2.8.18</code>之后支持直接传输 RDB 文件，可以使用<code>repl-diskless-sync</code>配置参数配置。</p>
</blockquote>
</li>
</ol>
<p>全量同步完成以后，在此后的时间里主从维护着心跳检查来确认对方是否在线，每隔一段时间（默认 10 秒，通过<code>repl-ping-slave-period</code>参数指定）主节点向从节点发送 PING 命令判断从节点是否在线，而从节点每秒 1 次向主节点发送 REPLCONF ACK 命令，命令格式为：<code>REPLCONF ACK &#123;offset&#125;</code>，其中 offset 指的是从节点保存的复制偏移量，作用是：</p>
<ol>
<li>向主节点报告自己复制进度，主节点会对比复制偏移量向从节点发送未同步的命令；</li>
<li>判断主节点是否在线。</li>
</ol>
<h3 id="主从复制执行过程-Slave怎么与Master建立连接"><a href="#主从复制执行过程-Slave怎么与Master建立连接" class="headerlink" title="主从复制执行过程 - Slave怎么与Master建立连接"></a>主从复制执行过程 - Slave怎么与Master建立连接</h3><p><img src="/imgs/Redis/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6.png" alt="主从复制" title="主从复制"><br>1、Slave Redis实例上配置<code>slaveof xxx</code>，表示将成为另一台Redis实例的从服务器，启动 Slave时，需要设置当前节点的Master信息，并开始主从同步过程；<br>代码位置：<code>replication.c/slaveofCommand()</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">// 进入连接状态（重点）</span><br><span class="line">server.repl_state = REDIS_REPL_CONNECT;</span><br><span class="line">server.master_repl_offset = 0;</span><br><span class="line">server.repl_down_since = 0;</span><br></pre></td></tr></table></figure>
<p>2、上边设置复制信息成功后，Redis服务器会有一个cron任务（<code>serverCron</code>）定时判断需要进行同步操作，向Master建立连接，也就是一个握手的过程；<br>代码位置：<code>replication.c/replicationCron()</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">if (server.repl_state == REPL_STATE_CONNECT) &#123;</span><br><span class="line">   if (connectWithMaster() == C_OK) &#123;</span><br><span class="line">       serverLog(LL_NOTICE,&quot;MASTER &lt;-&gt; SLAVE sync started&quot;);</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>serverCron是Redis的主事件循环，负责超多的任务，包括过期key处理、rehash、备份RDB文件、AOF重写等等。</p>
</blockquote>
<p>3、确定连接后，接下来，cron任务里还有比较关键的一项是确定复制方案，<br>会先向 Master 发送一个 PSYNC Command，Master会返回复制方案，也就是下面的全量、增量及不支持这3种情况：<br>代码位置：<code>replication.c/syncWithMaster()</code><br><code>replication.c/slaveTryPartialResynchronization()</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">// 向主服务器发送 PSYNC 命令</span><br><span class="line">reply = sendSynchronousCommand(fd,&quot;PSYNC&quot;,psync_runid,psync_offset,NULL);</span><br><span class="line"></span><br><span class="line">// 全量复制</span><br><span class="line">if (!strncmp(reply,&quot;+FULLRESYNC&quot;,11)) &#123;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 增量复制</span><br><span class="line">if (!strncmp(reply,&quot;+CONTINUE&quot;,9)) &#123;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 错误，目前master不支持PSYNC</span><br><span class="line">if (strncmp(reply,&quot;-ERR&quot;,4)) &#123;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>注意PSYNC命令的两个参数：</p>
<ul>
<li>主库的runID：每个Redis实例启动时都会自动生成的一个随机ID，用来唯一标识这个实例。<br>当从库和主库第一次复制时，因为不知道主库的runID，因此会将runID设为”?”。</li>
<li>复制进度offset：设为-1表示第一次复制。</li>
</ul>
<p>4、Master接收到命令后需要判断需要全量同步还是部分同步<br>这部分代码在<code>replication.c/syncCommand()</code>中，接下来我们再讨论主节点如何判断同步方式及同步的流程。</p>
<h3 id="主从复制执行过程-Master如何处理PSYNC命令"><a href="#主从复制执行过程-Master如何处理PSYNC命令" class="headerlink" title="主从复制执行过程 - Master如何处理PSYNC命令"></a>主从复制执行过程 - Master如何处理PSYNC命令</h3><p>1、无论是第一次连接还是重新连接，Master 都会启动一个后台进程（fork），将<strong>数据快照</strong>保存到数据文件中，同时 Master 会记录<strong>所有修改数据的命令</strong>并缓存在数据文件中（持久化），Master会将文件内容加载到内存中，等之后回传给Slave（复制）；<br>2、Master端与Slave端完成握手后，需要判断是需要进行全量还是增量复制（也就是上面的返回<code>+FULLRESYNC</code>还是<code>+CONTINUE</code><br>处理Slave的<code>PSYNC</code>命令的代码位置：<code>replication.c/syncCommand()</code><br>判断是否需要执行全量复制的代码位置：<code>replication.c/masterTryPartialResynchronization()</code><br>判断执行<strong>全量复制</strong>的条件如下代码所示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">// 检查 master id 是否和 runid 一致，只有一致的情况下才考虑执行psync</span><br><span class="line">if (strcasecmp(master_runid, server.runid)) &#123;</span><br><span class="line">    /* Run id &quot;?&quot; is used by slaves that want to force a full resync. */</span><br><span class="line">    // 从服务器提供的 run id 和服务器的 run id 不一致</span><br><span class="line">    if (master_runid[0] != &#x27;?&#x27;) &#123;</span><br><span class="line">        redisLog(REDIS_NOTICE,&quot;Partial resynchronization not accepted: &quot;</span><br><span class="line">            &quot;Runid mismatch (Client asked for runid &#x27;%s&#x27;, my runid is &#x27;%s&#x27;)&quot;,</span><br><span class="line">            master_runid, server.runid);</span><br><span class="line">    // 从服务器提供的 run id 为 &#x27;?&#x27; ，表示强制 FULL RESYNC</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        redisLog(REDIS_NOTICE,&quot;Full resync requested by slave.&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">    // 需要 full resync</span><br><span class="line">    goto need_full_resync;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 判断当前Slave带来的offset在Master的backlog中是否还能找到，找不到则执行全量复制</span><br><span class="line">if (getLongLongFromObjectOrReply(c,c-&gt;argv[2],&amp;psync_offset,NULL) !=</span><br><span class="line">       REDIS_OK) goto need_full_resync;</span><br><span class="line"></span><br><span class="line">// 如果没有backlog</span><br><span class="line">if (!server.repl_backlog ||</span><br><span class="line">    // 或者 psync_offset 小于 server.repl_backlog_off</span><br><span class="line">    // （想要恢复的那部分数据已经被覆盖）</span><br><span class="line">    psync_offset &lt; server.repl_backlog_off ||</span><br><span class="line">    // psync offset 大于 backlog 所保存的数据的偏移量</span><br><span class="line">    psync_offset &gt; (server.repl_backlog_off + server.repl_backlog_histlen))</span><br><span class="line">&#123;</span><br><span class="line">    // 执行 FULL RESYNC</span><br><span class="line">    redisLog(REDIS_NOTICE,</span><br><span class="line">        &quot;Unable to partial resync with the slave for lack of backlog (Slave request was: %lld).&quot;, psync_offset);</span><br><span class="line">    if (psync_offset &gt; server.master_repl_offset) &#123;</span><br><span class="line">        redisLog(REDIS_WARNING,</span><br><span class="line">            &quot;Warning: slave tried to PSYNC with an offset that is greater than the master replication offset.&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">    goto need_full_resync;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>3、如果是部分复制<br>Master会向Slave发送 backlog 中从 offset 到 backlog 尾部之间的数据<br>代码：<code>replication.c/addReplyReplicationBacklog()</code><br>部分复制在3.0版本和之后的版本中的实现有比较大的差异。<br>在3.0时，部分复制发生在Slave向Master发送PSYNC命令时。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line">void syncCommand(redisClient *c) &#123;</span><br><span class="line">    ...</span><br><span class="line">    </span><br><span class="line">    if (!strcasecmp(c-&gt;argv[0]-&gt;ptr,&quot;psync&quot;)) &#123;</span><br><span class="line">        // 尝试进行 PSYNC</span><br><span class="line">        if (masterTryPartialResynchronization(c) == REDIS_OK) &#123;</span><br><span class="line">            // 可执行 PSYNC</span><br><span class="line">            server.stat_sync_partial_ok++;</span><br><span class="line">            return; /* No full resync needed, return. */</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            // 不可执行 PSYNC</span><br><span class="line">            char *master_runid = c-&gt;argv[1]-&gt;ptr;</span><br><span class="line">            </span><br><span class="line">            /* Increment stats for failed PSYNCs, but only if the</span><br><span class="line">             * runid is not &quot;?&quot;, as this is used by slaves to force a full</span><br><span class="line">             * resync on purpose when they are not albe to partially</span><br><span class="line">             * resync. */</span><br><span class="line">            if (master_runid[0] != &#x27;?&#x27;) server.stat_sync_partial_err++;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int masterTryPartialResynchronization(redisClient *c) &#123;</span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">    /* If we reached this point, we are able to perform a partial resync:</span><br><span class="line">     * 程序运行到这里，说明可以执行 partial resync</span><br><span class="line">     *</span><br><span class="line">     * 1) Set client state to make it a slave.</span><br><span class="line">     *    将客户端状态设为 salve  </span><br><span class="line">     *</span><br><span class="line">     * 2) Inform the client we can continue with +CONTINUE</span><br><span class="line">     *    向 slave 发送 +CONTINUE ，表示 partial resync 的请求被接受</span><br><span class="line">     *</span><br><span class="line">     * 3) Send the backlog data (from the offset to the end) to the slave. </span><br><span class="line">     *    发送 backlog 中，客户端所需要的数据</span><br><span class="line">     */</span><br><span class="line">    c-&gt;flags |= REDIS_SLAVE;</span><br><span class="line">    c-&gt;replstate = REDIS_REPL_ONLINE;</span><br><span class="line">    c-&gt;repl_ack_time = server.unixtime;</span><br><span class="line">    listAddNodeTail(server.slaves,c);</span><br><span class="line">    /* We can&#x27;t use the connection buffers since they are used to accumulate</span><br><span class="line">     * new commands at this stage. But we are sure the socket send buffer is</span><br><span class="line">     * emtpy so this write will never fail actually. */</span><br><span class="line">    // 向从服务器发送一个同步 +CONTINUE ，表示 PSYNC 可以执行</span><br><span class="line">    buflen = snprintf(buf,sizeof(buf),&quot;+CONTINUE\r\n&quot;);</span><br><span class="line">    if (write(c-&gt;fd,buf,buflen) != buflen) &#123;</span><br><span class="line">        freeClientAsync(c);</span><br><span class="line">        return REDIS_OK;</span><br><span class="line">    &#125;</span><br><span class="line">    // 发送 backlog 中的内容（也即是从服务器缺失的那些内容）到从服务器</span><br><span class="line">    psync_len = addReplyReplicationBacklog(c,psync_offset);</span><br><span class="line">    redisLog(REDIS_NOTICE,</span><br><span class="line">        &quot;Partial resynchronization request accepted. Sending %lld bytes of backlog starting from offset %lld.&quot;, psync_len, psync_offset);</span><br><span class="line">        </span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>3.0后，在每次命令执行完之后，还会触发命令传播：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">void processInputBufferAndReplicate(client *c) &#123;</span><br><span class="line">    // 处理命令然后广播命令</span><br><span class="line">    // if this is a slave, we just process the commands</span><br><span class="line">    if (!(c-&gt;flags &amp; CLIENT_MASTER)) &#123;</span><br><span class="line">        processInputBuffer(c);</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        /* If the client is a master we need to compute the difference</span><br><span class="line">         * between the applied offset before and after processing the buffer,</span><br><span class="line">         * to understand how much of the replication stream was actually</span><br><span class="line">         * applied to the master state: this quantity, and its corresponding</span><br><span class="line">         * part of the replication stream, will be propagated to the</span><br><span class="line">         * sub-replicas and to the replication backlog. */</span><br><span class="line">        size_t prev_offset = c-&gt;reploff;</span><br><span class="line">        processInputBuffer(c);</span><br><span class="line">        // applied is how much of the replication stream was actually applied to the master state</span><br><span class="line">        size_t applied = c-&gt;reploff - prev_offset;</span><br><span class="line">        if (applied) &#123;</span><br><span class="line"></span><br><span class="line">            replicationFeedSlavesFromMasterStream(server.slaves,</span><br><span class="line">                    c-&gt;pending_querybuf, applied);</span><br><span class="line">            sdsrange(c-&gt;pending_querybuf,applied,-1);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>所谓命令传播，就是当Master节点每处理完一个命令都会把命令广播给所有的子节点，而每个子节点接收到Master的广播过来的命令后，会在处理完之后继续广播给自己的子节点。<br>命令传播也是异步的操作，即Master节点处理完客户端的命令之后会立马向客户端返回结果，而不会一直等待所有的子节点都确认完成操作后再返回以保证Redis高效的性能。<br>4、什么时候会改为采用全量复制<br>上面的增量复制中，我们看到Redis实际上是将repl_backlog中的内容复制给了Slave，backlog是一块内存缓冲区（默认大小为1M），每次处理完命令之后，先写入缓冲区repl_backlog, 然后再发送给Slave。<br>如果一个Slave断连了一段时间，重启后Master可以将这块缓冲区内的内容复制给Slave，但是如果断连的时间比较长，也有可能会触发全量复制，因为缓冲区能保存的命令有限，只能至多保存的命令长度为repl_backlog_length，如果某个子节点落后当前最新命令的长度大于了repl_backlog_length，那么就会触发全量复制。<br>5、如果是全量复制<br>这种情况下，Master并不会直接将RDB文件传给Slave，而是先发给Slave<code>+FULLRESYNC</code>，；<br>代码：<code>replication.c/masterTryPartialResynchronization()</code>的末尾<br>什么时候Master会将RDB文件传给Slave呢？如果当前已经有可用的RDB文件，则直接将RDB文件传输给Slave；如果当前RDB正在备份过程中，Master会在每次RDB文件备份完毕后执行一次传输任务。<br><code>replication.c/syncCommand()</code>末尾Master判断RDB当前的备份状态，设置标识表示当前RDB文件是否可用于复制，如果可以复制则会在之后的主事件循环中触发文件的发送：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">void syncCommand(redisClient *c) &#123;</span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">    /* Here we need to check if there is a background saving operation</span><br><span class="line">     * in progress, or if it is required to start one */</span><br><span class="line">    // 检查是否有 BGSAVE 在执行</span><br><span class="line">    if (server.rdb_child_pid != -1) &#123;</span><br><span class="line">        /* Ok a background save is in progress. Let&#x27;s check if it is a good</span><br><span class="line">         * one for replication, i.e. if there is another slave that is</span><br><span class="line">         * registering differences since the server forked to save */</span><br><span class="line">        redisClient *slave;</span><br><span class="line">        listNode *ln;</span><br><span class="line">        listIter li;</span><br><span class="line"></span><br><span class="line">        // 如果有至少一个 slave 在等待这个 BGSAVE 完成</span><br><span class="line">        // 那么说明正在进行的 BGSAVE 所产生的 RDB 也可以为其他 slave 所用</span><br><span class="line">        listRewind(server.slaves,&amp;li);</span><br><span class="line">        while((ln = listNext(&amp;li))) &#123;</span><br><span class="line">            slave = ln-&gt;value;</span><br><span class="line">            if (slave-&gt;replstate == REDIS_REPL_WAIT_BGSAVE_END) break;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        if (ln) &#123;</span><br><span class="line">            /* Perfect, the server is already registering differences for</span><br><span class="line">             * another slave. Set the right state, and copy the buffer. */</span><br><span class="line">            // 幸运的情况，可以使用目前 BGSAVE 所生成的 RDB</span><br><span class="line">            copyClientOutputBuffer(c,slave);</span><br><span class="line">            // 设置复制状态</span><br><span class="line">            c-&gt;replstate = REDIS_REPL_WAIT_BGSAVE_END;</span><br><span class="line">            redisLog(REDIS_NOTICE,&quot;Waiting for end of BGSAVE for SYNC&quot;);</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            /* No way, we need to wait for the next BGSAVE in order to</span><br><span class="line">             * register differences */</span><br><span class="line">            // 不好运的情况，必须等待下个 BGSAVE</span><br><span class="line">            c-&gt;replstate = REDIS_REPL_WAIT_BGSAVE_START;</span><br><span class="line">            redisLog(REDIS_NOTICE,&quot;Waiting for next BGSAVE for SYNC&quot;);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        /* Ok we don&#x27;t have a BGSAVE in progress, let&#x27;s start one */</span><br><span class="line">        // 没有 BGSAVE 在进行，开始一个新的 BGSAVE</span><br><span class="line">        redisLog(REDIS_NOTICE,&quot;Starting BGSAVE for SYNC&quot;);</span><br><span class="line">        if (rdbSaveBackground(server.rdb_filename) != REDIS_OK) &#123;</span><br><span class="line">            redisLog(REDIS_NOTICE,&quot;Replication failed, can&#x27;t BGSAVE&quot;);</span><br><span class="line">            addReplyError(c,&quot;Unable to perform background save&quot;);</span><br><span class="line">            return;</span><br><span class="line">        &#125;</span><br><span class="line">        // 设置状态</span><br><span class="line">        c-&gt;replstate = REDIS_REPL_WAIT_BGSAVE_END;</span><br><span class="line">        /* Flush the script cache for the new slave. */</span><br><span class="line">        // 因为新 slave 进入，刷新复制脚本缓存</span><br><span class="line">        replicationScriptCacheFlush();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>主事件循环中发RDB文件的代码如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">int serverCron(struct aeEventLoop *eventLoop, long long id, void *clientData) &#123;</span><br><span class="line"></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">    /* Check if a background saving or AOF rewrite in progress terminated. */</span><br><span class="line">    // 检查 BGSAVE 或者 BGREWRITEAOF 是否已经执行完毕</span><br><span class="line">    if (server.rdb_child_pid != -1 || server.aof_child_pid != -1) &#123;</span><br><span class="line">        int statloc;</span><br><span class="line">        pid_t pid;</span><br><span class="line"></span><br><span class="line">        // 接收子进程发来的信号，非阻塞</span><br><span class="line">        if ((pid = wait3(&amp;statloc,WNOHANG,NULL)) != 0) &#123;</span><br><span class="line">            int exitcode = WEXITSTATUS(statloc);</span><br><span class="line">            int bysignal = 0;</span><br><span class="line">            </span><br><span class="line">            if (WIFSIGNALED(statloc)) bysignal = WTERMSIG(statloc);</span><br><span class="line"></span><br><span class="line">            // BGSAVE 执行完毕</span><br><span class="line">            if (pid == server.rdb_child_pid) &#123;</span><br><span class="line">                backgroundSaveDoneHandler(exitcode,bysignal);</span><br><span class="line"></span><br><span class="line">            // BGREWRITEAOF 执行完毕</span><br><span class="line">            &#125; else if (pid == server.aof_child_pid) &#123;</span><br><span class="line">                backgroundRewriteDoneHandler(exitcode,bysignal);</span><br><span class="line"></span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                redisLog(REDIS_WARNING,</span><br><span class="line">                    &quot;Warning, detected child with unmatched pid: %ld&quot;,</span><br><span class="line">                    (long)pid);</span><br><span class="line">            &#125;</span><br><span class="line">            updateDictResizePolicy();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>接下来的调用包括：<br><code>replication.c/backgroundSaveDoneHandler()</code><br><code>replication.c/updateSlavesWaitingBgsave()</code><br><code>replication.c/sendBulkToSlave()</code></p>
<p>全量同步的大致流程如此，主要分为以下几步：</p>
<ol>
<li>Master节点开启子进程进行RDB文件生成</li>
<li>Master节点将RDB文件发送给Slave节点</li>
<li>Slave节点清空内存中的所有数据并删除之前的RDB文件</li>
<li>Slave节点使用从Master接收的RDB文件恢复数据到内存中</li>
</ol>
<p>需要注意的是，这个过程中的每一步都是耗时的IO操作，所以大部分时候Redis都是尽可能采用增量复制，而不是全量复制。<br>下面再来讨论Master如何发送及Slave如何接收这份数据。</p>
<h3 id="主从复制执行过程-Master如何发送及Slave如何接收复制数据"><a href="#主从复制执行过程-Master如何发送及Slave如何接收复制数据" class="headerlink" title="主从复制执行过程 - Master如何发送及Slave如何接收复制数据"></a>主从复制执行过程 - Master如何发送及Slave如何接收复制数据</h3><p>1、如果是全量复制<br>Slave和Master刚开始握手完毕后，会注册一个<code>readSyncBulkPayload</code>处理器，用于读取从Master发送过来的RDB文件。<br>2、Slave 将数据文件保存到磁盘上，然后再加载到内存中；<br>从库接收到RDB文件后，会<strong>先清空当前数据库，然后加载RDB文件</strong>，这是因为从库在开始和主库同步前可能保存了其他数据，为了避免之前数据的影响，从库需要先把当前数据库清空。<br>3、同步过程中主库产生的新数据也要同步给从库<br>主库同步数据给从库的过程中，主库不会被阻塞，仍然可以正常接收请求（否则Redis服务不就中断了？），但是这些请求中的写操作并没有记录到刚刚生成的RDB文件中，为了保证主从库的数据一致性，主库会在内存中用专门的<strong>replication buffer（代码中对应</strong>repl_backlog_buffer<strong>）</strong>记录RDB文件生成后收到的所有写操作。<br><code>repl_backlog_buffer</code>是一个环形缓冲区，主库会记录自己写到的位置，而从库则会记录自己已经读到的位置，可以使用<code>repl_backlog_size</code>来配置这个缓冲区的大小，如果配得过小，可能会导致增量复制阶段从库复制进度赶不上主库，进而导致从库重新进行全量复制。<br>在Master端定义的offset是<code>master_repl_offset</code>，在Slave端定义的offset是<code>slave_repl_offset</code>，正常情况下这两个偏移量是基本相等的。<br>增量同步期间，从库在发送psync的同时，会把自己当前的slave_repl_offset发给主库，主库判断自己的master_repl_offset和slave_repl_offset之间的差距，如果断连了，master_repl_offset可能会超过slave_repl_offset，那么将这超过的部分发给slave就可以恢复同步了。</p>
<h2 id="主从复制存在的问题"><a href="#主从复制存在的问题" class="headerlink" title="主从复制存在的问题"></a>主从复制存在的问题</h2><h3 id="主从库间网络断了怎么办？"><a href="#主从库间网络断了怎么办？" class="headerlink" title="主从库间网络断了怎么办？"></a>主从库间网络断了怎么办？</h3><p>Redis2.8之前，如果主从同步过程中出现了网络闪断，那么主从是会重新进行一次全量复制的，开销非常大。<br>Redis2.8之后，网络闪断后，主从会采取<strong>增量复制</strong>，将闪断期间的命令发给从库。</p>
<h3 id="宕机恢复"><a href="#宕机恢复" class="headerlink" title="宕机恢复"></a>宕机恢复</h3><p>因为 slave 顶多只负责处理读请求，slave 挂掉不会造成数据丢失的问题。<br>slave 宕机的情况下，应该要求客户端具有一定的熔断恢复能力，并且能在重启后快速恢复：</p>
<ol>
<li>恢复正常后重新连接；</li>
<li>Master 收到 Slave 的连接后，第一次同步时，主节点做一次 bgsave，并同时将后续修改操作记录到内存 buffer；</li>
<li>Master 将其完整的 rdb 数据文件全量发送给 Slave；</li>
<li>Slave 接收完成后将 rdb 镜像文件加载到内存，加载完成后，再通知 Master 将期间修改的操作记录同步到 Slave 节点进行重放就完成了同步过程；</li>
<li>如果 Master 同时收到多个 Slave 发来的同步请求，Master 只会在后台启动一个进程保存数据文件，然后将其发送给所有的 Slave，确保 Slave 正常。</li>
</ol>
<p>主从复制无法应对 Master 挂掉的情况，实际上这种方案只能尽量保证数据不会丢失，不能保证服务的高可用性，为此，需要引入 Redis 的 Sentinel 机制。</p>
<p>客户端可以使用 <code>WAIT</code> 命令来请求同步复制某些特定的数据。但是，WAIT 命令只能确保在其他 Redis 实例中有指定数量的已确认的副本：在故障转移期间，由于不同原因的故障转移或是由于 Redis 持久性的实际配置，故障转移期间确认的写入操作可能仍然会丢失。</p>
<h3 id="是否可以关闭持久化"><a href="#是否可以关闭持久化" class="headerlink" title="是否可以关闭持久化"></a>是否可以关闭持久化</h3><p>作为复制方案中的一环，可以考虑关闭 Master 或 Slave 的持久化功能，但是并不建议关掉它们，因为：</p>
<ul>
<li>如果关闭 Master 的持久化：重启（重启功能可以由一些只能运维工具来保证，比如 K8S）的 Master 将从一个空数据集开始，如果一个 Slave 试图与它同步，那么这个 Slave 也会被清空。</li>
<li>如果关闭 Slave 的持久化：重启的 Slave 需要从 Master 全量同步数据。</li>
</ul>
<p>正如前所述，关闭了持久化并配置了自动重启的 Master 是危险的——会导致整个集群的数据全部被清空。<br>如果 Sentinel 集群用于需要高可用的场景、且 Master 被关闭掉了持久化功能，也是非常危险的：</p>
<ul>
<li>如果重启比较慢，Sentinel 的故障迁移机制重新选主，一个 Slave 会上升为 Master；</li>
<li>如果重启得足够快，Sentinel 没有探测到故障，此时 Master 数据被清空了，而 Slave 仍从 Master 同步数据，这将引起上边提到的故障模式——数据将丢失。</li>
</ul>
<p>因此，如果考虑磁盘性能过慢会导致延迟、关掉了持久化，那么自动重启进程这项应该被禁用。</p>
<h3 id="如何保证主从数据的一致性-数据丢失窗口的存在"><a href="#如何保证主从数据的一致性-数据丢失窗口的存在" class="headerlink" title="如何保证主从数据的一致性 - 数据丢失窗口的存在"></a>如何保证主从数据的一致性 - 数据丢失窗口的存在</h3><p>由于 Redis 使用<strong>异步复制</strong>，无法保证Slave和Master的实时一致性，因此总会有一个<strong>数据丢失窗口</strong>。<br>那在什么情况下，从库会滞后执行同步命令呢？</p>
<ol>
<li>一方面，主从库间的网络可能会有传输延迟，所以从库不能及时地收到主库发送的命令，从库上执行同步命令的时间就会被延后。</li>
<li>另一方面，即使从库及时收到了主库的命令，但是，也可能会因为正在处理其它复杂度高的命令（例如集合操作命令）而阻塞。此时，从库需要处理完当前的命令，才能执行主库发送的命令操作，这就会造成主从数据不一致。而在主库命令被滞后处理的这段时间内，主库本身可能又执行了新的写操作。这样一来，主从库间的数据不一致程度就会进一步加剧。</li>
</ol>
<p>因为异步复制的本质，Redis主从复制无法完全避免数据的丢失，除了尽量保证网络连接状况良好外，还可以写一些监控程序来监控主从库间的复制进度，原理是实时给Redis实例发<code>info replication</code>命令得到<code>master_repl_offset</code>和<code>slave_repl_offset</code>这两个进度信息，计算这二者的差值即可得到主从复制进度的实时程度，如果某个从库进度差值大于我们预设的一个阈值，我们可以让客户端不再和这个从库连接进行数据读取，从而减少读到不一致数据的情况。</p>
<blockquote>
<p>这个阈值当然不能设置得过低，否则可能导致所有从库都连不上了。</p>
</blockquote>
<p>既然无法避免，那么只能退一步、控制影响范围了，Redis 可以保证：</p>
<ol>
<li>Redis slave 每秒钟都会 ping master，确认已处理的复制流的数量。</li>
<li>Redis master 会记得上一次从每个 slave 都收到 ping 的时间。</li>
<li>用户可以配置一个最小的 slave 数量，使得它滞后 &lt;&#x3D; 最大秒数。</li>
<li>如果至少有 N 个 slave ，并且滞后小于 M 秒，则写入将被接受。如果条件不满足，master 将会回复一个 error 并且写入将不被接受。</li>
</ol>
<p>这些条件是通过<code>min-slaves-to-write</code>和<code>min-slaves-max-lag</code>这两个配置来实现的：</p>
<ul>
<li><code>min-slaves-to-write</code>：最少有n个slave的连接还是健康的情况下才能提供服务，至于怎么判断连接是否健康，需要看下面一个配置；</li>
<li><code>min-slaves-max-lag</code>：判断连接健康的最大延迟时间，slave每次PING Master时Master都会记录该Slave 最后一次PING的时间，如果最后一次PING成功的时间距今比较长了，就说明该Slave的连接状态很有可能已经出问题了。</li>
</ul>
<p>对于给定的写入来说，虽然不能保证绝对实时的一致性，但至少数据丢失的时间窗限制在给定的秒数内。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"># It is possible for a master to stop accepting writes if there are less than</span><br><span class="line"># N slaves connected, having a lag less or equal than M seconds.</span><br><span class="line">#</span><br><span class="line"># The N slaves need to be in &quot;online&quot; state.</span><br><span class="line">#</span><br><span class="line"># The lag in seconds, that must be &lt;= the specified value, is calculated from</span><br><span class="line"># the last ping received from the slave, that is usually sent every second.</span><br><span class="line">#</span><br><span class="line"># This option does not GUARANTEES that N replicas will accept the write, but</span><br><span class="line"># will limit the window of exposure for lost writes in case not enough slaves</span><br><span class="line"># are available, to the specified number of seconds.</span><br><span class="line">#</span><br><span class="line"># For example to require at least 3 slaves with a lag &lt;= 10 seconds use:</span><br><span class="line">#</span><br><span class="line"># min-slaves-to-write 3</span><br><span class="line"># min-slaves-max-lag 10</span><br><span class="line">#</span><br><span class="line"># Setting one or the other to 0 disables the feature.</span><br><span class="line">#</span><br><span class="line"># By default min-slaves-to-write is set to 0 (feature disabled) and</span><br><span class="line"># min-slaves-max-lag is set to 10.</span><br><span class="line"></span><br><span class="line">min-slaves-to-write &lt;slave 数量&gt;</span><br><span class="line">min-slaves-max-lag &lt;秒数&gt;</span><br></pre></td></tr></table></figure>

<h3 id="过期的-key-问题"><a href="#过期的-key-问题" class="headerlink" title="过期的 key 问题"></a>过期的 key 问题</h3><p>由于复制的异步特性，对 key 设置过期时间和写入操作很容易导致 race condition 及导致数据集不一致，比如：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">(1) sadd x 1</span><br><span class="line">(2) expire x 100</span><br><span class="line">(3) sadd x 2</span><br></pre></td></tr></table></figure>
<p>在 Master 上，命令(3)是在过期前执行的，而 Slave 上可能因为延后导致命令(3)执行前 x 就已经过期了，此时 x 是没有过期时间的（ttl x 得到-1 表示不过期），这就导致了数据的不一致。</p>
<blockquote>
<p>set 命令不会出现这个问题，因为 set 会将过期时间给覆盖成-1。当然情况比较复杂，也有可能是我没有想到。</p>
</blockquote>
<p>为了保证针对过期的 key 的复制能够正确工作，Redis 提供如下保证：</p>
<ol>
<li>slave 不会让 key 过期，而是等待 master 让 key 过期。当一个 master 让一个 key 到期（或由于 LRU 算法将之驱逐）时，它会合成一个 DEL 命令并传输到所有的 slave。一旦一个 slave 被提升为一个 master ，它将开始独立地过期 key，而不需要任何旧 master 的帮助。</li>
<li>但是，由于这是 master 驱动的 key 过期行为，master 无法及时提供 DEL 命令，所以有时候 slave 的内存中仍然可能存在在逻辑上已经过期的 key 。为了处理这个问题，slave 使用它的逻辑时钟以报告只有在不违反数据集的一致性的读取操作（从主机的新命令到达）中才存在 key。用这种方法，slave 避免报告逻辑过期的 key 仍然存在。在实际应用中，使用 slave 程序进行缩放的 HTML 碎片缓存，将避免返回已经比期望的时间更早的数据项。</li>
<li>在 Lua 脚本执行期间，不执行任何 key 过期操作。当一个 Lua 脚本运行时，从概念上讲，master 中的时间是被冻结的，这样脚本运行的时候，一个给定的键要么存在要么不存在。这可以防止 key 在脚本中间过期，保证将相同的脚本发送到 slave ，从而在二者的数据集中产生相同的效果。</li>
</ol>
<h2 id="QA"><a href="#QA" class="headerlink" title="QA"></a>QA</h2><h3 id="AOF日志更全，为什么主从同步不使用AOF而是RDB呢？"><a href="#AOF日志更全，为什么主从同步不使用AOF而是RDB呢？" class="headerlink" title="AOF日志更全，为什么主从同步不使用AOF而是RDB呢？"></a>AOF日志更全，为什么主从同步不使用AOF而是RDB呢？</h3><p>网络传输效率：RDB直接存储数据，而不是命令，数据量更小，传输更快。<br>恢复效率：因为使用AOF恢复数据库的话是需要将AOF中记录的命令再执行一次的，这个效率远不如直接将RDB中的数据直接加载到内存里。</p>
<h3 id="主从切换过程中，客户端能正常进行请求吗？"><a href="#主从切换过程中，客户端能正常进行请求吗？" class="headerlink" title="主从切换过程中，客户端能正常进行请求吗？"></a>主从切换过程中，客户端能正常进行请求吗？</h3><p>主库故障后从库仍能正常接收读请求，但主库挂掉了所以无法处理写请求。</p>
<h3 id="如果实现应用程序不感知服务器的中断？"><a href="#如果实现应用程序不感知服务器的中断？" class="headerlink" title="如果实现应用程序不感知服务器的中断？"></a>如果实现应用程序不感知服务器的中断？</h3><ol>
<li>客户端可以缓存写请求，因为使用Redis的场景同步写请求比较少，且一般都不会在应用程序的关键路径上，所以在不能立刻执行写请求的情况下，客户端完全可以先把请求缓存起来，给应用程序返回一个确认即可。</li>
<li>另外，主从切换后，客户端要能及时和新主库重新建立连接。</li>
</ol>
<h3 id="主从数据发生不一致怎么办？"><a href="#主从数据发生不一致怎么办？" class="headerlink" title="主从数据发生不一致怎么办？"></a>主从数据发生不一致怎么办？</h3><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li><a target="_blank" rel="noopener" href="https://www.cnblogs.com/hongmoshui/p/10594639.html">Redis复制实现原理</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/102859170">Redis集群——主从复制数据同步</a></li>
</ol>
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kity@2.0.4/dist/kity.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text/javascript" src="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.6.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.6.0/dist/mindmap.min.css">
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/a2b16944.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="tallate">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Tallate">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/a2b16944.html" class="post-title-link" itemprop="url">Redis 持久化</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2019-09-22 12:21:48" itemprop="dateCreated datePublished" datetime="2019-09-22T12:21:48+08:00">2019-09-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-07-07 01:56:20" itemprop="dateModified" datetime="2025-07-07T01:56:20+08:00">2025-07-07</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%BC%93%E5%AD%98/" itemprop="url" rel="index"><span itemprop="name">缓存</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>Redis 为了达到最快的读写速度将数据都读到内存中，并通过异步的方式将数据写入磁盘。所以 redis 具有快速和数据持久化的特征。如果不将数据放在内存中，磁盘 I&#x2F;O 速度为严重影响 redis 的性能。在内存越来越便宜的今天，redis 将会越来越受欢迎。<br>如果设置了最大使用的内存，则数据已有记录数达到内存限值后不能继续插入新值。<br>不过 Redis 也提供了持久化的选项。</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/a2b16944.html#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/f1a5dd67.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="tallate">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Tallate">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/f1a5dd67.html" class="post-title-link" itemprop="url">Redis 数据结构</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2019-09-22 12:21:48" itemprop="dateCreated datePublished" datetime="2019-09-22T12:21:48+08:00">2019-09-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-07-07 01:56:20" itemprop="dateModified" datetime="2025-07-07T01:56:20+08:00">2025-07-07</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%BC%93%E5%AD%98/" itemprop="url" rel="index"><span itemprop="name">缓存</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <span id="more"></span>


<h1 id="基本数据结构"><a href="#基本数据结构" class="headerlink" title="基本数据结构"></a>基本数据结构</h1><h2 id="String"><a href="#String" class="headerlink" title="String"></a>String</h2><h3 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h3><ol>
<li>最大能存储 512MB &#x3D;&#x3D; 536870912 B(byte) ；</li>
<li>二进制安全，在传输数据的时候，能保证二进制数据的信息安全，也就是不会被篡改、破译；如果被攻击，能够及时检测出来</li>
<li>能存储各种类型的数据，字符串、数字，以至对象（通过json序列化）、位图等。</li>
</ol>
<h3 id="基本使用"><a href="#基本使用" class="headerlink" title="基本使用"></a>基本使用</h3><p>容量：512M</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">set aa &#x27;str&#x27;</span><br><span class="line">get aa</span><br></pre></td></tr></table></figure>
<p>操作总结</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">set/get/del/append/strlen key</span><br><span class="line">incr/decr/incrby/decrby key</span><br><span class="line">getrange key start end/setrange key offset value（从offset处开始读取/覆盖）</span><br><span class="line">setex key seconds value(set with expire插入key的同时设置过期时间)/setnx key value(set if not exists如果已存在则直接返回0)</span><br><span class="line">mset/mget/msetnx key value &#123;key value&#125;（设置/读取多个key的值，msetnx比较特殊，要么都成功，要么一个都不执行，可以用来设置一个对象的多个不同字段）</span><br><span class="line">getset key(设置并返回key对应的旧值，可以用于计数器的重置)</span><br></pre></td></tr></table></figure>
<h3 id="常见应用"><a href="#常见应用" class="headerlink" title="常见应用"></a>常见应用</h3><p>字符串、jpg图片、序列化对象、一些复杂的计数功能的缓存</p>
<h2 id="Hash"><a href="#Hash" class="headerlink" title="Hash"></a>Hash</h2><p>存储 String 类型键值对的映射表、对象</p>
<h3 id="基本使用方法"><a href="#基本使用方法" class="headerlink" title="基本使用方法"></a>基本使用方法</h3><p>容量：每个 Hash 可存 2^32 - 1（约 40 亿）个键值对</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hmset user username &#x27;name&#x27; password &#x27;123456&#x27; # 定义一个有两个元素的Hash表</span><br><span class="line">hgetall user # 获取user中所有key和value</span><br><span class="line">hget user username # 获取user中key为username的value</span><br></pre></td></tr></table></figure>
<h3 id="常见应用-1"><a href="#常见应用-1" class="headerlink" title="常见应用"></a>常见应用</h3><p>单点登录（存&lt;CookieId, 用户信息&gt;，设置 30 分钟为缓存过期时间，能很好地模拟出类似 Session 的效果）。</p>
<h2 id="List"><a href="#List" class="headerlink" title="List"></a>List</h2><p>String列表</p>
<h3 id="基本使用方法-1"><a href="#基本使用方法-1" class="headerlink" title="基本使用方法"></a>基本使用方法</h3><p>容量：每个 List 可存 2^32 - 1 个元素</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">lpush ball basketball soccer # 按顺序从左侧压入，如果ball列表不存在则创建</span><br><span class="line">rpush ball volleyball</span><br><span class="line">lrange 0 1 # 获取索引从0到1的值</span><br></pre></td></tr></table></figure>
<p>操作总结</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">lpush/rpush/lrange</span><br><span class="line">lpop/rpop</span><br><span class="line">lindex</span><br><span class="line">llen</span><br><span class="line">lrem key</span><br><span class="line">ltrim key</span><br><span class="line">rpoplpush</span><br><span class="line">lset key index value</span><br><span class="line">linsert key before/after val1 val2</span><br></pre></td></tr></table></figure>
<h3 id="常见应用-2"><a href="#常见应用-2" class="headerlink" title="常见应用"></a>常见应用</h3><p>简单的消息队列<br>基于 Redis 的分页功能（利用 lrang 命令，性能极佳，用户体验好）</p>
<h2 id="Set"><a href="#Set" class="headerlink" title="Set"></a>Set</h2><p>字符串的无序集合，使用 Hash 实现（key 和 value 相同的 Hash）</p>
<h3 id="基本使用方法-2"><a href="#基本使用方法-2" class="headerlink" title="基本使用方法"></a>基本使用方法</h3><p>容量：2^32 - 1 个成员</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sadd myset li1 # 向集合myset中添加一个元素li1，若不存在则创建</span><br><span class="line">smembers myset</span><br></pre></td></tr></table></figure>
<h3 id="常见应用-3"><a href="#常见应用-3" class="headerlink" title="常见应用"></a>常见应用</h3><p>全局去重（为什么不用 JDK 自带的 Set 去重？因为我们的系统一般都是集群部署）<br>计算共同喜好、全部喜好、自己独有的喜好等功能（交集、并集、差集）</p>
<h2 id="ZSet"><a href="#ZSet" class="headerlink" title="ZSet"></a>ZSet</h2><p>字符串的有序集合，每个元素都关联一个 double 类型的权重参数 score，集合中的元素能够按 score 进行排列。</p>
<h3 id="基本使用方法-3"><a href="#基本使用方法-3" class="headerlink" title="基本使用方法"></a>基本使用方法</h3><p>容量：2^32 - 1 个成员</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">zadd myzset 0 abc</span><br><span class="line">zrangebyscore myzset 0 10</span><br></pre></td></tr></table></figure>
<h3 id="常见应用-4"><a href="#常见应用-4" class="headerlink" title="常见应用"></a>常见应用</h3><p>排行榜<br>取 Top N 操作<br>延时任务（<a target="_blank" rel="noopener" href="https://www.cnblogs.com/rjzheng/p/8972725.html%EF%BC%89">https://www.cnblogs.com/rjzheng/p/8972725.html）</a><br>范围查找</p>
<h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><p>实现上类似于 Java 的 SortedSet 和 HashMap 的结合体，value 唯一（Set 结构的特点），每个 value 一个 score 代表该 value 的排序权重。<br>zset 内部是使用一种叫做跳跃列表的结构实现的。</p>
<h1 id="Redis-数据结构的实现"><a href="#Redis-数据结构的实现" class="headerlink" title="Redis 数据结构的实现"></a>Redis 数据结构的实现</h1><h2 id="数据结构的声明和实现"><a href="#数据结构的声明和实现" class="headerlink" title="数据结构的声明和实现"></a>数据结构的声明和实现</h2><p><img src="/imgs/Redis/Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%8F%8A%E5%85%B6%E5%AE%9E%E7%8E%B0.png" alt="Redis数据结构及其实现" title="Redis数据结构及其实现"><br>Redis 中的 set、zset 等结构在 Redis 中并不是由一个单独的数据结构实现的，而是会根据情况有所变化。</p>
<h3 id="set"><a href="#set" class="headerlink" title="set"></a>set</h3><p>set和Java中的HashSet有点像，它本身是HashMap的封装，key是集合中的对象，而value直接用NULL代替。<br>但是注意一些特殊情况：</p>
<ul>
<li>创建集合对象时，如果发现集合内的元素可以使用整数（longlong）编码，则创建一个intset而不是dict；</li>
<li>之前是intset编码的情况下，插入的新元素如果是非整数的，那么集合会被重新转换成dict编码的；或者插入的元素数量达到了阈值（512），也会自动转换成dict。<br>创建代码见：<code>t_set.c/setTypeCreate()</code></li>
</ul>
<h3 id="zset"><a href="#zset" class="headerlink" title="zset"></a>zset</h3><p>zset同样有两种形态：ziplist编码和skiplist编码。</p>
<ul>
<li>按ziplist编码的情况下：<br>zset本身就是个ziplist对象。</li>
<li>按skiplist编码的情况下：<br>zset的集合功能是通过dict实现的，这部分和set并无区别；<br>zset的有序性是通过skiplist实现的，skiplist按分值排序成员，支持平均复杂度为O(logN)的按分值定位成员的操作。</li>
</ul>
<p>执行zadd命令代码：<code>t_zset.c/zaddGenericCommand()</code><br>创建zset对象：<code>object.c/createZsetZiplistObject()</code>、<code>object.c/createZsetObject()</code></p>
<h2 id="SDS-Simple-Dynamic-String"><a href="#SDS-Simple-Dynamic-String" class="headerlink" title="SDS(Simple Dynamic String)"></a>SDS(Simple Dynamic String)</h2><p>Redis 中的动态数组有以下特点：</p>
<ul>
<li>可动态扩展内存。sds 表示的字符串其内容可以修改，也可以追加。在很多语言中字符串会分为 mutable 和 immutable 两种，显然 sds 属于 mutable 类型的。</li>
<li>减少修改字符串的内存重新分配次数<br>C语言由于不记录字符串的长度，所以如果要修改字符串，必须要重新分配内存（先释放再申请），因为如果没有重新分配，字符串长度增大时会造成内存缓冲区溢出，字符串长度减小时会造成内存泄露。<br>而对于SDS，由于<code>len</code>属性和<code>free</code>属性的存在，对于修改字符串SDS实现了空间预分配和惰性空间释放两种策略：<br>1、空间预分配：对字符串进行空间扩展的时候，扩展的内存比实际需要的多，这样可以减少连续执行字符串增长操作所需的内存重分配次数。<br>2、惰性空间释放：对字符串进行缩短操作时，程序不立即使用内存重新分配来回收缩短后多余的字节，而是使用 free 属性将这些字节的数量记录下来，等待后续使用。（当然SDS也提供了相应的API，当我们有需要时，也可以手动释放这些未使用的空间。）</li>
<li>二进制安全（Binary Safe）。sds 能存储任意二进制数据，而不仅仅是可打印字符。</li>
<li>与传统的 C 语言字符串类型兼容。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">struct SDS&lt;T&gt; &#123;</span><br><span class="line">  T capacity; // 数组容量</span><br><span class="line">  T len; // 数组当前长度</span><br><span class="line">  byte flags; // 特殊标识位，不理睬它</span><br><span class="line">  byte[] content; // 数组内容</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>下面的函数将 t 数组拷贝到 s 中，如果长度不够则需要进行扩容：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">/* Append the specified binary-safe string pointed by &#x27;t&#x27; of &#x27;len&#x27; bytes to the</span><br><span class="line"> * end of the specified sds string &#x27;s&#x27;.</span><br><span class="line"> *</span><br><span class="line"> * After the call, the passed sds string is no longer valid and all the</span><br><span class="line"> * references must be substituted with the new pointer returned by the call. */</span><br><span class="line">sds sdscatlen(sds s, const void *t, size_t len) &#123;</span><br><span class="line">    size_t curlen = sdslen(s);  // 原字符串长度</span><br><span class="line"></span><br><span class="line">    // 按需调整空间，如果 capacity 不够容纳追加的内容，就会重新分配字节数组并复制原字符串的内容到新数组中</span><br><span class="line">    s = sdsMakeRoomFor(s,len);</span><br><span class="line">    if (s == NULL) return NULL; // 内存不足</span><br><span class="line">    memcpy(s+curlen, t, len);  // 追加目标字符串的内容到字节数组中</span><br><span class="line">    sdssetlen(s, curlen+len); // 设置追加后的长度值</span><br><span class="line">    s[curlen+len] = &#x27;\0&#x27;; // 让字符串以\0 结尾，便于调试打印，还可以直接使用 glibc 的字符串函数进行操作</span><br><span class="line">    return s;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>SDS 有 embstr 和 raw 两种存储结构，它们的区别是：</p>
<ol>
<li>内存分配上：<br>embstr 调用 1 次 malloc, 因此 redisObject 和 SDS 内存是连续分配的；<br>raw 需要调用 2 次 malloc, 因此 redisObject 和 SDS 内存不连续分配</li>
<li>使用上:<br>embstr 整体 64 byte, 正好和<strong>cpu cache line</strong> 64byte 一样, 可以更好的使用缓存, 效率更高</li>
</ol>
<h2 id="quicklist"><a href="#quicklist" class="headerlink" title="quicklist"></a>quicklist</h2><p>Redis 早期版本存储 list 数据结构采用（元素少时 ziplist、多时 linkedlist ）的方案，但是：</p>
<ol>
<li>链表的附加空间太高，prev 和 next 指针就要占去 16 个字节（64 位系统）；</li>
<li>链表每个节点都是单独分配，会加剧内存的碎片化。</li>
</ol>
<p>因此在之后的版本中转换为了 quicklist 存储。<br>quicklist 是 ziplist 和 linkedlist 的混合体，它将 linkedlist 按段切分，每一段使用 ziplist 来紧凑存储，多个 ziplist 之间使用双向指针串接起来。<br><img src="/imgs/Redis/Redis-quicklist%E7%BB%93%E6%9E%84.png" alt="Redis-quicklist结构" title="Redis-quicklist结构"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">struct ziplist &#123;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br><span class="line">struct ziplist_compressed &#123;</span><br><span class="line">    int32 size;</span><br><span class="line">    byte[] compressed_data;</span><br><span class="line">&#125;</span><br><span class="line">struct quicklistNode &#123;</span><br><span class="line">    quicklistNode* prev;</span><br><span class="line">    quicklistNode* next;</span><br><span class="line">    ziplist* zl; // 指向压缩列表</span><br><span class="line">    int32 size; // ziplist 的字节总数</span><br><span class="line">    int16 count; // ziplist 中的元素数量</span><br><span class="line">    int2 encoding; // 存储形式 2bit，原生字节数组还是 LZF 压缩存储</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br><span class="line">struct quicklist &#123;</span><br><span class="line">    quicklistNode* head;</span><br><span class="line">    quicklistNode* tail;</span><br><span class="line">    long count; // 元素总数</span><br><span class="line">    int nodes; // ziplist 节点的个数</span><br><span class="line">    int compressDepth; // LZF 算法压缩深度</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="ziplist"><a href="#ziplist" class="headerlink" title="ziplist"></a>ziplist</h2><p>ziplist 是一种压缩存储的数组结构，当 Redis 中的集合数据结构很小，则它会使用这种紧凑的存储形式存储，元素之间紧挨着存储，查找就是对数组进行遍历找到目标对象。</p>
<ul>
<li>zset 和 hash 容器在元素个数较少时会采用 ziplist 存储。当存储的对象数量小于 512 且所有 entry 的 value 值长度小于 64，采用 ziplist 存储，否则转为采用 hashtable 存储。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">import redis</span><br><span class="line">client = redis.StrictRedis()</span><br><span class="line">client.delete(&quot;hello&quot;)</span><br><span class="line">for i in range(512):</span><br><span class="line">    client.hset(&quot;hello&quot;, str(i), str(i))</span><br><span class="line">print client.object(&quot;encoding&quot;, &quot;hello&quot;)</span><br><span class="line">client.hset(&quot;hello&quot;, &quot;512&quot;, &quot;512&quot;)</span><br><span class="line"># 或者插入一个长度为65的值也能起到转化的作用</span><br><span class="line">print client.object(&quot;encoding&quot;, &quot;hello&quot;)</span><br></pre></td></tr></table></figure></li>
</ul>
<p>可以上服务器上使用<code>debug object</code>命令验证数据结构的类型：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt; zadd hgc_test 1.0 go 2.0 python 2.0 java</span><br><span class="line">...</span><br><span class="line">&gt; debug object hgc_test</span><br><span class="line">Value at:0x7f73c6d673a0 refcount:1 encoding:ziplist serializedlength:36 lru:1381596 lru_seconds_idle:77</span><br></pre></td></tr></table></figure>
<h3 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h3><p><img src="/imgs/Redis/Redis-ziplist%E7%BB%93%E6%9E%84.png" alt="Redis-ziplist结构" title="Redis-ziplist结构"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">struct ziplist&lt;T&gt; &#123;</span><br><span class="line">    int32 zlbytes; // 整个压缩列表占用字节数</span><br><span class="line">    int32 zltail_offset; // 最后一个元素距离压缩列表起始位置的偏移量，用于快速定位到最后一个节点</span><br><span class="line">    int16 zllength; // 元素个数</span><br><span class="line">    T[] entries; // 元素内容列表，挨个挨个紧凑存储</span><br><span class="line">    int8 zlend; // 标志压缩列表的结束，值恒为 0xFF</span><br><span class="line">&#125;</span><br><span class="line">struct entry &#123;</span><br><span class="line">    int&lt;var&gt; prevlen; // 前一个 entry 的字节长度</span><br><span class="line">    int&lt;var&gt; encoding; // 元素类型编码</span><br><span class="line">    optional byte[] content; // 元素内容</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>zltail_offset 字段可以快速定位到 ziplist 中的最后一个节点，可以用于倒序遍历，entry 中的 prevlen 表示前一个 entry 的字节长度，可以用于倒序遍历时找到下一个元素的位置；</li>
<li>encoding 记录编码类型，ziplist 利用该字段决定后面的 content 内容的形式，比如用<code>00xxxxxx</code>表示最大长度为 63 的短字符串，<code>01xxxxxx xxxxxxxx</code>表示中等长度的字符串；</li>
</ul>
<h3 id="插入"><a href="#插入" class="headerlink" title="插入"></a>插入</h3><p>ziplist 是紧凑存储的，没有冗余空间，因此插入一个新元素就需要调用 realloc 重新分配内存空间，并将之前的内容一次性拷贝到新的内存空间中。<br>重新分配空间是比较耗时的，因此 ziplist 不适合存储大量数据。</p>
<h3 id="更新-删除"><a href="#更新-删除" class="headerlink" title="更新&#x2F;删除"></a>更新&#x2F;删除</h3><p>修改或删除一个元素后其后一个位置的元素中的 prevlen 也需要级联更新，prevlen 字段又是变长的，所以可能会导致连锁反应。</p>
<h3 id="ziplist-vs-dict"><a href="#ziplist-vs-dict" class="headerlink" title="ziplist vs dict"></a>ziplist vs dict</h3><p>为什么 hash 结构中会采用 ziplist 而不是 dict，主要原因如下：</p>
<ol>
<li>数据量小时，ziplist 的速度也很快；</li>
<li>数据量大时，ziplist 在每次插入或修改时引发的 realloc 操作会有更大的概率造成内存拷贝，从而降低性能，而且数据项过多的时候，在 ziplist 上查找指定数据项的性能会变得很低，因为在 ziplist 上的查找需要进行遍历。</li>
</ol>
<h2 id="dict（字典）"><a href="#dict（字典）" class="headerlink" title="dict（字典）"></a>dict（字典）</h2><p>dict 是 Redis 中使用最广泛的数据结构：</p>
<ol>
<li>hash 结构的数据会用到字典；</li>
<li>整个 Redis 数据库的所有 key 和 value 也组成了一个全局字典；</li>
<li>带过期时间的 key 集合也是一个字典；</li>
<li>set 结构的底层实现也是字典，只是所有 value 都是 NULL；</li>
<li>zset 集合中存储 value 和 score 值的映射关系也是通过 dict 结构实现的。</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">struct RedisDb &#123;</span><br><span class="line">    dict* dict; // all keys  key=&gt;value</span><br><span class="line">    dict* expires; // all expired keys key=&gt;long(timestamp)</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">struct dict &#123;</span><br><span class="line">    ...</span><br><span class="line">    dictht ht[2];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">struct zset &#123;</span><br><span class="line">    dict *dict; // all values  value=&gt;score</span><br><span class="line">    zskiplist *zsl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="hashtable"><a href="#hashtable" class="headerlink" title="hashtable"></a>hashtable</h3><p>dict 中的 hashtable 结构和 Java 中的 HashMap 类似，使用一个数组来保存所有的哈希桶，通过<strong>siphash</strong>函数来将 key 散列到数组中的某个桶上，每个哈希桶都是一个链表，也就是说如果发生哈希冲突，则将新元素直接插入到桶的头部。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">struct dictEntry &#123;</span><br><span class="line">    void* key;</span><br><span class="line">    void* val;</span><br><span class="line">    dictEntry* next; // 链接下一个 entry</span><br><span class="line">&#125;</span><br><span class="line">struct dictht &#123;</span><br><span class="line">    dictEntry** table; // 二维</span><br><span class="line">    long size; // 第一维数组的长度</span><br><span class="line">    long used; // hash 表中的元素个数</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="扩容：渐进式-rehash"><a href="#扩容：渐进式-rehash" class="headerlink" title="扩容：渐进式 rehash"></a>扩容：渐进式 rehash</h3><p>正常情况下，当 hashtable 中元素的个数等于第一维数组的长度时、来了一个新增&#x2F;修改&#x2F;删除操作，就会触发扩容，扩容的新数组是原数组大小的 2 倍。</p>
<blockquote>
<p>存在一个特殊情况：如果 Redis 正在做 bgsave，为了减少内存页的过多分离 (Copy On Write)，Redis 尽量不去扩容 (<code>dict_can_resize</code>)，但是如果 hash 表已经非常满了，元素的个数已经达到了第一维数组长度的 5 倍 (<code>dict_force_resize_ratio</code>)，说明 hash 表已经过于拥挤了，这个时候就会强制扩容。</p>
</blockquote>
<p><img src="/imgs/Redis/Redis-dict%E6%89%A9%E5%AE%B9rehash.png" alt="Redis-dict扩容rehash" title="Redis-dict扩容rehash"><br>一般情况下 dict 中只有一个 hashtable 有值，但是在扩容时会分配另一个新的 hashtable，然后执行<strong>渐进式</strong>的数据迁移，避免一次性对所有 key 执行 rehash，而是将 rehash 操作分散到了对 dict 的各个增删改查操作中去了。</p>
<ol>
<li>在扩容过程中，如果有新增元素，则该元素会被同时添加到新 hashtable 中；</li>
<li>查询、删除、修改操作中，会先查询旧 hashtable，若存在则迁移这个 key 所在的桶并返回元素，若不存在则到新 hashtable 中查找元素。</li>
<li>有一个异步线程执行定时任务对字典主动迁移。</li>
</ol>
<p>dict 之所以这样设计，是为了避免 rehash 期间单个请求的响应时间剧烈增加。<br>当旧 hashtable 中无元素时，即代表迁移完毕，这时会将新旧 hashtable 的指针交换，旧的会被删除，而新的则取而代之。</p>
<h3 id="缩容"><a href="#缩容" class="headerlink" title="缩容"></a>缩容</h3><p>当 hash 表因为元素的逐渐删除变得越来越稀疏时，Redis 会对 hash 表进行缩容来减少 hash 表的第一维数组空间占用。缩容的条件是元素个数低于数组长度的 10%。<br>缩容不会考虑 Redis 是否正在做 bgsave，因为 COW 的特性是当内存页上的数据被修改时会复制一页做修改，如果删除操作并不会触发删除内存页的数据，操作系统回收内存机制导致的。</p>
<h3 id="全局哈希表"><a href="#全局哈希表" class="headerlink" title="全局哈希表"></a>全局哈希表</h3><p><code>get a</code>和<code>llen b</code>中的a和b是不同数据结构的对象，他们统统被存储在一个叫全局哈希表的地方。<br>哈希表中的每个哈希桶存储的不是值本身，而是指向它们的指针。<br><img src="/imgs/Redis/Redis%E4%B8%AD%E7%9A%84%E5%85%A8%E5%B1%80%E5%93%88%E5%B8%8C%E8%A1%A8.jpg" alt="Redis中的全局哈希表" title="Redis中的全局哈希表"><br>代码定义在：<code>redis.h/redisDb</code></p>
<p>缺点：</p>
<ol>
<li>过多的哈希冲突容易产生过长的哈希桶（哈希冲突链）。<br>为了减少这个问题产生的影响，需要对哈希表进行rehash操作，这个rehash操作和dict数据结构的rehash原理是一样的。<blockquote>
<p>全局哈希表实际上就是dict，可以看源码中的定义。</p>
</blockquote>
</li>
</ol>
<p>优点：</p>
<ol>
<li>合适的散列函数和扩容机制可以保证<code>O(1)</code>的操作复杂度。</li>
</ol>
<h2 id="skiplist"><a href="#skiplist" class="headerlink" title="skiplist"></a>skiplist</h2><p>zset 中除了 dict（字典）外，还会用一个 skiplist 来提供按score排序的要求，以实现指定 score 的范围来获取 value 列表的功能。</p>
<p><img src="/imgs/Redis/Redis-skiplist%E7%BB%93%E6%9E%84.png" alt="Redis-skiplist结构" title="Redis-skiplist结构"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">struct zslnode &#123;</span><br><span class="line">  string value;</span><br><span class="line">  double score;</span><br><span class="line">  zslnode*[] forwards;  // 多层连接指针</span><br><span class="line">  zslnode* backward;  // 回溯指针</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">struct zsl &#123;</span><br><span class="line">  zslnode* header; // 跳跃列表头指针</span><br><span class="line">  int maxLevel; // 跳跃列表当前的最高层</span><br><span class="line">  map&lt;string, zslnode*&gt; ht; // hash 结构的所有键值对</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>各层均为一个有序的链表结构；</li>
<li>层数越大，节点越少；</li>
<li>有一个 header 节点作为哨兵，value&#x3D;null，score&#x3D;Double.MIN_VALUE。</li>
</ul>
<h3 id="插入-1"><a href="#插入-1" class="headerlink" title="插入"></a>插入</h3><p>插入时会先自顶向下找到新节点在跳表中底层的插入位置，插入每一层时都有概率晋升到更高一层，在 Redis 中是 25%。</p>
<h3 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h3><p>删除每一层上的对应节点。</p>
<h3 id="更新"><a href="#更新" class="headerlink" title="更新"></a>更新</h3><p>如果不影响排序则直接更新，否则会先删除再重新插入。 </p>
<h2 id="布隆过滤器"><a href="#布隆过滤器" class="headerlink" title="布隆过滤器"></a>布隆过滤器</h2><h2 id="HyperLogLog"><a href="#HyperLogLog" class="headerlink" title="HyperLogLog"></a>HyperLogLog</h2><p>布隆过滤器用于实现<code>contains</code>的需求，而 HyperLogLog 主要用于实现<code>count</code>。<br>同样是一个特别大的位数组，HyperLogLog 将位数组拆分为桶，每个桶是连续的 6 个位，计数时并非单独对某个桶计数，而是：</p>
<ul>
<li>set 操作：计算 key 的散列值，为一个 64 位的数字，前 14 位是桶的位置，桶记录后 50 位中第一个 1 的位置 count，并且<code>count = max(count, oldCount)</code>，即每次记录最大的计数。</li>
<li>count 操作：因为是概率算法，每个桶的计数值并不精确，但是所有桶的调和均值非常接近真实的计数值。</li>
</ul>
<h2 id="pubsub"><a href="#pubsub" class="headerlink" title="pubsub"></a>pubsub</h2><p>用于实现轻量级的发布订阅功能。</p>
<h2 id="geohash"><a href="#geohash" class="headerlink" title="geohash"></a>geohash</h2><h1 id="QA"><a href="#QA" class="headerlink" title="QA"></a>QA</h1><h2 id="使用string还是hash？"><a href="#使用string还是hash？" class="headerlink" title="使用string还是hash？"></a>使用string还是hash？</h2><p>当数据量少时，使用hash明显更加节省内存，因为数据少时hash会转成ziplist的结构，而string每个kv都需要一大堆的额外空间存储元数据。</p>
<h2 id="如何使用Redis的数据结构实现统计？"><a href="#如何使用Redis的数据结构实现统计？" class="headerlink" title="如何使用Redis的数据结构实现统计？"></a>如何使用Redis的数据结构实现统计？</h2><ol>
<li>需要支持集合运算（差集、交集、并集）的场合<br>使用set、zset，数据量少时会转成ziplist节省内存。</li>
<li>需要进行二值统计的场合<br>使用bitmap</li>
<li>需要大规模统计，且不要求精确统计的场合<br>使用HyperLogLog</li>
</ol>
<h2 id="采用渐进式hash时，如果实例暂时没有接收到新请求，是不是就不会做rehash了？"><a href="#采用渐进式hash时，如果实例暂时没有接收到新请求，是不是就不会做rehash了？" class="headerlink" title="采用渐进式hash时，如果实例暂时没有接收到新请求，是不是就不会做rehash了？"></a>采用渐进式hash时，如果实例暂时没有接收到新请求，是不是就不会做rehash了？</h2><p>不会，还有一个定时任务每隔100ms执行rehash，而且每次执行时长不会超过1ms，以免影响其他任务。</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ol>
<li><a target="_blank" rel="noopener" href="https://redissrc.readthedocs.io/en/latest/">redis源码解析</a></li>
</ol>
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kity@2.0.4/dist/kity.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text/javascript" src="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.6.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.6.0/dist/mindmap.min.css">
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/df2941e1.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="tallate">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Tallate">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/df2941e1.html" class="post-title-link" itemprop="url">Redis 概述</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2019-09-22 12:21:48" itemprop="dateCreated datePublished" datetime="2019-09-22T12:21:48+08:00">2019-09-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-07-07 01:56:20" itemprop="dateModified" datetime="2025-07-07T01:56:20+08:00">2025-07-07</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%BC%93%E5%AD%98/" itemprop="url" rel="index"><span itemprop="name">缓存</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <span id="more"></span>

<p><img src="/imgs/Redis/Redis%E6%9E%B6%E6%9E%84%E5%9B%BE.jpg" alt="Redis架构图" title="Redis架构图"><br><img src="/imgs/Redis/Redis%E7%9F%A5%E8%AF%86%E6%A1%86%E6%9E%B6.jpeg" alt="Redis知识框架" title="Redis知识框架"><br><img src="/imgs/Redis/Redis%E9%97%AE%E9%A2%98%E7%94%BB%E5%83%8F.jpg" alt="Redis问题画像" title="Redis问题画像"></p>
<blockquote>
<p>以上图片来自极客时间的《Redis核心技术与实战》。<br>对原理的分析都是基于Redis3.0版本的代码，现在最新的版本应该是6.0，很多功能都是后面的版本引入的，因此这篇里不会描述多线程这些功能。</p>
</blockquote>
<h2 id="为什么使用-Redis"><a href="#为什么使用-Redis" class="headerlink" title="为什么使用 Redis"></a>为什么使用 Redis</h2><h3 id="Redis-的缺点-优点"><a href="#Redis-的缺点-优点" class="headerlink" title="Redis 的缺点 &amp; 优点"></a>Redis 的缺点 &amp; 优点</h3><p>特性及优势：</p>
<ol>
<li>内存数据库，吞吐率不受磁盘影响；</li>
<li>每秒可以处理超过 10 万次读写操作；</li>
<li>多数据结构支持，包括 string、hash、list、set、zset、Bitmaps、Hyperloglog、Geo、Pub&#x2F;Sub、Redis Module、BloomFilter、RedisSearch、Redis-ML 等，支持绝大多数应用场景；</li>
<li>Replication（复制）；</li>
<li>lua（支持服务端执行复杂的业务逻辑）；</li>
<li>LRU eviction（缓存淘汰）；</li>
<li>Transactions；</li>
<li>Persistence（持久化），包括 rdb（快照）和 AOF 两种；</li>
<li>Sentinel（哨兵）；</li>
<li>Cluster（分区）。</li>
</ol>
<p>但是也不能忽略 Redis 本身的一些缺点：</p>
<ol>
<li>数据库容量受到物理内存的限制，不能用作海量数据的高性能读写，因此 Redis 适合的场景主要局限在较小数据量的高性能操作和运算上；</li>
<li>缓存和数据库双写一致性问题；</li>
<li>缓存雪崩问题；</li>
<li>缓存击穿问题；</li>
<li>缓存的并发竞争问题。</li>
</ol>
<h3 id="Redis-Memcached"><a href="#Redis-Memcached" class="headerlink" title="Redis &amp; Memcached"></a>Redis &amp; Memcached</h3><p>Redis 相对 Memcached 来说有以下优点：</p>
<ol>
<li>memcached 所有的值均是简单的字符串，redis 作为其替代者，支持更为丰富的数据类型 </li>
<li>redis 的速度比 memcached 快很多</li>
<li>redis 可以持久化其数据</li>
</ol>
<p>Redis 和 Memcached 之间存在以下区别：</p>
<ol>
<li>存储方式 Memecache 把数据全部存在内存之中，断电后会挂掉，数据不能超过内存大小。 Redis 有部份存在硬盘上，这样能保证数据的持久性。 </li>
<li>数据支持类型 Memcache 对数据类型支持相对简单。 Redis 有复杂的数据类型。 </li>
<li>使用底层模型不同 它们之间底层实现方式 以及与客户端之间通信的应用协议不一样。 Redis 直接自己构建了 VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求。</li>
</ol>
<h3 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h3><ol>
<li>会话缓存（Session Cache）<br>最常用的一种使用 Redis 的情景是会话缓存（session cache）。用 Redis 缓存会话比其他存储（如 Memcached）的优势在于：Redis 提供持久化。当维护一个不是严格要求一致性的缓存时，如果用户的购物车信息全部丢失，大部分人都会不高兴的，现在，他们还会这样吗？<br>幸运的是，随着 Redis 这些年的改进，很容易找到怎么恰当的使用 Redis 来缓存会话的文档。甚至广为人知的商业平台 Magento 也提供 Redis 的插件。</li>
<li>全页缓存（FPC）<br>除基本的会话 token 之外，Redis 还提供很简便的 FPC 平台。回到一致性问题，即使重启了 Redis 实例，因为有磁盘的持久化，用户也不会看到页面加载速度的下降，这是一个极大改进，类似 PHP 本地 FPC。<br>再次以 Magento 为例，Magento 提供一个插件来使用 Redis 作为全页缓存后端。<br>此外，对 WordPress 的用户来说，Pantheon 有一个非常好的插件 wp-redis，这个插件能帮助你以最快速度加载你曾浏览过的页面。</li>
<li>队列<br>Reids 在内存存储引擎领域的一大优点是提供 list 和 set 操作，这使得 Redis 能作为一个很好的消息队列平台来使用。Redis 作为队列使用的操作，就类似于本地程序语言（如 Python）对 list 的 push&#x2F;pop 操作。<br>当然要将 Redis 作为消息队列投入生产环境还有很多设计要点，比如采用 sleep 一段时间重试还是 blpop 阻塞、主题订阅、如何应对消费者下线导致的消息丢失问题（如何保证消息一定能被消费）等。<br>Redis 作为消息队列坑比较多，如果希望少点麻烦且对服务质量有一定要求，最好还是采用 RocketMQ 这些比较成熟的方案。</li>
<li>延时队列<br>使用 zset，时间戳作为 score，消费者用 zrangebyscore 指令获取 N 秒之前的数据轮询进行处理，这种思路和 JDK 中的 ScheduledThreadPoolExecutor 有点像。</li>
<li>排行榜&#x2F;计数器<br>Redis 在内存中对数字进行递增或递减的操作实现的非常好。集合（Set）和有序集合（Sorted Set）也使得我们在执行这些操作的时候变的非常简单，Redis 只是正好提供了这两种数据结构。所以，我们要从排序集合中获取到排名最靠前的 10 个用户–我们<br>称之为“user_scores”，我们只需要像下面一样执行即可：<br>当然，这是假定你是根据你用户的分数做递增的排序。如果你想返回用户及用户的分数，你需要这样执行：<br>ZRANGE user_scores 0 10 WITHSCORES<br>Agora Games 就是一个很好的例子，用 Ruby 实现的，它的排行榜就是使用 Redis 来存储数据的，你可以在这里看到。</li>
<li>发布&#x2F;订阅<br>最后（但肯定不是最不重要的）是 Redis 的发布&#x2F;订阅功能。发布&#x2F;订阅的使用场景确实非常多。我已看见人们在社交网络连接中使用，还可作为基于发布&#x2F;订阅的脚本触发器，甚至用 Redis 的发布&#x2F;订阅功能来建立聊天系统！（不，这是真的，你可以去核实）。<br>Redis 提供的所有特性中，我感觉这个是喜欢的人最少的一个，虽然它为用户提供如果此多功能。</li>
<li>分布式锁<br>不要用 setnx+expire，因为如果进程 crash 或重启这个锁就直接失效了。实际上 set 命令本身就包含超时和 cas 的设置。</li>
<li>扫描<br>如果 Redis 中有 1 亿多个 key，其中有 10W+个 key 有固定的前缀（这种场景非常常见），如何将它们全部找出来？<br>由于 Redis 的单线程特性，使用 keys 可能会阻塞 Redis 进程，最好换成 scan 命令，不过可能提取出的部分 key 是重复的，需要客户端做去重。</li>
</ol>
<h2 id="QA"><a href="#QA" class="headerlink" title="QA"></a>QA</h2><h3 id="Redis与其他KV存储有何不同？"><a href="#Redis与其他KV存储有何不同？" class="headerlink" title="Redis与其他KV存储有何不同？"></a>Redis与其他KV存储有何不同？</h3><ul>
<li>更多复杂的数据结构，支持更多特殊的场景；</li>
<li>Redis是内存数据库，但是支持持久化到磁盘。</li>
</ul>
<h3 id="有人说-Redis-只适合用来做缓存，当数据库来用并不合适，为什么？"><a href="#有人说-Redis-只适合用来做缓存，当数据库来用并不合适，为什么？" class="headerlink" title="有人说 Redis 只适合用来做缓存，当数据库来用并不合适，为什么？"></a>有人说 Redis 只适合用来做缓存，当数据库来用并不合适，为什么？</h3><p>Redis 的事务并不严格：<br>    * A(原子性)：Redis 支持事务，所有命令会被保存到一个事务队列中，服务器接收到 exec 时才会被真正执行，注意如果中间出错，事务不会回滚，后面的指令还会继续执行；而且如果涉及到复杂的逻辑判断，则只能通过<strong>lua 脚本</strong>实现“伪原子性”，说它是“伪原子性”是因为虽然脚本可以一次性执行多条命令，如果中间某个命令出错还是会无法保证“要么全部执行，要么都不执行”的要求。<br>    * I(隔离性)：Redis 是单线程模型，因此可以保证隔离性。<br>    * D(持久性)：Redis 是内存数据库，服务器意外崩溃会导致内存中的数据丢失，除非开启 AOF，并且配置成每次写入都记日志，但是这样又会极大地影响效率，所以一般会配置成混合模式的持久化。</p>
<h3 id="Redis会占用多少内存空间？"><a href="#Redis会占用多少内存空间？" class="headerlink" title="Redis会占用多少内存空间？"></a>Redis会占用多少内存空间？</h3><ul>
<li>An empty instance uses ~ 3MB of memory.</li>
<li>1 Million small Keys -&gt; String Value pairs use ~ 85MB of memory.<br>那么10亿个kv，大概就会占用85G的内存了。</li>
<li>1 Million Keys -&gt; Hash value, representing an object with 5 fields, use ~ 160 MB of memory.</li>
</ul>
<p>64位机器会占用比32位机器更多的内存，因为指针在64位机器上占用更多空间，但同时64位机器也可以有更大的内存空间。</p>
<h3 id="Redis-的底层数据结构有哪些"><a href="#Redis-的底层数据结构有哪些" class="headerlink" title="Redis 的底层数据结构有哪些"></a>Redis 的底层数据结构有哪些</h3><p>sds：string 使用，变长字符串，不够的情况下重新分配空间并将老字符串数据拷贝过去；<br>dict：字典应用很多，包括 Redis 数据库中保存所有 key-value、hash、set、zset。dict 类似 Java 中的 HashMap，将 key 散列到哈希桶数组中，每个哈希桶都是一个链表，插入就是插入到链表头部，当元素超过了容量的一半后会启动渐进式 rehash 进行扩容。<br>ziplist：相当于一个数组，查询时需要遍历一次，每次插入都需要 realloc 重新分配一个新的更大的数组，然后把老数组内容拷贝过去。<br>quicklist：由于 linkedlist 附加空间成本高且容易产生碎片，因此 Redis 里的 quicklist 设计成了 linkedlist 和 ziplist 的结合，它将 linkedlist 按段切分，每一段使用 ziplist 存储；<br>skiplist：skiplist 用于实现 zset 中按 score 排序的要求，插入时先自顶向下查位置，然后按概率计算该节点应该分配到几层。</p>
<h3 id="存储数据选择-string-还是-hash？"><a href="#存储数据选择-string-还是-hash？" class="headerlink" title="存储数据选择 string 还是 hash？"></a>存储数据选择 string 还是 hash？</h3><p>从业务层面来看，如果要存好多字段的对象、而且这个对象的每个字段都会单独拿出来用，则可以考虑使用 hash，否则没有太多限制条件。<br>从性能角度来看，如果存的字段少，hash 会使用 ziplist 结构存储，性能多少受点影响，而且还要考虑转换结构和渐进式扩容对性能的损耗。<br>从节约空间的角度来看，string 的 key 一般都会加个前缀，一般会比 hash 占用更多的空间，不过差距不大。</p>
<h3 id="设计-redis-排序，数据结构是金额-花钱的时间，金额越大，时间越早越靠前"><a href="#设计-redis-排序，数据结构是金额-花钱的时间，金额越大，时间越早越靠前" class="headerlink" title="设计 redis 排序，数据结构是金额+花钱的时间，金额越大，时间越早越靠前"></a>设计 redis 排序，数据结构是金额+花钱的时间，金额越大，时间越早越靠前</h3><p>用 zset 存，score 是金额拼上时间，金额放高位，MAX_INT 和时间作差放低位，查询时使用<code>ZREVRANGE</code>命令查询。</p>
<h3 id="hash-中哈希冲突怎么解决的"><a href="#hash-中哈希冲突怎么解决的" class="headerlink" title="hash 中哈希冲突怎么解决的"></a>hash 中哈希冲突怎么解决的</h3><p>分两种情况：hash 在数据量小时结构是 ziplist，这时插入不会做冲突检测，插入到目标位置后就向后统一移动数据，给新插入的数据项流出空间；在数据量大时结构是 dict，这种结构和 Java 中的 HashMap 类似，使用链表来处理冲突。</p>
<ol>
<li>说说 Redis 为什么那么快。<br>单线程模型-&gt;减少了线程间上下文切换的开销。<br>多路复用的 IO 模型-&gt;单线程监控多个连接。</li>
<li>为什么 Redis 记录 AOF 日志是先执行指令然后再记录 AOF 日志？而不是像其他存储引擎一样反过来？<br>主要是因为 Redis 本身是缓存而不是 db，侧重点不同，db 先写日志是为了失败回滚，而 Redis 持久化是一个附加功能，只能保证数据不会完全丢失。</li>
</ol>
<h3 id="Redis-淘汰时，如果读取，会不会数据不完整"><a href="#Redis-淘汰时，如果读取，会不会数据不完整" class="headerlink" title="Redis 淘汰时，如果读取，会不会数据不完整"></a>Redis 淘汰时，如果读取，会不会数据不完整</h3><p>redis 的淘汰分两种：</p>
<ul>
<li>一种是过期，这种不会导致这种问题，因为查询时会判断下过期时间，过期了就不返回；</li>
<li>另一种是超过内存容量淘汰，比如 LRU，这种也不会导致这种问题，因为执行每个命令时都会检查下缓存是否超出了阈值，可见代码<code>server.c/processCommand</code>：<br><img src="/imgs/Redis/Redis-%E6%89%A7%E8%A1%8C%E5%91%BD%E4%BB%A4%E5%89%8D%E6%A3%80%E6%9F%A5%E7%BC%93%E5%AD%98%E6%98%AF%E5%90%A6%E6%BA%A2%E5%87%BA.jpeg" alt="Redis-执行命令前检查缓存是否溢出" title="Redis-执行命令前检查缓存是否溢出"></li>
</ul>
<h3 id="Redis-的持久化原理是什么"><a href="#Redis-的持久化原理是什么" class="headerlink" title="Redis 的持久化原理是什么"></a>Redis 的持久化原理是什么</h3><p>Redis 有两种持久化方式：RDB 和 AOF<br>RDB 是快照，AOF 记录了写操作，效率起见，一般 RDB 作为 checkpoint，checkpoint 后的数据通过 AOF 恢复。</p>
<h3 id="RDB-和-AOF-之间的区别"><a href="#RDB-和-AOF-之间的区别" class="headerlink" title="RDB 和 AOF 之间的区别"></a>RDB 和 AOF 之间的区别</h3><p>RDB 二进制文件可以直接加载到内存速度较快；AOF 要重放命令，所以速度比较慢。<br>RDB 需要全量备份，AOF 可以增量备份，二者的应用场景不同。</p>
<h3 id="Redis的复制原理是什么？"><a href="#Redis的复制原理是什么？" class="headerlink" title="Redis的复制原理是什么？"></a>Redis的复制原理是什么？</h3><p>master 会启动一个后台进程进行持久化（RDB or AOF），第一次连接时会将 RDB 文件发给 slave，slave 先保存到磁盘，之后加载到内存中；如果不是第一次连接，slave 连接 master 后通过 PSYNC 命令告知自己同步的起始位置，master 将增量部分 AOF 文件发送给 slave。</p>
<h3 id="Redis-持久化期间，主进程还能对外提供服务吗？为什么"><a href="#Redis-持久化期间，主进程还能对外提供服务吗？为什么" class="headerlink" title="Redis 持久化期间，主进程还能对外提供服务吗？为什么"></a>Redis 持久化期间，主进程还能对外提供服务吗？为什么</h3><p>能。<br>因为 Redis 的复制是通过 fork 子进程实现的，父进程仍然可以接收请求。</p>
<h3 id="持久化期间，Redis如何处理新写入的数据呢，这个数据也会直接进行持久化吗？"><a href="#持久化期间，Redis如何处理新写入的数据呢，这个数据也会直接进行持久化吗？" class="headerlink" title="持久化期间，Redis如何处理新写入的数据呢，这个数据也会直接进行持久化吗？"></a>持久化期间，Redis如何处理新写入的数据呢，这个数据也会直接进行持久化吗？</h3><p>不会。<br>因为 Redis 复制是通过 fork 子进程实现的，由于 COW 机制，子进程只能看到老数据。</p>
<h3 id="主从复制为什么会发生延迟？怎么解决"><a href="#主从复制为什么会发生延迟？怎么解决" class="headerlink" title="主从复制为什么会发生延迟？怎么解决"></a>主从复制为什么会发生延迟？怎么解决</h3><p>延迟无法避免，比如主从之间的网络抖动、slave 发生阻塞（如 IO）等情况。<br>解决办法有两种：</p>
<ul>
<li><code>min-slave-to-write N</code>和<code>min-slave-max-lag M</code>，控制 Master，只有在至少有 N 个 slave 正在工作，并且滞后时间均小于 M 秒的情况下，Master 将不接受写入请求；</li>
<li><code>slave-serve-stale-data</code>，控制从库对主库失去响应或复制进行过程中从库的表现，为 yes 则从库会继续响应客户端的请求，为 no 则除去 INFO 和 SLAVOF 命令之外的任何请求都会返回一个错误<code>SYNC with master in progress</code>；</li>
<li>编写外部监控程序，如果某个 slave 延迟较大，则通知 client 不要读这个 slave。</li>
</ul>
<h3 id="Redis-怎么实现高可用"><a href="#Redis-怎么实现高可用" class="headerlink" title="Redis 怎么实现高可用"></a>Redis 怎么实现高可用</h3><p>从复制、Sentinel 到 Cluster</p>
<h3 id="sentinel-中，使用客户端是怎么连接服务器的？（Redisson-配置）"><a href="#sentinel-中，使用客户端是怎么连接服务器的？（Redisson-配置）" class="headerlink" title="sentinel 中，使用客户端是怎么连接服务器的？（Redisson 配置）"></a>sentinel 中，使用客户端是怎么连接服务器的？（Redisson 配置）</h3><p>见《Redis 客户端》。</p>
<h3 id="哈希槽原理？和一致性哈希的区别？怎么落点"><a href="#哈希槽原理？和一致性哈希的区别？怎么落点" class="headerlink" title="哈希槽原理？和一致性哈希的区别？怎么落点"></a>哈希槽原理？和一致性哈希的区别？怎么落点</h3><p>redis cluster 默认分配了 16384 个 slot，当我们 set 一个 key 时，会用<strong>CRC16</strong>算法来取模得到所属的 slot，然后将这个 key 分到哈希槽区间的节点上，具体算法就是：<code>CRC16(key) % 16384</code>。所以我们在测试的时候看到 set 和 get 的时候，直接跳转到了 7000 端口的节点。<br>哈希槽与一致性哈希的区别：哈希槽由客户端来重定向到目标 slot 所在节点，一致性哈希需要由服务器端重定向到目标节点，而且需要按顺时针方向一个一个节点递归地找。</p>
<h3 id="Redis雪崩、击穿、穿透等现象是怎么出现的？怎么解决"><a href="#Redis雪崩、击穿、穿透等现象是怎么出现的？怎么解决" class="headerlink" title="Redis雪崩、击穿、穿透等现象是怎么出现的？怎么解决"></a>Redis雪崩、击穿、穿透等现象是怎么出现的？怎么解决</h3><ol>
<li>缓存穿透<br>缓存穿透指查询一个不存在的数据，出于容错考虑这个查询会穿透到 DB 层，如果这种带穿透的查询特别多可能会把 DB 打挂掉。<br>解决办法：使用布隆过滤器，保存所有可能存在的数据到一个足够大的 bitmap 中，由于布隆过滤器的特性，一定不存在的数据在 bitmap 中一定找不到，从而可以很大程度上避免对底层存储系统的查询压力；还有一种更简单的方法，就是在查询返回结果为空时也把这个空结果缓存起来，但是它的过期时间会短一些，最长时间不超过 5 分钟。</li>
<li>缓存雪崩<br>缓存雪崩指的是设置缓存时采用了相同的过期时间，导致缓存在同一时间同时失效，请求全部打到 DB，DB 瞬时压力过大导致雪崩。<br>解决办法：缓存失效时间随机化，在原有失效时间基础上加上一个随机值，可以使得过期时间的重复率降低；加锁并令请求排队，使得请求串行化，避免所有请求都查询数据库，不过这样会导致性能的降低。</li>
<li>缓存击穿<br>缓存击穿指的是某个 key 在过期时正好有大量请求访问该 key，这些请求会同时回表，可能会瞬间将后端 DB 打挂。<br>解决办法：使用互斥锁，缓存失效时先加锁，避免并发回表；一些长时间不变的数据完全可以不设置过期时间，或者过期时间特别长。</li>
</ol>
<h3 id="主从复制的流程？传的是文件吗？"><a href="#主从复制的流程？传的是文件吗？" class="headerlink" title="主从复制的流程？传的是文件吗？"></a>主从复制的流程？传的是文件吗？</h3><p>流程见《主从同步》。<br>如果是全量同步，同步时会先同步 RDB 文件，再同步增量写命令；<br>如果是部分重同步，则只同步增量写命令。</p>
<h3 id="中间传输失败怎么办？中间传输不一致怎么办"><a href="#中间传输失败怎么办？中间传输不一致怎么办" class="headerlink" title="中间传输失败怎么办？中间传输不一致怎么办"></a>中间传输失败怎么办？中间传输不一致怎么办</h3><p>如果上次传输中断，则下次同步时从中断位置开始执行部分重同步。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li><a target="_blank" rel="noopener" href="https://redis.io/topics/faq">FAQ</a></li>
<li><a target="_blank" rel="noopener" href="https://www.cxc233.com/blog/e1d54234.html">使用vscode(gdb)调试redis</a></li>
</ol>
<h3 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h3><ol>
<li><a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/16375188/redis-strings-vs-redis-hashes-to-represent-json-efficiency">Redis strings vs Redis hashes to represent JSON: efficiency?</a></li>
</ol>
<h3 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h3><ol>
<li><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/4992bed65b22">Redis 源码涉及 C 语言</a></li>
<li><a target="_blank" rel="noopener" href="http://mp.weixin.qq.com/s?__biz=MzA4NTg1MjM0Mg==&mid=2657261203&idx=1&sn=f7ff61ce42e29b874a8026683875bbb1&scene=21#wechat_redirect">Redis 内部数据结构详解(1)——dict</a></li>
<li><a target="_blank" rel="noopener" href="http://mp.weixin.qq.com/s?__biz=MzA4NTg1MjM0Mg==&mid=2657261213&idx=1&sn=0ddddf48929610a4155bd82794cad4fa&scene=21#wechat_redirect">Redis 内部数据结构详解(2)——sds</a></li>
<li><a target="_blank" rel="noopener" href="http://mp.weixin.qq.com/s?__biz=MzA4NTg1MjM0Mg==&mid=2657261237&idx=1&sn=380d183332d41d24ea6f88a54f533fc3&scene=21#wechat_redirect">Redis 内部数据结构详解(3)——robj</a></li>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=MzA4NTg1MjM0Mg==&mid=2657261265&idx=1&sn=e105c4b86a5640c5fc8212cd824f750b&scene=21#wechat_redirect">Redis 内部数据结构详解(4)——ziplist</a></li>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=MzA4NTg1MjM0Mg==&mid=2657261335&idx=1&sn=053d72a348be2e78040f3847f4092d92&scene=21#wechat_redirect">Redis 内部数据结构详解(5)——quicklist</a></li>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=MzA4NTg1MjM0Mg==&mid=2657261457&idx=1&sn=fe966f3825b81e9d50a2cf38dac9060c&chksm=84479e48b330175ea07905e791856cca5fc50694db9fd4c3485ba5dc097443e69f5ed28a34b5&scene=21#wechat_redirect">Redis 为什么用跳表而不用平衡树？</a></li>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=MzA4NTg1MjM0Mg==&mid=2657261457&idx=1&sn=fe966f3825b81e9d50a2cf38dac9060c&chksm=84479e48b330175ea07905e791856cca5fc50694db9fd4c3485ba5dc097443e69f5ed28a34b5&scene=21#wechat_redirect">Redis 中的集合类型是怎么实现的？</a></li>
</ol>
<h3 id="Persistence"><a href="#Persistence" class="headerlink" title="Persistence"></a>Persistence</h3><ol>
<li><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/c210851d3558">剖析 Redis RDB 文件</a></li>
<li><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/131cf929a262">Redis 源码分析–RDB 实现源码阅读</a></li>
<li><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/90cdd28c5e92">Redis 源码分析–AOF 文件全量重写源码阅读</a></li>
<li><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/91cf48c8c082">Redis 源码分析–AOF 文件增量追写源码阅读</a></li>
</ol>
<h3 id="客户端"><a href="#客户端" class="headerlink" title="客户端"></a>客户端</h3><ol>
<li><a target="_blank" rel="noopener" href="http://www.redis.cn/topics/clients.html">Redis 如何处理客户端连接</a></li>
<li><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/36a5935db85b">剖析 Redis 协议</a></li>
<li><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/78b94407f59c">剖析 Redis 协议(续)</a></li>
</ol>
<h3 id="主从复制"><a href="#主从复制" class="headerlink" title="主从复制"></a>主从复制</h3><ol>
<li><a target="_blank" rel="noopener" href="http://www.redis.cn/topics/replication.html">复制</a></li>
<li><a target="_blank" rel="noopener" href="https://www.cnblogs.com/wdliu/p/9407179.html">redis 系列–主从复制以及 redis 复制演进</a></li>
</ol>
<h3 id="Sentinel-Cluster"><a href="#Sentinel-Cluster" class="headerlink" title="Sentinel &amp; Cluster"></a>Sentinel &amp; Cluster</h3><ol>
<li><a target="_blank" rel="noopener" href="http://www.redis.cn/topics/partitioning.html">分区：怎样将数据分布到多个 redis 实例</a></li>
<li><a target="_blank" rel="noopener" href="http://www.redis.cn/topics/sentinel.html">Redis 的 Sentinel 文档</a></li>
<li><a target="_blank" rel="noopener" href="http://www.redis.cn/topics/cluster-tutorial.html">Redis 集群教程</a></li>
<li><a target="_blank" rel="noopener" href="http://www.redis.cn/topics/cluster-spec.html">Redis 集群规范</a></li>
<li><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/4163916a2a8a">一致性哈希和哈希槽对比</a></li>
<li><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/145215dc3440">Redis 集群扩容和缩容</a></li>
</ol>
<h3 id="架构迁移"><a href="#架构迁移" class="headerlink" title="架构迁移"></a>架构迁移</h3><ol>
<li><a target="_blank" rel="noopener" href="http://www.redis.cn/articles/20170830103.html">Redis 集群迁移案例</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/vipshop/redis-migrate-tool">redis-migrate-tool</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/CodisLabs/redis-port">redis-port</a></li>
<li>redis-migration<br><a target="_blank" rel="noopener" href="https://github.com/helifu/redis-migration">redis-migration</a><br><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=MzAxNjc1MTk5Nw==&mid=401404354&idx=1&sn=36225e1e72aa1402d2fb79928addadd9&scene=1&srcid=0304rSI42ziy0Qfb9wvNDzBi&key=8dcebf9e179c9f3a6f34ddb7f5de1b77fe12f5078f6a2ac7bf9f7c0d8485989ab2d848694250dec6c20a3f96f42c0e09&ascene=0&uin=MzM4Njg2NDU1&devicetype=iMac+MacBookPro12,1+OSX+OSX+10.10.3+build(14D136)&version=11020201&pass_ticket=MGWnMZAOg9KlbJTWgO9ARaZA3po2c+LDVDHD6Xtt9cZYpjpc9ygP+pjWQz3D6NBE">redis-migration：独创的 redis 在线数据迁移工具</a></li>
</ol>
<h3 id="Twemproxy"><a href="#Twemproxy" class="headerlink" title="Twemproxy"></a>Twemproxy</h3><ol>
<li><a target="_blank" rel="noopener" href="https://github.com/twitter/twemproxy">Twemproxy</a></li>
</ol>
<h3 id="Codis"><a href="#Codis" class="headerlink" title="Codis"></a>Codis</h3><ol>
<li><a target="_blank" rel="noopener" href="https://github.com/CodisLabs/codis">Codis</a></li>
</ol>
<h3 id="Redisson"><a href="#Redisson" class="headerlink" title="Redisson"></a>Redisson</h3><ol>
<li><a target="_blank" rel="noopener" href="https://github.com/redisson/redisson">Redisson</a></li>
</ol>
<h3 id="系统优化"><a href="#系统优化" class="headerlink" title="系统优化"></a>系统优化</h3><ol>
<li><a target="_blank" rel="noopener" href="https://www.oschina.net/translate/redis-latency-problems-troubleshooting?lang=chs&p=1">Redis 响应延迟问题排查</a></li>
</ol>
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kity@2.0.4/dist/kity.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text/javascript" src="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.6.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.6.0/dist/mindmap.min.css">
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/9dda6023.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="tallate">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Tallate">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/9dda6023.html" class="post-title-link" itemprop="url">Redis 进程和 IO 模型</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2019-09-22 12:21:48" itemprop="dateCreated datePublished" datetime="2019-09-22T12:21:48+08:00">2019-09-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-07-07 01:56:20" itemprop="dateModified" datetime="2025-07-07T01:56:20+08:00">2025-07-07</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%BC%93%E5%AD%98/" itemprop="url" rel="index"><span itemprop="name">缓存</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <span id="more"></span>


<h2 id="为什么-Redis-这么快"><a href="#为什么-Redis-这么快" class="headerlink" title="为什么 Redis 这么快"></a>为什么 Redis 这么快</h2><p>Redis 采用的是一种<strong>单线程工作模型</strong>，它能这么快主要归功于下面几个策略：</p>
<ol>
<li>完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于 HashMap，HashMap 的优势就是查找和操作的时间复杂度都是 O(1)；</li>
<li>数据结构简单，对数据操作也简单，Redis 中的数据结构是专门进行设计的；</li>
<li>采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗；</li>
<li>使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis 直接自己构建了 VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求；</li>
<li>使用<strong>多路 I&#x2F;O 复用</strong>模型，非阻塞 IO；<br>多路 I&#x2F;O 复用模型是利用 select、poll、epoll 可以同时监察多个流的 I&#x2F;O 事件的能力，在空闲的时候，会把当前线程阻塞掉，当有一个或多个流有 I&#x2F;O 事件时，就从阻塞态中唤醒，于是程序就会轮询一遍所有的流（epoll 是只轮询那些真正发出了事件的流），并且只依次顺序的处理就绪的流，这种做法就避免了大量的无用操作。<br>Redis-Client 在操作的时候，会产生具有不同事件类型的 socket，在服务端，有一段 I&#x2F;O 多路复用程序，将其置入队列之中，然后，文件事件分派器依次去队列中取，转发到不同的事件处理器中（对这个 I&#x2F;O 多路复用机制，Redis 还提供了 select、epoll、evport、kqueue 等多路复用函数库）。<br>这里“多路”指的是多个网络连接，“复用”指的是复用同一个线程。采用多路 I&#x2F;O 复用技术可以让单个线程高效的处理多个连接请求（尽量减少网络 IO 的时间消耗），且 Redis 在内存中操作数据的速度非常快，也就是说内存内的操作不会成为影响 Redis 性能的瓶颈，主要由以上几点造就了 Redis 具有很高的吞吐量。<br><img src="/imgs/Redis/%E5%A4%9A%E8%B7%AFIO%E5%A4%8D%E7%94%A8%E6%A8%A1%E5%9E%8B.jpg" alt="多路IO复用模型" title="多路IO复用模型"></li>
</ol>
<h2 id="一些常见的进程模型"><a href="#一些常见的进程模型" class="headerlink" title="一些常见的进程模型"></a>一些常见的进程模型</h2><ol>
<li>单进程多线程模型：MySQL、Memcached、Oracle（Windows 版本）；</li>
<li>多进程模型：Oracle（Linux 版本）；</li>
<li>Nginx 有两类进程，一类称为 Master 进程(相当于管理进程)，另一类称为 Worker 进程（实际工作进程）。启动方式有两种：<ol>
<li>单进程启动：此时系统中仅有一个进程，该进程既充当 Master 进程的角色，也充当 Worker 进程的角色。</li>
<li>多进程启动：此时系统有且仅有一个 Master 进程，至少有一个 Worker 进程工作。</li>
<li>Master 进程主要进行一些全局性的初始化工作和管理 Worker 的工作；事件处理是在 Worker 中进行的。</li>
</ol>
</li>
</ol>
<h2 id="为什么是-NIO"><a href="#为什么是-NIO" class="headerlink" title="为什么是 NIO"></a>为什么是 NIO</h2><p>对于优化单个 server 节点的网络层，多使用 NIO 方式，server 端与 client 端在多次通讯的情况下使用 TCP 长连接维持会话，比如 Redis epoll 模型，RocketMq 的 netty 模型<br>对于高性能 Server 节点，在处理好网络请求同时，还要保证 server 端逻辑可以快速执行完成，这就涉及到合理的数据结构与线程模型。<br>在 Redis 中，采用的是 Reactor 模式实现文件事件处理器：<br><img src="/imgs/Redis/Redis-%E4%BA%8B%E4%BB%B6%E5%A4%84%E7%90%86%E6%A8%A1%E5%9E%8B.png" alt="Redis-事件处理模型" title="Redis-事件处理模型"></p>
<ol>
<li>IO 多路复用<br>根据平台不同选择不同的 IO 复用模型，比如 Linux 就是选择 epoll，select 是备选方案，不过正常情况下根本不会采用，因为 select 效率低，且有文件描述符监听上限。</li>
<li>封装不同 IO 模型，为事件处理器提供统一接口</li>
</ol>
<h2 id="Redis单线程多路复用IO模型实现-事件注册"><a href="#Redis单线程多路复用IO模型实现-事件注册" class="headerlink" title="Redis单线程多路复用IO模型实现 - 事件注册"></a>Redis单线程多路复用IO模型实现 - 事件注册</h2><p>Redis服务器的初始化过程中包括了对事件处理器的初始化。<br>1、服务器启动期间初始化事件处理器<br>服务器初始化代码：<code>redis.c/initServer</code><br>初始化事件处理器代码：<code>ae.c/aeCreateEventLoop</code><br>2、根据系统的不同，选择不同的底层IO事件处理实现<br>比如linux的话，会选择epoll作为实现：<code>epoll.c/aeApiCreate</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">/*</span><br><span class="line"> * 创建一个新的 epoll 实例，并将它赋值给 eventLoop</span><br><span class="line"> */</span><br><span class="line">static int aeApiCreate(aeEventLoop *eventLoop) &#123;</span><br><span class="line"></span><br><span class="line">    aeApiState *state = zmalloc(sizeof(aeApiState));</span><br><span class="line"></span><br><span class="line">    if (!state) return -1;</span><br><span class="line"></span><br><span class="line">    // 初始化事件槽空间</span><br><span class="line">    state-&gt;events = zmalloc(sizeof(struct epoll_event)*eventLoop-&gt;setsize);</span><br><span class="line">    if (!state-&gt;events) &#123;</span><br><span class="line">        zfree(state);</span><br><span class="line">        return -1;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // 创建 epoll 实例</span><br><span class="line">    state-&gt;epfd = epoll_create(1024); /* 1024 is just a hint for the kernel */</span><br><span class="line">    if (state-&gt;epfd == -1) &#123;</span><br><span class="line">        zfree(state-&gt;events);</span><br><span class="line">        zfree(state);</span><br><span class="line">        return -1;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // 赋值给 eventLoop</span><br><span class="line">    eventLoop-&gt;apidata = state;</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>当服务器需要监听某些事件时，会注册对这些事件的监听器，下面是注册监听器的函数：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">/*</span><br><span class="line"> * 根据 mask 参数的值，监听 fd 文件的状态，</span><br><span class="line"> * 当 fd 可用时，执行 proc 函数</span><br><span class="line"> */</span><br><span class="line">int aeCreateFileEvent(aeEventLoop *eventLoop, int fd, int mask,</span><br><span class="line">        aeFileProc *proc, void *clientData)</span><br><span class="line">&#123;</span><br><span class="line">    if (fd &gt;= eventLoop-&gt;setsize) &#123;</span><br><span class="line">        errno = ERANGE;</span><br><span class="line">        return AE_ERR;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    if (fd &gt;= eventLoop-&gt;setsize) return AE_ERR;</span><br><span class="line"></span><br><span class="line">    // 取出文件事件结构</span><br><span class="line">    aeFileEvent *fe = &amp;eventLoop-&gt;events[fd];</span><br><span class="line"></span><br><span class="line">    // 监听指定 fd 的指定事件</span><br><span class="line">    if (aeApiAddEvent(eventLoop, fd, mask) == -1)</span><br><span class="line">        return AE_ERR;</span><br><span class="line"></span><br><span class="line">    // 设置文件事件类型，以及事件的处理器</span><br><span class="line">    fe-&gt;mask |= mask;</span><br><span class="line">    if (mask &amp; AE_READABLE) fe-&gt;rfileProc = proc;</span><br><span class="line">    if (mask &amp; AE_WRITABLE) fe-&gt;wfileProc = proc;</span><br><span class="line"></span><br><span class="line">    // 私有数据</span><br><span class="line">    fe-&gt;clientData = clientData;</span><br><span class="line"></span><br><span class="line">    // 如果有需要，更新事件处理器的最大 fd</span><br><span class="line">    if (fd &gt; eventLoop-&gt;maxfd)</span><br><span class="line">        eventLoop-&gt;maxfd = fd;</span><br><span class="line"></span><br><span class="line">    return AE_OK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>比如Redis服务器要接受客户端的请求，就要注册一个监听连接事件，回调函数中会为客户端连接创建一个socket，并注册可读文件事件。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">void initServer() &#123;</span><br><span class="line"></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">    /* Create an event handler for accepting new connections in TCP and Unix</span><br><span class="line">     * domain sockets. */</span><br><span class="line">    // 为 TCP 连接关联连接应答（accept）处理器</span><br><span class="line">    // 用于接受并应答客户端的 connect() 调用</span><br><span class="line">    for (j = 0; j &lt; server.ipfd_count; j++) &#123;</span><br><span class="line">        if (aeCreateFileEvent(server.el, server.ipfd[j], AE_READABLE,</span><br><span class="line">            acceptTcpHandler,NULL) == AE_ERR)</span><br><span class="line">            &#123;</span><br><span class="line">                redisPanic(</span><br><span class="line">                    &quot;Unrecoverable error creating server.ipfd file event.&quot;);</span><br><span class="line">            &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Redis单线程多路复用IO模型实现-事件循环（处理）"><a href="#Redis单线程多路复用IO模型实现-事件循环（处理）" class="headerlink" title="Redis单线程多路复用IO模型实现 - 事件循环（处理）"></a>Redis单线程多路复用IO模型实现 - 事件循环（处理）</h2><p>Redis中定义了两种事件：时间事件TimeEvents、文件事件FileEvents：</p>
<ul>
<li><code>TimeEvents</code>：一般都是一些定时任务，实际上现在时间事件只应用于服务器启动时注册的<code>serverCron</code>定时任务的执行；</li>
<li><code>FileEvents</code>：socket文件的IO事件，比如上面的监听连接的事件就是文件事件。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br></pre></td><td class="code"><pre><span class="line">/*</span><br><span class="line"> * 事件处理器的主循环</span><br><span class="line"> */</span><br><span class="line">void aeMain(aeEventLoop *eventLoop) &#123;</span><br><span class="line"></span><br><span class="line">    eventLoop-&gt;stop = 0;</span><br><span class="line"></span><br><span class="line">    while (!eventLoop-&gt;stop) &#123;</span><br><span class="line"></span><br><span class="line">        // 如果有需要在事件处理前执行的函数，那么运行它</span><br><span class="line">        if (eventLoop-&gt;beforesleep != NULL)</span><br><span class="line">            eventLoop-&gt;beforesleep(eventLoop);</span><br><span class="line"></span><br><span class="line">        // 开始处理事件</span><br><span class="line">        aeProcessEvents(eventLoop, AE_ALL_EVENTS);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 1、看是否有事件到达了执行时间</span><br><span class="line">// 2、如果有，则执行这些事件</span><br><span class="line">/* Process every pending time event, then every pending file event</span><br><span class="line"> * (that may be registered by time event callbacks just processed).</span><br><span class="line"> *</span><br><span class="line"> * 处理所有已到达的时间事件，以及所有已就绪的文件事件。</span><br><span class="line"> *</span><br><span class="line"> * Without special flags the function sleeps until some file event</span><br><span class="line"> * fires, or when the next time event occurs (if any).</span><br><span class="line"> *</span><br><span class="line"> * 如果不传入特殊 flags 的话，那么函数睡眠直到文件事件就绪，</span><br><span class="line"> * 或者下个时间事件到达（如果有的话）。</span><br><span class="line"> *</span><br><span class="line"> * If flags is 0, the function does nothing and returns.</span><br><span class="line"> * 如果 flags 为 0 ，那么函数不作动作，直接返回。</span><br><span class="line"> *</span><br><span class="line"> * if flags has AE_ALL_EVENTS set, all the kind of events are processed.</span><br><span class="line"> * 如果 flags 包含 AE_ALL_EVENTS ，所有类型的事件都会被处理。</span><br><span class="line"> *</span><br><span class="line"> * if flags has AE_FILE_EVENTS set, file events are processed.</span><br><span class="line"> * 如果 flags 包含 AE_FILE_EVENTS ，那么处理文件事件。</span><br><span class="line"> *</span><br><span class="line"> * if flags has AE_TIME_EVENTS set, time events are processed.</span><br><span class="line"> * 如果 flags 包含 AE_TIME_EVENTS ，那么处理时间事件。</span><br><span class="line"> *</span><br><span class="line"> * if flags has AE_DONT_WAIT set the function returns ASAP until all</span><br><span class="line"> * the events that&#x27;s possible to process without to wait are processed.</span><br><span class="line"> * 如果 flags 包含 AE_DONT_WAIT ，</span><br><span class="line"> * 那么函数在处理完所有不许阻塞的事件之后，即刻返回。</span><br><span class="line"> *</span><br><span class="line"> * The function returns the number of events processed. </span><br><span class="line"> * 函数的返回值为已处理事件的数量</span><br><span class="line"> */</span><br><span class="line">int aeProcessEvents(aeEventLoop *eventLoop, int flags)</span><br><span class="line">&#123;</span><br><span class="line">    int processed = 0, numevents;</span><br><span class="line"></span><br><span class="line">    /* Nothing to do? return ASAP */</span><br><span class="line">    if (!(flags &amp; AE_TIME_EVENTS) &amp;&amp; !(flags &amp; AE_FILE_EVENTS)) return 0;</span><br><span class="line"></span><br><span class="line">    /* Note that we want call select() even if there are no</span><br><span class="line">     * file events to process as long as we want to process time</span><br><span class="line">     * events, in order to sleep until the next time event is ready</span><br><span class="line">     * to fire.</span><br><span class="line">     */</span><br><span class="line">    if (eventLoop-&gt;maxfd != -1 ||</span><br><span class="line">        ((flags &amp; AE_TIME_EVENTS) &amp;&amp; !(flags &amp; AE_DONT_WAIT))) &#123;</span><br><span class="line">        int j;</span><br><span class="line">        aeTimeEvent *shortest = NULL;</span><br><span class="line">        struct timeval tv, *tvp;</span><br><span class="line"></span><br><span class="line">        // 获取最近的时间事件</span><br><span class="line">        if (flags &amp; AE_TIME_EVENTS &amp;&amp; !(flags &amp; AE_DONT_WAIT))</span><br><span class="line">            shortest = aeSearchNearestTimer(eventLoop);</span><br><span class="line">        if (shortest) &#123;</span><br><span class="line">            // 如果时间事件存在的话</span><br><span class="line">            // 那么根据最近可执行时间事件和现在时间的时间差来决定文件事件的阻塞时间</span><br><span class="line">            long now_sec, now_ms;</span><br><span class="line"></span><br><span class="line">            /* Calculate the time missing for the nearest</span><br><span class="line">             * timer to fire. */</span><br><span class="line">            // 计算距今最近的时间事件还要多久才能达到</span><br><span class="line">            // 并将该时间距保存在 tv 结构中</span><br><span class="line">            aeGetTime(&amp;now_sec, &amp;now_ms);</span><br><span class="line">            tvp = &amp;tv;</span><br><span class="line">            tvp-&gt;tv_sec = shortest-&gt;when_sec - now_sec;</span><br><span class="line">            if (shortest-&gt;when_ms &lt; now_ms) &#123;</span><br><span class="line">                tvp-&gt;tv_usec = ((shortest-&gt;when_ms+1000) - now_ms)*1000;</span><br><span class="line">                tvp-&gt;tv_sec --;</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                tvp-&gt;tv_usec = (shortest-&gt;when_ms - now_ms)*1000;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            // 时间差小于 0 ，说明事件已经可以执行了，将秒和毫秒设为 0 （不阻塞）</span><br><span class="line">            if (tvp-&gt;tv_sec &lt; 0) tvp-&gt;tv_sec = 0;</span><br><span class="line">            if (tvp-&gt;tv_usec &lt; 0) tvp-&gt;tv_usec = 0;</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            </span><br><span class="line">            // 执行到这一步，说明没有时间事件</span><br><span class="line">            // 那么根据 AE_DONT_WAIT 是否设置来决定是否阻塞，以及阻塞的时间长度</span><br><span class="line"></span><br><span class="line">            /* If we have to check for events but need to return</span><br><span class="line">             * ASAP because of AE_DONT_WAIT we need to set the timeout</span><br><span class="line">             * to zero */</span><br><span class="line">            if (flags &amp; AE_DONT_WAIT) &#123;</span><br><span class="line">                // 设置文件事件不阻塞</span><br><span class="line">                tv.tv_sec = tv.tv_usec = 0;</span><br><span class="line">                tvp = &amp;tv;</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                /* Otherwise we can block */</span><br><span class="line">                // 文件事件可以阻塞直到有事件到达为止</span><br><span class="line">                tvp = NULL; /* wait forever */</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        // 处理文件事件，阻塞时间由 tvp 决定</span><br><span class="line">        numevents = aeApiPoll(eventLoop, tvp);</span><br><span class="line">        for (j = 0; j &lt; numevents; j++) &#123;</span><br><span class="line">            // 从已就绪数组中获取事件</span><br><span class="line">            aeFileEvent *fe = &amp;eventLoop-&gt;events[eventLoop-&gt;fired[j].fd];</span><br><span class="line"></span><br><span class="line">            int mask = eventLoop-&gt;fired[j].mask;</span><br><span class="line">            int fd = eventLoop-&gt;fired[j].fd;</span><br><span class="line">            int rfired = 0;</span><br><span class="line"></span><br><span class="line">           /* note the fe-&gt;mask &amp; mask &amp; ... code: maybe an already processed</span><br><span class="line">             * event removed an element that fired and we still didn&#x27;t</span><br><span class="line">             * processed, so we check if the event is still valid. */</span><br><span class="line">            // 读事件</span><br><span class="line">            if (fe-&gt;mask &amp; mask &amp; AE_READABLE) &#123;</span><br><span class="line">                // rfired 确保读/写事件只能执行其中一个</span><br><span class="line">                rfired = 1;</span><br><span class="line">                fe-&gt;rfileProc(eventLoop,fd,fe-&gt;clientData,mask);</span><br><span class="line">            &#125;</span><br><span class="line">            // 写事件</span><br><span class="line">            if (fe-&gt;mask &amp; mask &amp; AE_WRITABLE) &#123;</span><br><span class="line">                if (!rfired || fe-&gt;wfileProc != fe-&gt;rfileProc)</span><br><span class="line">                    fe-&gt;wfileProc(eventLoop,fd,fe-&gt;clientData,mask);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            processed++;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    /* Check time events */</span><br><span class="line">    // 执行时间事件</span><br><span class="line">    if (flags &amp; AE_TIME_EVENTS)</span><br><span class="line">        processed += processTimeEvents(eventLoop);</span><br><span class="line"></span><br><span class="line">    return processed; /* return the number of processed file/time events */</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kity@2.0.4/dist/kity.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text/javascript" src="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.6.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.6.0/dist/mindmap.min.css">
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="上一页" aria-label="上一页" href="/page/9/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/9/">9</a><span class="page-number current">10</span><a class="page-number" href="/page/11/">11</a><span class="space">&hellip;</span><a class="page-number" href="/page/19/">19</a><a class="extend next" rel="next" title="下一页" aria-label="下一页" href="/page/11/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">tallate</span>
  </div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

  <a href="https://github.com/tallate" class="github-corner" title="在 GitHub 上关注我" aria-label="在 GitHub 上关注我" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>


  <script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"version":"7.1.2","options":null,"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.3.0/mermaid.min.js","integrity":"sha256-9y71g5Lz/KLsHjB8uXwnkuWDtAMDSzD/HdIbqhJfTAI="}}</script>
  <script src="/js/third-party/tags/mermaid.js"></script>





  





</body>
</html>
