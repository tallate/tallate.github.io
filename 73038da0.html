<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"tallate.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.18.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="ZooKeeper 是分布式的、开源的分布式应用程序协调服务，原本是 Hadoop、HBase 的一个重要组件。它为分布式应用提供一致性服务的软件，包括：配置维护、域名服务、分布式同步、组服务等。">
<meta property="og:type" content="article">
<meta property="og:title" content="ZooKeeper 原理总结">
<meta property="og:url" content="https://tallate.github.io/73038da0.html">
<meta property="og:site_name" content="Tallate">
<meta property="og:description" content="ZooKeeper 是分布式的、开源的分布式应用程序协调服务，原本是 Hadoop、HBase 的一个重要组件。它为分布式应用提供一致性服务的软件，包括：配置维护、域名服务、分布式同步、组服务等。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://tallate.github.io/imgs/ZooKeeper%E5%8E%9F%E7%90%86%E6%80%BB%E7%BB%93/read_dominant.jpg">
<meta property="og:image" content="https://tallate.github.io/imgs/ZooKeeper/ZooKeeper-Watch.png">
<meta property="og:image" content="https://tallate.github.io/imgs/ZooKeeper%E5%8E%9F%E7%90%86%E6%80%BB%E7%BB%93/read_write.png">
<meta property="og:image" content="https://tallate.github.io/imgs/ZooKeeper%E5%8E%9F%E7%90%86%E6%80%BB%E7%BB%93/read_dominant.jpg">
<meta property="og:image" content="https://tallate.github.io/imgs/ZooKeeper%E5%8E%9F%E7%90%86%E6%80%BB%E7%BB%93/CAP.jpg">
<meta property="og:image" content="https://tallate.github.io/imgs/ZooKeeper%E5%8E%9F%E7%90%86%E6%80%BB%E7%BB%93/Reliability.jpg">
<meta property="og:image" content="https://tallate.github.io/imgs/ZooKeeper%E5%8E%9F%E7%90%86%E6%80%BB%E7%BB%93/replicated.jpg">
<meta property="og:image" content="https://tallate.github.io/imgs/ZooKeeper%E5%8E%9F%E7%90%86%E6%80%BB%E7%BB%93/Leader%E9%80%89%E4%B8%BE.png">
<meta property="og:image" content="https://tallate.github.io/imgs/ZooKeeper%E5%8E%9F%E7%90%86%E6%80%BB%E7%BB%93/%E4%B8%A4%E9%98%B6%E6%AE%B5Messaging.jpg">
<meta property="article:published_time" content="2019-07-29T10:51:58.000Z">
<meta property="article:modified_time" content="2025-07-06T17:56:20.882Z">
<meta property="article:author" content="tallate">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://tallate.github.io/imgs/ZooKeeper%E5%8E%9F%E7%90%86%E6%80%BB%E7%BB%93/read_dominant.jpg">


<link rel="canonical" href="https://tallate.github.io/73038da0.html">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://tallate.github.io/73038da0.html","path":"/73038da0.html","title":"ZooKeeper 原理总结"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>ZooKeeper 原理总结 | Tallate</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Tallate</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">该吃吃该喝喝 啥事别往心里搁</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="tags fa-fw"></i>标签<span class="badge">84</span></a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="th fa-fw"></i>分类<span class="badge">25</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="archive fa-fw"></i>归档<span class="badge">192</span></a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%BF%E7%94%A8-ZooKeeper"><span class="nav-number">1.</span> <span class="nav-text">为什么使用 ZooKeeper</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%86%E5%B8%83%E5%BC%8F%E5%BA%94%E7%94%A8%E9%9D%A2%E5%AF%B9%E7%9A%84%E9%97%AE%E9%A2%98"><span class="nav-number">1.0.1.</span> <span class="nav-text">分布式应用面对的问题</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8F%AF%E7%94%A8%E6%80%A7"><span class="nav-number">1.0.1.1.</span> <span class="nav-text">可用性</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%80%E8%87%B4%E6%80%A7"><span class="nav-number">1.0.1.2.</span> <span class="nav-text">一致性</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9C%AC%E5%9C%B0%E4%BA%8B%E5%8A%A1%E5%92%8C%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1"><span class="nav-number">1.0.2.</span> <span class="nav-text">本地事务和分布式事务</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CAP-%E5%92%8C-BASE"><span class="nav-number">1.0.3.</span> <span class="nav-text">CAP 和 BASE</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ZooKeeper-%E7%9A%84%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="nav-number">1.0.4.</span> <span class="nav-text">ZooKeeper 的应用场景</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#ZooKeeper-%E5%8E%9F%E7%90%86"><span class="nav-number">2.</span> <span class="nav-text">ZooKeeper 原理</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84"><span class="nav-number">2.1.</span> <span class="nav-text">数据结构</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%B7%AF%E5%BE%84%EF%BC%88path%EF%BC%89%E5%92%8C%E6%A0%91"><span class="nav-number">2.1.1.</span> <span class="nav-text">路径（path）和树</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%8A%82%E7%82%B9%EF%BC%88znode%EF%BC%89"><span class="nav-number">2.1.2.</span> <span class="nav-text">节点（znode）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84"><span class="nav-number">2.1.3.</span> <span class="nav-text">内存结构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%8A%82%E7%82%B9%E5%AE%B9%E9%87%8F%E9%99%90%E5%88%B6"><span class="nav-number">2.1.4.</span> <span class="nav-text">节点容量限制</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%89%88%E6%9C%AC%E5%8F%B7"><span class="nav-number">2.1.5.</span> <span class="nav-text">版本号</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8E%9F%E5%AD%90%E8%AF%BB%E5%86%99"><span class="nav-number">2.1.6.</span> <span class="nav-text">原子读写</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ACL"><span class="nav-number">2.1.7.</span> <span class="nav-text">ACL</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BA%8F%E5%88%97"><span class="nav-number">2.1.8.</span> <span class="nav-text">序列</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%80%9A%E7%9F%A5%E6%9C%BA%E5%88%B6%EF%BC%88Watcher%EF%BC%89"><span class="nav-number">2.2.</span> <span class="nav-text">通知机制（Watcher）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%80%9A%E4%BF%A1%E6%A8%A1%E5%9E%8B%EF%BC%88Session%EF%BC%89"><span class="nav-number">2.3.</span> <span class="nav-text">通信模型（Session）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AF%BB%E5%86%99%E6%95%B0%E6%8D%AE"><span class="nav-number">2.4.</span> <span class="nav-text">读写数据</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B"><span class="nav-number">2.5.</span> <span class="nav-text">客户端启动流程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9C%8D%E5%8A%A1%E7%AB%AF%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B"><span class="nav-number">2.6.</span> <span class="nav-text">服务端启动流程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ZooKeeper-%E9%9B%86%E7%BE%A4%E5%8E%9F%E7%90%86"><span class="nav-number">2.7.</span> <span class="nav-text">ZooKeeper 集群原理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#ZooKeeper-%E9%80%82%E5%90%88%E8%AF%BB%E5%A4%9A%E5%86%99%E5%B0%91%E7%9A%84%E5%9C%BA%E6%99%AF"><span class="nav-number">2.7.1.</span> <span class="nav-text">ZooKeeper 适合读多写少的场景</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%B0%83%E5%92%8C-CAP"><span class="nav-number">2.7.2.</span> <span class="nav-text">分布式协调和 CAP</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ZooKeeper-%E9%9B%86%E7%BE%A4%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%89%B9%E6%80%A7"><span class="nav-number">2.7.3.</span> <span class="nav-text">ZooKeeper 集群系统的特性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ZooKeeper-%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F%E6%8F%90%E4%BE%9B%E7%9A%84%E4%BF%9D%E8%AF%81"><span class="nav-number">2.7.4.</span> <span class="nav-text">ZooKeeper 消息系统提供的保证</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ZAB-%E5%8D%8F%E8%AE%AE%E4%BE%9D%E8%B5%96%E7%9A%84-TCP-%E5%8D%8F%E8%AE%AE%E7%89%B9%E6%80%A7"><span class="nav-number">2.7.5.</span> <span class="nav-text">ZAB 协议依赖的 TCP 协议特性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Service-%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%EF%BC%88replicated%E3%80%81Leader-Follower%EF%BC%89"><span class="nav-number">2.7.6.</span> <span class="nav-text">Service 网络结构（replicated、Leader-Follower）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ordered"><span class="nav-number">2.7.7.</span> <span class="nav-text">ordered</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Total-order-%E5%8E%9F%E7%90%86"><span class="nav-number">2.7.8.</span> <span class="nav-text">Total order 原理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A4%9A%E6%95%B0%E6%B4%BE%EF%BC%88Quorum%EF%BC%89"><span class="nav-number">2.7.9.</span> <span class="nav-text">多数派（Quorum）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%8E%E9%80%9A%E4%BF%A1%E7%9B%B8%E5%85%B3%E7%9A%84%E6%A6%82%E5%BF%B5"><span class="nav-number">2.7.10.</span> <span class="nav-text">与通信相关的概念</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8%E8%B6%85%E6%97%B6%E6%9D%A5%E5%AE%B9%E9%94%99"><span class="nav-number">2.7.11.</span> <span class="nav-text">使用超时来容错</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%A4%E9%98%B6%E6%AE%B5-Messaging"><span class="nav-number">2.7.12.</span> <span class="nav-text">两阶段 Messaging</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#ZAB-%E5%8D%8F%E8%AE%AE"><span class="nav-number">2.7.12.1.</span> <span class="nav-text">ZAB 协议</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#ZAB-%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%A8%A1%E5%BC%8F"><span class="nav-number">2.7.12.2.</span> <span class="nav-text">ZAB 的两种模式</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%80%89%E4%B8%BE%E7%AE%97%E6%B3%95%E6%A6%82%E8%BF%B0"><span class="nav-number">2.7.12.3.</span> <span class="nav-text">选举算法概述</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#ZooKeeper-%E6%98%AF%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E4%BA%8B%E5%8A%A1%E7%9A%84%E9%A1%BA%E5%BA%8F%E4%B8%80%E8%87%B4%E6%80%A7%E7%9A%84"><span class="nav-number">2.7.12.4.</span> <span class="nav-text">ZooKeeper 是如何保证事务的顺序一致性的</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Leader-Activation"><span class="nav-number">2.7.12.5.</span> <span class="nav-text">Leader Activation</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Leader-%E9%80%89%E4%B8%BE"><span class="nav-number">2.7.12.6.</span> <span class="nav-text">Leader 选举</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Active-Messaging"><span class="nav-number">2.7.12.7.</span> <span class="nav-text">Active Messaging</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Paxos-ZAB-%E5%8C%BA%E5%88%AB"><span class="nav-number">2.7.12.8.</span> <span class="nav-text">Paxos &amp; ZAB 区别</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Summary"><span class="nav-number">2.7.13.</span> <span class="nav-text">Summary</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Comparisons"><span class="nav-number">2.7.14.</span> <span class="nav-text">Comparisons</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#QA"><span class="nav-number">3.</span> <span class="nav-text">QA</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%B4%E6%97%B6%E8%8A%82%E7%82%B9%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E4%BC%9A%E8%A7%A6%E5%8F%91%E8%87%AA%E5%8A%A8%E6%B8%85%E9%99%A4"><span class="nav-number">3.1.</span> <span class="nav-text">临时节点什么时候会触发自动清除</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%82%E8%80%83"><span class="nav-number">3.2.</span> <span class="nav-text">参考</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%9B%86%E7%BE%A4%E5%8E%9F%E7%90%86"><span class="nav-number">3.2.1.</span> <span class="nav-text">集群原理</span></a></li></ol></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">tallate</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">192</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">25</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">84</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://tallate.github.io/73038da0.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="tallate">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tallate">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="ZooKeeper 原理总结 | Tallate">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          ZooKeeper 原理总结
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2019-07-29 18:51:58" itemprop="dateCreated datePublished" datetime="2019-07-29T18:51:58+08:00">2019-07-29</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-07-07 01:56:20" itemprop="dateModified" datetime="2025-07-07T01:56:20+08:00">2025-07-07</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/ZooKeeper/" itemprop="url" rel="index"><span itemprop="name">ZooKeeper</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><p>ZooKeeper 是分布式的、开源的分布式应用程序协调服务，原本是 Hadoop、HBase 的一个重要组件。它为分布式应用提供一致性服务的软件，包括：配置维护、域名服务、分布式同步、组服务等。</p>
<span id="more"></span>

<h1 id="为什么使用-ZooKeeper"><a href="#为什么使用-ZooKeeper" class="headerlink" title="为什么使用 ZooKeeper"></a>为什么使用 ZooKeeper</h1><p>区别于<strong>集中式系统</strong>，<strong>分布式系统</strong>是一个硬件或软件组件分布在不同的网络计算机上，彼此之间仅仅通过消息传递进行通信和协调的系统。<br>因为分布式特性，多个主机注定会出现很多问题，包括单点、分区、脑裂等。<br>ZooKeeper 解决的就是如何协调这些主机，就像动物园管理员一样（这也是其名字的由来），作为分布式协调中间件，ZooKeeper 主要用来解决分布式环境当中多个进程之间的同步控制。</p>
<h3 id="分布式应用面对的问题"><a href="#分布式应用面对的问题" class="headerlink" title="分布式应用面对的问题"></a>分布式应用面对的问题</h3><p>分布式系统存在着不确定性和不可预测性，我们可能会面临诸多问题，包括：</p>
<ul>
<li>节点部分失效；</li>
<li>节点短时间内不可用导致被误判为宕机，此时服务器可能正在执行需要长时间阻塞用户线程的任务，比如 GC；</li>
<li>由于网络不可靠而引起丢包或任意延迟；</li>
<li>不可靠的时钟导致节点间不同步；</li>
</ul>
<p>这些问题可以归类到可用性和一致性两类问题上。</p>
<blockquote>
<p>从 CAP 理论中我们可以了解到，网络分区无法避免，设计分布式系统时必须考虑网络的安全性，其次再权衡可用性和一致性，二者相当于鱼和熊掌不可得兼。</p>
</blockquote>
<h4 id="可用性"><a href="#可用性" class="headerlink" title="可用性"></a>可用性</h4><ul>
<li><strong>节点故障</strong>无法避免：服务器越多，个别节点发生宕机或僵死情况的可能性越高，特别是在一些有上百个服务的大型企业中，故障几乎每天都会发生。</li>
<li><strong>通信故障</strong>无法避免：从集中式到分布式，必然引入了网络因素，而由于网络本身的不可靠性，因此就引入了额外的问题。分布式系统各节点之间的网络通信能够正常进行，其延时也会远大于单机操作，在消息的收发过程中，消息丢失和消息延迟变得十分普遍。<br>当网络发生异常情况时，导致分布式系统中部分节点之间的网络延时不断增大，最终导致组成分布式系统的所有节点中，只有部分节点之间能够正常通信，而另一些节点则不能，这种现象称之为<strong>网络分区</strong>，当网络分区出现时，分布式系统会出现局部小集群，在极端情况下，这些局部小集群会独立完成原本需要整个分布式系统才能完成的功能，包括对数据的事务处理，这就对分布式一致性提出了非常大的挑战。</li>
</ul>
<p>由于网络可能会出现各种各样的问题，因此分布式系统的每一次请求与响应，存在特有的<strong>三态</strong>概念：成功、失败、超时。当网络在异常情况下，可能会出现超时现象，通常由以下两种情况：</p>
<ol>
<li>由于网络原因，该请求并没有被成功地发送到接收方，而是在发送过程就发生了消息丢失现象。</li>
<li>该请求成功的被接收方接受后，并进行了处理，但是在将响应反馈给发送方时，发生了消息丢失现象。</li>
</ol>
<h4 id="一致性"><a href="#一致性" class="headerlink" title="一致性"></a>一致性</h4><p>为了灾备，主机一般会设有副本，主从、从从之间同步数据会有延迟，先写入的副本和后写入的副本之间必然产生不一致，甚至写入顺序不同也会导致数据副本间的不一致。<br>P2P 集群中这种问题更为突出，因为主从集群中数据完全以主节点为准，而 P2P 集群中每个节点都可以主动写数据。<br>    * 缺乏全局时钟：典型的分布式系统由一系列在空间上随意分布的多个进程组成，具有明显的分布性，这些进程之间通过交换消息来进行互相通信，因此，在分布式系统中，很难定义两个时间究竟谁先谁后，原因就是因为分布式系统缺乏一个全局的时钟序列控制。<br>    * 并发操作：同一分布式系统中的多个节点，可能会并发地操作一些共享资源，诸如数据库或分布式存储等，就算通过某些手段协调一致了时钟，但是由于网络延迟的存在，并发请求仍然难以决定请求到达、返回的先后顺序。</p>
<blockquote>
<p><strong>副本</strong>指的是分布式系统对数据和服务提供的一种冗余方式，为了对外提供高可用的服务，我们往往会对数据和服务进行副本处理。<br><strong>数据副本</strong>是指在不同的节点上持久化同一份数据，当某一个节点上存储的数据丢失时，可以从副本上读取到该数据，这是解决分布式系统数据丢失问题最为有效的手段。<br><strong>服务副本</strong>是指多个节点提供同样的服务，每个节点都有能力接受来自外部的请求并进行相应的处理。<br>这里最产生不一致的指的是数据副本，比如 MySQL 主从集群。<br>机器故障是无法避免的，我们在设计的时候一般也会考虑故障的情况、从而为数据引入副本，如果所有这些服务器（主、副）全部挂掉且损坏、数据全部丢失，那么谈一致性也就没意义了，不过一般不会出现这样的情况，一些稍大型的公司甚至会考虑双活、两地三中心等机制。<br>我认为一致性是分布式系统中最有难度、最有魅力的，一致性问题会引出几乎最难解的问题，同样也会催发出各种优美的解决方案，比如 ZooKeeper 中的 ZAB 协议。</p>
</blockquote>
<p>一些一致性验证框架通过混沌理论来测试分布式系统的一致性，比如<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_39860915/article/details/103193605">Jepsen</a>。</p>
<h3 id="本地事务和分布式事务"><a href="#本地事务和分布式事务" class="headerlink" title="本地事务和分布式事务"></a>本地事务和分布式事务</h3><p><strong>事务</strong>是由一系列对系统中数据进行访问与更新的操作所组成的一个程序执行单元，狭义上的食物特指数据库事务。一方面，当多个应用程序并发访问数据库时，食物可以在这些应用程序之间提供一个隔离方法，以防止彼此的操作相互干扰，另一方面，食物为数据库操作序列提供了一个从失败中恢复到正常状态的方法，同时提供了数据库即使在宜昌状态下仍能保持数据一致性的方法。事务具有原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）、持久性（Durability），简称 ACID。</p>
<ol>
<li>原子性，指事务必须是一个原子的操作序列单元，事务中包含的各项操作在一次执行过程中，只允许出现以下两种状态之一，全部成功执行，全部不执行。任何一项操作失败都将导致整个事务失败，同时其他已经被执行的操作都将被撤销并回滚，只有所有操作全部成功，整个事务才算是成功完成。</li>
<li>一致性，指事务的执行不能破坏数据库数据的完整性和一致性，一个事务在执行之前和执行之后，数据库都必须处于一致性状态，即事务执行的结果必须是使数据库从一个一致性状态转变到另一个一致性状态，因此当数据库只包含成功事务提交的结果时，就能说数据库处于一致性状态，而如果数据库系统在运行过程中发生故障，有些事务尚未完成就被迫中断，这些未完成的事务对数据库所做的修改有一部分已写入物理数据库，这时数据库就处于一种不正确的状态，或者说是不一致的状态。</li>
<li>隔离性，指在并发环境中，并发的事务是相互隔离的，一个事务的执行不能被其他事务干扰，即不同的事务并发操作相同的数据时，每个事务都有各自完整的数据空间，即一个事务内部的操作及使用的数据对其他并发事务是隔离的，并发执行的各个事务之间不能相互干扰。</li>
<li>持久性，指一个事务一旦提交，他对数据库中对应数据的状态变更就应该是永久的，即一旦某个事务成功结束，那么它对数据库所做的更新就必须被永久的保存下来，即使发生系统崩溃或者宕机故障，只要数据库能够重新启动，那么一定能够将其恢复到事务成功结束时的状态。</li>
</ol>
<p><strong>分布式事务</strong>是指事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于分布式系统的不同节点上，通常一个分布式事务中会涉及对多个数据源或业务系统的操作。一个分布式事务可以看做是由多个分布式的操作序列组成，通常可以把这一系列分布式的操作序列称为子事务。由于在分布式事务中，各个子事务的执行是分布式的，因此要实现一种能够保证 ACID 特性的分布式事务处理系统就显得格外复杂。</p>
<h3 id="CAP-和-BASE"><a href="#CAP-和-BASE" class="headerlink" title="CAP 和 BASE"></a>CAP 和 BASE</h3><p><strong>CAP</strong>理论告诉我们，一个分布式系统不可能同时满足一致性、可用性、分区容错性这三个基本需求，最多只能同时满足其中的两个。</p>
<ol>
<li>Consistent（一致性），指数据在多个副本之间是否能够保持一致的特性，在一致性的需求下，当一个系统在数据一致的状态下执行更新操作后，应该保证系统的数据仍然处于一致状态。对于一个将数据副本分布在不同分布式节点上的系统来说，如果对第一个结点的数据进行了更新操作并且成功后，却没有使得第二个节点上的数据得到相应的更新，于是在对第二个结点的数据进行读取操作时，获取的仍然是老数据（脏数据），这就是典型的分布式数据不一致的情况，在分布式系统中，如果能够做到针对一个数据项的更新操作执行成功后，所有的用户都可以读取到期最新的值，那么这样的系统就被认为具有强一致性。</li>
<li>Available（可用性），指系统提供的服务必须一直处于可用的状态，对于用户的每一操作请求总是能够在有限的时间内返回结果。</li>
<li>Partition（分区容错性），分布式系统在遇到任何网络分区故障时，仍然需要能够保证对外提供满足一致性和可用性的服务，除非是整个网络环境都发生了故障。</li>
</ol>
<p><strong>BASE</strong>是基本可用（Basically Available）、Soft state（弱状态）、Eventually consistent（最终一致性）三个短语的简写。</p>
<ol>
<li>基本可用，指分布式系统在出现不可预知故障时，允许损失部分可用性，如响应时间上的损失或功能上的损失。</li>
<li>弱状态，也称为软状态，指允许系统中的二数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时。</li>
<li>最终一致性，指系统中所有的数据副本，在经过一段时回见的同步后，最终能够达到一个一致的状态，因此最终一致性的本质是需要系统保证数据能够达到一致，而不需要实时保证系统数据的强一致性。<br>因为强一致性实现起来难度比较大，具有强一致性的系统一般简称为 CP（Consistent+Pertition），ZooKeeper 就是 CP 的一个例子，CP 系统的一个显著特征是缺乏可用性，比如主挂掉后集群会进入选举，在此期间服务都是不可用的，因此一般业务服务不会直接依赖 ZooKeeper。<br>分布式系统谈得最多的就是最终一致性，但仅靠系统本身是不够的，最终一致性包括人工环节，甚至客服的介入。大部分异常都可以通过扫描 + 重试（at least once 语义） + 幂等忽略，真正产生的异常数据比较少，人工可以处理得过来，最严重的情况下，就需要借助日志来排查 Bug 了。</li>
</ol>
<h3 id="ZooKeeper-的应用场景"><a href="#ZooKeeper-的应用场景" class="headerlink" title="ZooKeeper 的应用场景"></a>ZooKeeper 的应用场景</h3><p>在构建微服务应用的时候，ZooKeepe 到并 r 主要是作注册中心用，基于 Spring Cloud 或 Dubbo 框架开发的提供者、消费者都向 ZooKeeper 注册自己的 URL，消费者还能拿订阅提供者的注册 URL，以便在后续程序的执行中去调用提供者。而提供者发生了变动，也会通过 Zookeeper 向订阅的消费者发送通知。</p>
<h1 id="ZooKeeper-原理"><a href="#ZooKeeper-原理" class="headerlink" title="ZooKeeper 原理"></a>ZooKeeper 原理</h1><h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><h3 id="路径（path）和树"><a href="#路径（path）和树" class="headerlink" title="路径（path）和树"></a>路径（path）和树</h3><p>ZooKeeper 通过路径来引用一个节点。路径必须是绝对的，因此他们必须由斜杠字符来开头。除此以外，他们必须是唯一的，也就是说每一个路径只有一个表示，因此这些路径不能改变。在 ZooKeeper 中，路径由 Unicode 字符串组成，并且有一些限制。字符串”&#x2F;zookeeper”用以保存管理信息，比如关键配额信息。</p>
<p>Zookeeper 提供基于类似于文件系统的目录节点树方式的数据存储，但是 Zookeeper 并不是用来专门存储数据的，它的作用主要是用来<strong>维护和监控存储的数据的状态变化</strong>。通过监控这些数据状态的变化，从而可以达到基于数据的集群管理。<br>与 Linux 文件系统不同的是，Linux 文件系统有目录和文件的区别，而 Zookeeper 的数据节点称为<strong>ZNode</strong>，ZNode 是 Zookeeper 中数据的最小单元，每个 ZNode 都可以保存数据（ZooKeeper was designed to store coordination data: status information, configuration, location information, etc., so the data stored at each node is usually small, in the byte to kilobyte range.），同时还可以挂载子节点，因此构成了一个层次化的命名空间，称为<strong>树</strong>。<br>另外，client 在创建 znode 时还可以指定一个 sequential flag，创建的 znode 将会拥有一个递增的序号，该序号会加到 znode 的名字后面。<br><img src="/imgs/ZooKeeper%E5%8E%9F%E7%90%86%E6%80%BB%E7%BB%93/read_dominant.jpg" alt="read_dominant" title="read_dominant"></p>
<h3 id="节点（znode）"><a href="#节点（znode）" class="headerlink" title="节点（znode）"></a>节点（znode）</h3><p>zk 中 znode 类型有四种，持久化目录节点、持久化顺序编号目录节点(有顺序，能够在注册机器等许多场景用到)、临时目录节点、临时顺序编号节点。<br>节点类型在创建后就不能更改。</p>
<ul>
<li>持久节点（PERSISTENT）：该节点的生命周期不依赖于会话，并且只有在客户端显示执行删除操作的时候，他们才能被删除。</li>
<li>持久顺序节点（PERSISTENT_SEQUENTIAL）：跟持久一样，就是父节点在创建下一级子节点（父节点必须是持久的）的时候，记录每个子节点创建的先后顺序，会给每个子节点名加上一个数字后缀。</li>
<li>临时节点（EPHEMERAL）：该节点的生命周期依赖于创建它们的会话。一旦会话(Session)结束，临时节点将被自动删除，当然可以也可以手动删除。虽然每个临时的 Znode 都会绑定到一个客户端会话，但他们对所有的客户端还是可见的。另外，ZooKeeper 的临时节点不允许拥有子节点。<blockquote>
<p>注意是会话结束而不是连接被断开。</p>
</blockquote>
</li>
<li>临时顺序节点（EPEMERAL_SEQUENTIAL）：类似持久顺序节点。</li>
</ul>
<p>一个节点主要包含以下属性：<br>代码：<code>Stat</code></p>
<ul>
<li>stat：此为状态信息, 描述该 Znode 的版本, 权限等信息</li>
<li>data：与该 Znode 关联的数据</li>
<li>children：该 Znode 下的子节点</li>
</ul>
<h3 id="内存结构"><a href="#内存结构" class="headerlink" title="内存结构"></a>内存结构</h3><p>Zookeeper 的数据模型是树结构，在内存数据库中，存储了整棵树的内容，包括所有的节点路径、节点数据、ACL 信息，Zookeeper 会定时将这个数据存储到磁盘上。</p>
<ul>
<li>DataTree：DataTree 是内存数据存储的核心，是一个树结构，代表了内存中一份完整的数据。DataTree 不包含任何与网络、客户端连接及请求处理相关的业务逻辑，是一个独立的组件。</li>
<li>DataNode：DataNode 是数据存储的最小单元，其内部除了保存了结点的数据内容、ACL 列表、节点状态之外，还记录了父节点的引用和子节点列表两个属性，其也提供了对子节点列表进行操作的接口。</li>
<li>ZKDatabase：Zookeeper 的内存数据库，管理 Zookeeper 的所有会话、DataTree 存储和事务日志。ZKDatabase 会定时向磁盘 dump 快照数据，同时在 Zookeeper 启动时，会通过磁盘的事务日志和快照文件恢复成一个完整的内存数据库。</li>
</ul>
<h3 id="节点容量限制"><a href="#节点容量限制" class="headerlink" title="节点容量限制"></a>节点容量限制</h3><p>管理调度数据，比如分布式应用中的配置文件信息、状态信息、汇集位置等等。这些数据的共同特性就是它们都是很小的数据，通常以 KB 为大小单位。ZooKeeper 的服务器和客户端都被设计为严格检查并限制每个 Znode 的数据大小至多 1M，但常规使用中应该远小于此值。</p>
<h3 id="版本号"><a href="#版本号" class="headerlink" title="版本号"></a>版本号</h3><p>ZooKeeper 中的版本表示的是对数据节点的数据内容、子节点列表，或是节点 ACL 信息的修改次数。<br>代码：<code>PrepRequestProcessor</code><br>在 ZooKeeper 中，版本号主要用于更新时进行并发校验。</p>
<h3 id="原子读写"><a href="#原子读写" class="headerlink" title="原子读写"></a>原子读写</h3><p>ZooKeeper 中的每个节点存储的数据要被原子性的操作。也就是说读操作将获取与节点相关的所有数据，写操作也将替换掉节点的所有数据。<br>The data stored at each znode in a namespace is read and written atomically. Reads get all the data bytes associated with a znode and a write replaces all the data. Each node has an Access Control List (ACL) that restricts who can do what.</p>
<h3 id="ACL"><a href="#ACL" class="headerlink" title="ACL"></a>ACL</h3><p>Zookeeper 内部存储了分布式系统运行时状态的元数据，这些元数据会直接影响基于 Zookeeper 进行构造的分布式系统的运行状态，如何保障系统中数据的安全，从而避免因误操作而带来的数据随意变更而导致的数据库异常十分重要，Zookeeper 提供了一套完善的 ACL 权限控制机制来保障数据的安全。<br>我们可以从三个方面来理解 ACL 机制：权限模式 Scheme、授权对象 ID、权限 Permission，通常使用”scheme:id:permission”来标识一个有效的 ACL 信息。<br>每一个节点都拥有自己的 ACL(访问控制列表)，这个列表规定了用户的权限，即限定了特定用户对目标节点可以执行的操作。</p>
<h3 id="序列"><a href="#序列" class="headerlink" title="序列"></a>序列</h3><p>当创建 Znode 的时候，用户可以请求在 ZooKeeper 的路径结尾添加一个递增的计数。这个计数对于此节点的父节点来说是唯一的，它的格式为”%10d”(10 位数字，没有数值的数位用 0 补充，例如”0000000001”)。当计数值大于 232-1 时，计数器将溢出。</p>
<h2 id="通知机制（Watcher）"><a href="#通知机制（Watcher）" class="headerlink" title="通知机制（Watcher）"></a>通知机制（Watcher）</h2><p>ZooKeeper 实现这些分布式进程的状态（ZNode 的 Data、Children）共享时，基于性能的考虑采用了类似的<strong>异步非阻塞</strong>的主动通知模式即 Watch 机制，使得分布式进程之间的“共享状态通信”更加实时高效，其实这也是 ZooKeeper 的主要任务决定的—协调。<br><img src="/imgs/ZooKeeper/ZooKeeper-Watch.png" alt="ZooKeeper-Watch" title="ZooKeeper-Watch"><br>Zookeeper 的 Watcher 机制主要包括<strong>客户端线程</strong>、<strong>客户端 WatcherManager</strong>、<strong>Zookeeper 服务器</strong>三部分。</p>
<ol>
<li>客户端在查询 znode 时可以向 ZooKeeper 服务器的<code>WatchManager</code>注册 watch 事件，表示想要监听该 znode 的节点状态，同时客户端本地会存储该监听器相关的信息在<code>ZKWatchManager</code>中；</li>
<li>当节点状态发生改变时（znode 的增、删、改）将会触发 watch 所对应的事件，当 watch 被触发时，ZooKeeper 将会给相应会话客户端发送且仅发送一条通知，因为 watch 只能被触发一次，这样可以减少网络流量；<br>代码：<code>org.apache.zookeeper.server.watch.WatchManager#triggerWatch</code></li>
<li>客户端在本地响应式的回调相关 Watcher 的 Handler；</li>
</ol>
<p>ZooKeeper 对节点的 watch 监听通知不是永久的，一个 watch 事件是一个<strong>一次性</strong>的触发器，当被设置了 watch 的数据发生了改变的时间，则服务器将这个改变发送给设置了 watch 的客户端，以便通知它们。<br>为什么不是永久的？举个例子，如果服务端变动频繁，而监听的客户端很多的情况下，每次变动都要通知到所有的客户端，这太消耗性能了。<br>一般是客户端执行 getData(“&#x2F;节点 A”, true)，如果节点 A 发生了变更或删除，客户端会得到它的 watch 事件，但是在之后节点 A 又发生了变更，而客户端又没有设置 watch 事件，就不再给客户端发送了。<br>在实际应用中，很多情况下，我们的客户端不需要知道服务端的每一次变动，我只要最新的数据即可。</p>
<h2 id="通信模型（Session）"><a href="#通信模型（Session）" class="headerlink" title="通信模型（Session）"></a>通信模型（Session）</h2><p>当 client 连接 zookeeper 时，会初始化一个 session，session 有一个超时时间，如在超时时间内，zookeeper 没有从 client 收到任何信息（zookeeper 会发状态检测信息），则认为 client 故障了，此时 zookeeper 会关闭这个 session（session 也可由 client 显式关闭）。</p>
<h2 id="读写数据"><a href="#读写数据" class="headerlink" title="读写数据"></a>读写数据</h2><p><img src="/imgs/ZooKeeper%E5%8E%9F%E7%90%86%E6%80%BB%E7%BB%93/read_write.png" alt="read_write" title="read_write"></p>
<ul>
<li>写数据，一个客户端进行写数据请求时，如果是 follower 接收到写请求，就会把请求转发给 Leader，Leader 通过内部的 Zab 协议进行原子广播，直到所有 Zookeeper 节点都成功写了数据后（内存同步以及磁盘更新），这次写请求算是完成，然后 Zookeeper Service 就会给 Client 发回响应。</li>
<li>读数据，因为集群中所有的 Zookeeper 节点都呈现一个同样的命名空间视图（就是结构数据），上面的写请求已经保证了写一次数据必须保证集群所有的 Zookeeper 节点都是同步命名空间的，所以读的时候可以在任意一台 Zookeeper 节点上。</li>
</ul>
<h2 id="客户端启动流程"><a href="#客户端启动流程" class="headerlink" title="客户端启动流程"></a>客户端启动流程</h2><ol>
<li>实例化<code>ZooKeeper</code><br>初始化过程中会创建一个客户端的 Watcher 管理器<code>ClientWatchManager</code>。</li>
<li>构造 ZooKeeper 服务器地址列表管理器<code>HostProvider</code><br>构造 ZooKeeper 时传入的服务器地址由<code>HostProvider</code>管理。</li>
<li>创建并初始化客户端网络连接器<code>ClientCnxn</code><br>创建<code>ClientCnxn</code>的同时，还会初始化客户端两个核心队列<code>outgoingQueue</code>和<code>pendingQueue</code>作为请求发送队列和服务端响应的等待队列。</li>
<li>初始化 SendThread 和 EventThread<br>前者管理客户端和服务端之间的所有网络 IO，后者用于进行客户端的事件处理。</li>
</ol>
<h2 id="服务端启动流程"><a href="#服务端启动流程" class="headerlink" title="服务端启动流程"></a>服务端启动流程</h2><h2 id="ZooKeeper-集群原理"><a href="#ZooKeeper-集群原理" class="headerlink" title="ZooKeeper 集群原理"></a>ZooKeeper 集群原理</h2><h3 id="ZooKeeper-适合读多写少的场景"><a href="#ZooKeeper-适合读多写少的场景" class="headerlink" title="ZooKeeper 适合读多写少的场景"></a>ZooKeeper 适合读多写少的场景</h3><p>ZooKeeper 适合读频率远大于写的场景，下图是 ZooKeeper 官网给出的吞吐量&#x2F;读请求比率的压测结果<br><img src="/imgs/ZooKeeper%E5%8E%9F%E7%90%86%E6%80%BB%E7%BB%93/read_dominant.jpg" alt="read_dominant" title="read_dominant"><br>The figure ZooKeeper Throughput as the Read-Write Ratio Varies is a throughput graph of ZooKeeper release 3.2 running on servers with dual 2Ghz Xeon and two SATA 15K RPM drives.<br>为什么这个比率这么悬殊呢？主要是由于 ZooKeeper 的数据同步机制，它的核心是<strong>ZAB</strong>协议。</p>
<h3 id="分布式协调和-CAP"><a href="#分布式协调和-CAP" class="headerlink" title="分布式协调和 CAP"></a>分布式协调和 CAP</h3><p>作为一个分布式系统，分区容错性是一个必须要考虑的关键点。一个分布式系统一旦丧失了分区容错性，也就表示放弃了扩展性。因为在分布式系统中，网络故障是经常出现的，一旦出现在这种问题就会导致整个系统不可用是绝对不能容忍的。所以，大部分分布式系统都会在保证分区容错性的前提下在一致性和可用性之间做权衡。<br>ZooKeeper 是个 CP（一致性+分区容错性）的分布式系统，即任何时刻对 ZooKeeper 的访问请求能得到一致的数据结果，同时系统对网络分割具备容错性；但是它不能保证每次服务请求的可用性。也就是在极端环境下，ZooKeeper 可能会丢弃一些请求，消费者程序需要重新请求才能获得结果。<br>ZooKeeper 是分布式协调服务，它的职责是保证数据在其管辖下的所有服务之间保持同步、一致；所以就不难理解为什么 ZooKeeper 被设计成 CP 而不是 AP 特性的了。而且， 作为 ZooKeeper 的核心实现算法 Zab，就是解决了分布式系统下数据如何在多个服务之间保持同步问题的。<br><img src="/imgs/ZooKeeper%E5%8E%9F%E7%90%86%E6%80%BB%E7%BB%93/CAP.jpg" alt="CAP" title="CAP"></p>
<h3 id="ZooKeeper-集群系统的特性"><a href="#ZooKeeper-集群系统的特性" class="headerlink" title="ZooKeeper 集群系统的特性"></a>ZooKeeper 集群系统的特性</h3><ul>
<li>Sequential Consistency - Updates from a client will be applied in the order that they were sent.</li>
<li>Atomicity - Updates either succeed or fail. No partial results.</li>
<li>Single System Image - A client will see the same view of the service regardless of the server that it connects to.</li>
<li>Reliability - Once an update has been applied, it will persist from that time forward until a client overwrites the update.<br>①Failure and recovery of a follower<br>②Failure and recovery of a different follower<br>③Failure of the leader<br>④Failure and recovery of two followers<br>⑤Failure of another leader<br><img src="/imgs/ZooKeeper%E5%8E%9F%E7%90%86%E6%80%BB%E7%BB%93/Reliability.jpg" alt="Reliability" title="Reliability"></li>
<li>Timeliness - The clients view of the system is guaranteed to be up-to-date within a certain time bound.</li>
</ul>
<h3 id="ZooKeeper-消息系统提供的保证"><a href="#ZooKeeper-消息系统提供的保证" class="headerlink" title="ZooKeeper 消息系统提供的保证"></a>ZooKeeper 消息系统提供的保证</h3><p>ZooKeeper 能在服务器之间建立点对点的 FIFO 通道，满足：</p>
<ul>
<li>Reliable delivery<br>If a message, m, is delivered by one server, it will be eventually delivered by all servers.</li>
<li>Total order<br>If a message is delivered before message b by one server, a will be delivered before b by all servers. If a and b are delivered messages, either a will be delivered before b or b will be delivered before a.</li>
<li>Causal order<br>If a message b is sent after a message a has been delivered by the sender of b, a must be ordered before b. If a sender sends c after sending b, c must be ordered after b.</li>
</ul>
<h3 id="ZAB-协议依赖的-TCP-协议特性"><a href="#ZAB-协议依赖的-TCP-协议特性" class="headerlink" title="ZAB 协议依赖的 TCP 协议特性"></a>ZAB 协议依赖的 TCP 协议特性</h3><ul>
<li>Ordered delivery<br>Data is delivered in the same order it is sent and a message m is delivered only after all messages sent before m have been delivered. (The corollary to this is that if message m is lost all messages after m will be lost.)</li>
<li>No message after close<br>Once a FIFO channel is closed, no messages will be received from it.</li>
</ul>
<h3 id="Service-网络结构（replicated、Leader-Follower）"><a href="#Service-网络结构（replicated、Leader-Follower）" class="headerlink" title="Service 网络结构（replicated、Leader-Follower）"></a>Service 网络结构（replicated、Leader-Follower）</h3><p>Like the distributed processes it coordinates, ZooKeeper itself is intended to be replicated over a sets of hosts called an <strong>ensemble</strong>.<br><img src="/imgs/ZooKeeper%E5%8E%9F%E7%90%86%E6%80%BB%E7%BB%93/replicated.jpg" alt="replicated" title="replicated"><br>The servers that make up the ZooKeeper service must all know about each other. They maintain an <strong>in-memory image of state</strong>, along with a <strong>transaction logs</strong> and <strong>snapshots</strong> in a persistent store. As long as a majority of the servers are available, the ZooKeeper service will be available.<br>Clients connect to a single ZooKeeper server. The client maintains a <strong>TCP</strong> connection through which it sends requests, gets responses, gets watch events, and sends heart beats. If the TCP connection to the server breaks, the client will connect to a different server.<br>Zookeeper 的工作集群可以简单分成两类，一个是 Leader，唯一一个，其余的都是 follower，如何确定 Leader 是通过内部选举确定的。</p>
<ul>
<li>Leader 和各个 follower 是互相通信的，对于 Zookeeper 系统的数据都是保存在内存里面的，同样也会备份一份在磁盘上。</li>
<li>如果 Leader 挂了，Zookeeper 集群会重新选举，在毫秒级别就会重新选举出一个 Leader。</li>
<li>集群中除非有一半以上的 Zookeeper 节点挂了，Zookeeper Service 才不可用。</li>
</ul>
<h3 id="ordered"><a href="#ordered" class="headerlink" title="ordered"></a>ordered</h3><p>ZooKeeper stamps each update with a number that reflects the order of all ZooKeeper transactions. Subsequent operations can use the order to implement higher-level abstractions, such as synchronization primitives.</p>
<h3 id="Total-order-原理"><a href="#Total-order-原理" class="headerlink" title="Total order 原理"></a>Total order 原理</h3><p>As stated above, ZooKeeper guarantees a total order of messages, and it also guarantees a total order of proposals. ZooKeeper exposes the total ordering using a ZooKeeper transaction id (zxid). All proposals will be stamped with a zxid when it is proposed and exactly reflects the total ordering. Proposals are sent to all ZooKeeper servers and committed when a quorum of them acknowledge the proposal. If a proposal contains a message, the message will be delivered when the proposal is committed. Acknowledgement means the server has recorded the proposal to persistent storage. Our quorums have the requirement that any pair of quorum must have at least one server in common. We ensure this by requiring that all quorums have size (n&#x2F;2+1) where n is the number of servers that make up a ZooKeeper service.<br>The <strong>zxid</strong> has two parts: the epoch and a counter. In our implementation the zxid is a 64-bit number. We use the high order 32-bits for the epoch and the low order 32-bits for the counter. Because it has two parts represent the zxid both as a number and as a pair of integers, (epoch, count). The epoch number represents a change in leadership. Each time a new leader comes into power it will have its own epoch number. We have a simple algorithm to assign a unique zxid to a proposal: the leader simply increments the zxid to obtain a unique zxid for each proposal. Leadership activation will ensure that only one leader uses a given epoch, so our simple algorithm guarantees that every proposal will have a unique id.</p>
<h3 id="多数派（Quorum）"><a href="#多数派（Quorum）" class="headerlink" title="多数派（Quorum）"></a>多数派（Quorum）</h3><p>一个由相同应用复制出来的组被称为一个多数派（Quorum），一个多数派中的所有服务器的配置文件都是一致的。<br> Atomic broadcast and leader election use the notion of quorum to guarantee a consistent view of the system. By default, ZooKeeper uses majority quorums, which means that every voting that happens in one of these protocols requires a majority to vote on. One example is acknowledging a leader proposal: the leader can only commit once it receives an acknowledgement from a quorum of servers.<br> If we extract the properties that we really need from our use of majorities, we have that we only need to guarantee that groups of processes used to validate an operation by voting (e.g., acknowledging a leader proposal) pairwise intersect in at least one server. Using majorities guarantees such a property. However, there are other ways of constructing quorums different from majorities. For example, we can assign weights to the votes of servers, and say that the votes of some servers are more important. To obtain a quorum, we get enough votes so that the sum of weights of all votes is larger than half of the total sum of all weights.<br> A different construction that uses weights and is useful in wide-area deployments (co-locations) is a hierarchical one. With this construction, we split the servers into disjoint groups and assign weights to processes. To form a quorum, we have to get a hold of enough servers from a majority of groups G, such that for each group g in G, the sum of votes from g is larger than half of the sum of weights in g. Interestingly, this construction enables smaller quorums. If we have, for example, 9 servers, we split them into 3 groups, and assign a weight of 1 to each server, then we are able to form quorums of size 4. Note that two subsets of processes composed each of a majority of servers from each of a majority of groups necessarily have a non-empty intersection. It is reasonable to expect that a majority of co-locations will have a majority of servers available with high probability.<br> With ZooKeeper, we provide a user with the ability of configuring servers to use majority quorums, weights, or a hierarchy of groups.</p>
<h3 id="与通信相关的概念"><a href="#与通信相关的概念" class="headerlink" title="与通信相关的概念"></a>与通信相关的概念</h3><ul>
<li>Packet<br>a sequence of bytes sent through a FIFO channel</li>
<li>Proposal（怎么翻译啊？？？）<br>a unit of agreement. Proposals are agreed upon by exchanging packets with a quorum of ZooKeeper servers. Most proposals contain messages, however the NEW_LEADER proposal is an example of a proposal that does not correspond to a message.</li>
<li>Message<br>a sequence of bytes to be atomically broadcast to all ZooKeeper servers. A message put into a proposal and agreed upon before it is delivered.</li>
</ul>
<h3 id="使用超时来容错"><a href="#使用超时来容错" class="headerlink" title="使用超时来容错"></a>使用超时来容错</h3><p>FLP proved that consensus cannot be achieved in asynchronous distributed systems if failures are possible. To ensure we achieve consensus in the presence of failures we use timeouts. However, we rely on times for liveness not for correctness. So, if timeouts stop working (clocks malfunction for example) the messaging system may hang, but it will not violate its guarantees.</p>
<h3 id="两阶段-Messaging"><a href="#两阶段-Messaging" class="headerlink" title="两阶段 Messaging"></a>两阶段 Messaging</h3><ul>
<li>Leader activation<br>In this phase a leader establishes the correct state of the system and gets ready to start making proposals.</li>
<li>Active messaging<br>In this phase a leader accepts messages to propose and coordinates message delivery.</li>
</ul>
<p>ZooKeeper is a holistic protocol. We do not focus on individual proposals, rather look at the stream of proposals as a whole. Our strict ordering allows us to do this efficiently and greatly simplifies our protocol. Leadership activation embodies this holistic concept. A leader becomes active only when a quorum of followers (The leader counts as a follower as well. You can always vote for yourself ) has synced up with the leader, they have the same state. This state consists of all of the proposals that the leader believes have been committed and the proposal to follow the leader, the NEW_LEADER proposal. (Hopefully you are thinking to yourself, Does the set of proposals that the leader believes has been committed included all the proposals that really have been committed? The answer is yes. Below, we make clear why.)</p>
<h4 id="ZAB-协议"><a href="#ZAB-协议" class="headerlink" title="ZAB 协议"></a>ZAB 协议</h4><p>Zookeeper 的核心是广播，这个机制保证了各个 Server 之间的同步。实现这个机制的协议叫做 Zab 协议。<br>Zab（ZooKeeper Atomic Broadcast）原子消息广播协议作为数据一致性的核心算法，Zab 协议是专为 Zookeeper 设计的支持崩溃恢复原子消息广播算法。<br>Zab 协议核心如下：<br>所有的事务请求必须一个全局唯一的服务器（Leader）来协调处理，集群其余的服务器称为 follower 服务器。Leader 服务器负责将一个客户端请求转化为事务提议（Proposal），并将该 proposal 分发给集群所有的 follower 服务器。之后 Leader 服务器需要等待所有的 follower 服务器的反馈，一旦<strong>超过了半数的 follower 服务器进行了正确反馈</strong>后，那么 Leader 服务器就会再次向所有的 follower 服务器分发 commit 消息，要求其将前一个 proposal 进行提交。<br>以上对Zab协议的简单描述有点像两阶段提交协议，只是“Prepare”阶段现在只需要半数以上返回正确反馈就可以进入“Commit”阶段了。</p>
<h4 id="ZAB-的两种模式"><a href="#ZAB-的两种模式" class="headerlink" title="ZAB 的两种模式"></a>ZAB 的两种模式</h4><p>Zab 协议包括两种基本的模式：<strong>崩溃恢复</strong>和<strong>消息广播</strong>。</p>
<ul>
<li>当整个服务框架启动过程中或 Leader 服务器出现网络中断、崩溃退出与重启等异常情况时，Zab 协议就会进入恢复模式并选举产生新的 Leader 服务器。</li>
<li>当选举产生了新的 Leader 服务器，同时集群中已经<strong>有过半的机器与该 Leader 服务器完成了状态同步</strong>之后，Zab 协议就会退出恢复模式，状态同步是指数据同步，用来保证集群在过半的机器能够和 Leader 服务器的数据状态保持一致。</li>
<li>当集群中已经有过半的 Follower 服务器完成了和 Leader 服务器的状态同步，那么整个服务框架就可以进入消息广播模式。</li>
<li>当一台同样遵守 Zab 协议的服务器启动后加入到集群中，如果此时集群中已经存在一个 Leader 服务器在负责进行消息广播，那么加入的服务器就会自觉地进入数据恢复模式：找到 Leader 所在的服务器，并与其进行数据同步，然后一起参与到消息广播流程中去。</li>
</ul>
<p>Zookeeper 只允许唯一的一个 Leader 服务器来进行事务请求的处理，Leader 服务器在接收到客户端的事务请求后，会生成对应的事务提议并发起一轮广播协议，而如果集群中的其他机器收到客户端的事务请求后，那么这些非 Leader 服务器会首先将这个事务请求转发给 Leader 服务器。</p>
<h4 id="选举算法概述"><a href="#选举算法概述" class="headerlink" title="选举算法概述"></a>选举算法概述</h4><p>当 leader 崩溃或者 leader 失去大多数的 follower，这时 zk 进入恢复模式，恢复模式的主要目的是选出一个唯一 Leader。<br>用一个小组开发作为场景，假设这个小组有两个开发经理（Leader）A 和 B，这两名经理都会发出 proposal 指令并在得到超过半数下属的答复后再发出一个 accept 指令，每条指令都带上当时的时间，下属只会在接受到时间最近的一条 proposal 对应的 accept 后才会真正开始工作，现在考虑这样的情况：</p>
<ol>
<li>A 发出 proposal 指令，并带上指令；</li>
<li>下属接受该指令；</li>
<li>B 发出 proposal 指令；</li>
<li>下属接受 B 的指令；</li>
<li>A 发出 accept 指令；</li>
<li>被下属忽略（因为 A 的 accept 指令的时间戳晚于 B 的 proposal 指令）；</li>
<li>A 于是又发出下一个 proposal；</li>
<li>下属接受新 proposal（覆盖掉 B 的指令）；</li>
<li>接下来轮到 B 的指令被忽略掉了，这样会陷入一个死循环。</li>
</ol>
<p>因此，&#96;Leader 必须是唯一的，不然会发生上述<strong>脑裂现象</strong>。</p>
<h4 id="ZooKeeper-是如何保证事务的顺序一致性的"><a href="#ZooKeeper-是如何保证事务的顺序一致性的" class="headerlink" title="ZooKeeper 是如何保证事务的顺序一致性的"></a>ZooKeeper 是如何保证事务的顺序一致性的</h4><p>ZooKeeper 采用了递增的事务 Id 来标识，所有的 proposal 都在被提出的时候加上了 zxid，zxid 实际上是一个 64 位的数字，高 32 位是 epoch 用来标识 leader 是否发生改变，如果有新的 leader 产生出来，epoch 会自增，低 32 位用来递增计数。当新产生 proposal 的时候，会依据数据库的两阶段过程，首先会向其他的 server 发出事务执行请求，如果超过半数的机器都能执行并且能够成功，那么就会开始执行。</p>
<h4 id="Leader-Activation"><a href="#Leader-Activation" class="headerlink" title="Leader Activation"></a>Leader Activation</h4><p>Leader activation includes leader election. We currently have two leader election algorithms in ZooKeeper: LeaderElection and FastLeaderElection (AuthFastLeaderElection is a variant of FastLeaderElection that uses UDP and allows servers to perform a simple form of authentication to avoid IP spoofing). ZooKeeper messaging doesn’t care about the exact method of electing a leader has long as the following holds:</p>
<ul>
<li>The leader has seen the highest zxid of all the followers.</li>
<li>A quorum of servers have committed to following the leader.</li>
</ul>
<p>Of these two requirements only the first, the highest zxid amoung the followers needs to hold for correct operation. The second requirement, a quorum of followers, just needs to hold with high probability. We are going to recheck the second requirement, so if a failure happens during or after the leader election and quorum is lost, we will recover by abandoning leader activation and running another election.<br>After leader election a single server will be designated as a leader and start waiting for followers to connect. The rest of the servers will try to connect to the leader. The leader will sync up with followers by sending any proposals they are missing, or if a follower is missing too many proposals, it will send a full snapshot of the state to the follower.<br>There is a corner case in which a follower that has proposals, U, not seen by a leader arrives. Proposals are seen in order, so the proposals of U will have a zxids higher than zxids seen by the leader. The follower must have arrived after the leader election, otherwise the follower would have been elected leader given that it has seen a higher zxid. Since committed proposals must be seen by a quorum of servers, and a quorum of servers that elected the leader did not see U, the proposals of you have not been committed, so they can be discarded. When the follower connects to the leader, the leader will tell the follower to discard U.<br>A new leader establishes a zxid to start using for new proposals by getting the epoch, e, of the highest zxid it has seen and setting the next zxid to use to be (e+1, 0), fter the leader syncs with a follower, it will propose a NEW_LEADER proposal. Once the NEW_LEADER proposal has been committed, the leader will activate and start receiving and issuing proposals.<br>It all sounds complicated but here are the basic rules of operation during leader activation:</p>
<ul>
<li>A follower will ACK the NEW_LEADER proposal after it has synced with the leader.</li>
<li>A follower will only ACK a NEW_LEADER proposal with a given zxid from a single server.</li>
<li>A new leader will COMMIT the NEW_LEADER proposal when a quorum of followers have ACKed it.</li>
<li>A follower will commit any state it received from the leader when the NEW_LEADER proposal is COMMIT.</li>
<li>A new leader will not accept new proposals until the NEW_LEADER proposal has been COMMITED.<br>If leader election terminates erroneously, we don’t have a problem since the NEW_LEADER proposal will not be committed since the leader will not have quorum. When this happens, the leader and any remaining followers will timeout and go back to leader election.</li>
</ul>
<h4 id="Leader-选举"><a href="#Leader-选举" class="headerlink" title="Leader 选举"></a>Leader 选举</h4><p>Leader 选举是保证分布式数据一致性的关键所在。当 Zookeeper 集群中的一台服务器出现以下两种情况之一时，需要进入 Leader 选举。</p>
<ol>
<li>服务器初始化启动。</li>
<li>服务器运行期间无法和 Leader 保持连接。</li>
</ol>
<p>Zookeeper 在 3.4.0 版本后只保留了 TCP 版本的 FastLeaderElection 选举算法。当一台机器进入 Leader 选举时，当前集群可能会处于以下两种状态：</p>
<ol>
<li>集群中已存在 Leader。</li>
<li>集群中不存在 Leader。</li>
</ol>
<p>对于集群中已经存在 Leader 而言，此种情况一般都是某台机器启动得较晚，在其启动之前，集群已经在正常工作，对这种情况，该机器试图去选举 Leader 时，会被告知当前服务器的 Leader 信息，对于该机器而言，仅仅需要和 Leader 机器建立起连接，并进行状态同步即可。</p>
<p>而在集群中不存在 Leader 情况下则会相对复杂，其步骤如下：</p>
<ol>
<li>第一次投票。无论哪种导致进行 Leader 选举，集群的所有机器都处于试图选举出一个 Leader 的状态，即 LOOKING 状态，LOOKING 机器会向所有其他机器发送消息，该消息称为投票。投票中包含了 SID（服务器的唯一标识）和 ZXID（事务 ID），(SID, ZXID)形式来标识一次投票信息。假定 Zookeeper 由 5 台机器组成，SID 分别为 1、2、3、4、5，ZXID 分别为 9、9、9、8、8，并且此时 SID 为 2 的机器是 Leader 机器，某一时刻，1、2 所在机器出现故障，因此集群开始进行 Leader 选举。在第一次投票时，每台机器都会将自己作为投票对象，于是 SID 为 3、4、5 的机器投票情况分别为(3, 9)，(4, 8)， (5, 8)。</li>
<li>变更投票。每台机器发出投票后，也会收到其他机器的投票，每台机器会根据一定规则来处理收到的其他机器的投票，并以此来决定是否需要变更自己的投票，这个规则也是整个 Leader 选举算法的核心所在，其中术语描述如下</li>
</ol>
<ul>
<li>vote_sid：接收到的投票中所推举 Leader 服务器的 SID。</li>
<li>vote_zxid：接收到的投票中所推举 Leader 服务器的 ZXID。</li>
<li>self_sid：当前服务器自己的 SID。</li>
<li>self_zxid：当前服务器自己的 ZXID。</li>
</ul>
<p>每次对收到的投票的处理，都是对(vote_sid, vote_zxid)和(self_sid, self_zxid)对比的过程。</p>
<ul>
<li>规则一：如果 vote_zxid 大于 self_zxid，就认可当前收到的投票，并再次将该投票发送出去。</li>
<li>规则二：如果 vote_zxid 小于 self_zxid，那么坚持自己的投票，不做任何变更。</li>
<li>规则三：如果 vote_zxid 等于 self_zxid，那么就对比两者的 SID，如果 vote_sid 大于 self_sid，那么就认可当前收到的投票，并再次将该投票发送出去。</li>
<li>规则四：如果 vote_zxid 等于 self_zxid，并且 vote_sid 小于 self_sid，那么坚持自己的投票，不做任何变更。</li>
</ul>
<p><img src="/imgs/ZooKeeper%E5%8E%9F%E7%90%86%E6%80%BB%E7%BB%93/Leader%E9%80%89%E4%B8%BE.png" alt="Leader选举" title="Leader选举"><br>结合上面规则，给出下面的集群变更过程。<br>3. 确定 Leader。经过第二轮投票后，集群中的每台机器都会再次接收到其他机器的投票，然后开始统计投票，如果一台机器收到了超过半数的相同投票，那么这个投票对应的 SID 机器即为 Leader。此时 Server3 将成为 Leader。</p>
<p>由上面规则可知，通常那台服务器上的数据越新（ZXID 会越大），其成为 Leader 的可能性越大，也就越能够保证数据的恢复。如果 ZXID 相同，则 SID 越大机会越大。</p>
<h4 id="Active-Messaging"><a href="#Active-Messaging" class="headerlink" title="Active Messaging"></a>Active Messaging</h4><p>Leader Activation does all the heavy lifting. Once the leader is coronated he can start blasting out proposals. As long as he remains the leader no other leader can emerge since no other leader will be able to get a quorum of followers. If a new leader does emerge, it means that the leader has lost quorum, and the new leader will clean up any mess left over during her leadership activation.<br>ZooKeeper messaging operates similar to a classic two-phase commit.<br><img src="/imgs/ZooKeeper%E5%8E%9F%E7%90%86%E6%80%BB%E7%BB%93/%E4%B8%A4%E9%98%B6%E6%AE%B5Messaging.jpg" alt="两阶段Messaging" title="两阶段Messaging"><br>All communication channels are FIFO, so everything is done in order. Specifically the following operating constraints are observed:</p>
<ul>
<li>The leader sends proposals to all followers using the same order. Moreover, this order follows the order in which requests have been received. Because we use FIFO channels this means that followers also receive proposals in order.</li>
<li>Followers process messages in the order they are received. This means that messages will be ACKed in order and the leader will receive ACKs from followers in order, due to the FIFO channels. It also means that if message $m$ has been written to non-volatile storage, all messages that were proposed before $m$ have been written to non-volatile storage.</li>
<li>The leader will issue a COMMIT to all followers as soon as a quorum of followers have ACKed a message. Since messages are ACKed in order, COMMITs will be sent by the leader as received by the followers in order.</li>
<li>COMMITs are processed in order. Followers deliver a proposals message when that proposal is committed.</li>
</ul>
<p>Zab 协议的消息广播过程使用是一个原子广播协议，类似一个 2PC 提交过程。具体的：</p>
<ul>
<li>ZooKeeper 使用单一主进程 Leader 用于处理客户端所有事务请求，并采用 Zab 的原子广播协议，将服务器数据状态变更以事务 Proposal 的形式广播 Follower 上，因此能很好的处理客户端的大量并发请求。</li>
<li>另一方面，由于事务间可能存在着依赖关系，Zab 协议保证 Leader 广播的变更序列被顺序的处理，有些状态的变更必须依赖于比它早生成的那些状态变更。</li>
<li>最后，考虑到主进程 Leader 在任何时候可能崩溃或者异常退出， 因此 Zab 协议还要 Leader 进程崩溃的时候可以重新选出 Leader 并且保证数据的完整性；Follower 收到 Proposal 后，写到磁盘，返回 Ack。Leader 收到大多数 ACK 后，广播 Commit 消息，自己也提交该消息。Follower 收到 Commit 之后，提交该消息。</li>
</ul>
<p>Zab 协议简化了 2PC 事务提交：</p>
<ul>
<li>去除中断逻辑移除，follower 要么 ack，要么抛弃 Leader。</li>
<li>Leader 不需要所有的 Follower 都响应成功，只要一个多数派 Ack 即可。</li>
</ul>
<h4 id="Paxos-ZAB-区别"><a href="#Paxos-ZAB-区别" class="headerlink" title="Paxos &amp; ZAB 区别"></a>Paxos &amp; ZAB 区别</h4><p>Paxos 是分布式选举算法，ZooKeeper 使用的 ZAB 协议（ZooKeeper Atomic Broadcast）。<br>二者有相同的地方。比如都有一个 Leader，用来协调 N 个 Follower 的运行；Leader 要等待超半数的 Follower 做出正确反馈之后才进行提案；二者都有一个值来代表 Leader 的周期（zxid 的前 32 位）。<br>二者不同的地方在于，ZAB 用来构建高可用的分布式数据主备系统（ZooKeeper），Paxos 是用来构建分布式一致性状态机系统的。</p>
<h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>So there you go. Why does it work? Specifically, why does is set of proposals believed by a new leader always contain any proposal that has actually been committed? First, all proposals have a unique zxid, so unlike other protocols, we never have to worry about two different values being proposed for the same zxid; followers (a leader is also a follower) see and record proposals in order; proposals are committed in order; there is only one active leader at a time since followers only follow a single leader at a time; a new leader has seen all committed proposals from the previous epoch since it has seen the highest zxid from a quorum of servers; any uncommited proposals from a previous epoch seen by a new leader will be committed by that leader before it becomes active.</p>
<h3 id="Comparisons"><a href="#Comparisons" class="headerlink" title="Comparisons"></a>Comparisons</h3><p>Isn’t this just Multi-Paxos? No, Multi-Paxos requires some way of assuring that there is only a single coordinator. We do not count on such assurances. Instead we use the leader activation to recover from leadership change or old leaders believing they are still active.<br>Isn’t this just Paxos? Your active messaging phase looks just like phase 2 of Paxos? Actually, to us active messaging looks just like 2 phase commit without the need to handle aborts. Active messaging is different from both in the sense that it has cross proposal ordering requirements. If we do not maintain strict FIFO ordering of all packets, it all falls apart. Also, our leader activation phase is different from both of them. In particular, our use of epochs allows us to skip blocks of uncommitted proposals and to not worry about duplicate proposals for a given zxid.</p>
<h1 id="QA"><a href="#QA" class="headerlink" title="QA"></a>QA</h1><h2 id="临时节点什么时候会触发自动清除"><a href="#临时节点什么时候会触发自动清除" class="headerlink" title="临时节点什么时候会触发自动清除"></a>临时节点什么时候会触发自动清除</h2><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li><a target="_blank" rel="noopener" href="https://blog.acolyer.org/2015/01/27/zookeeper-wait-free-coordination-for-internet-scale-systems/">ZooKeeper: wait-free coordination for internet scale systems</a></li>
<li><a target="_blank" rel="noopener" href="https://www.usenix.org/conference/usenix-atc-10/zookeeper-wait-free-coordination-internet-scale-systems">一个讲座视频 Presentation Video</a></li>
<li><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/42931473/answer/228592730">zookeeper 有什么缺点？</a></li>
<li><a target="_blank" rel="noopener" href="http://www.linkedkeeper.com/mobile/item.action?bid=1014">浅谈分布式服务协调技术 Zookeeper</a></li>
</ol>
<h3 id="集群原理"><a href="#集群原理" class="headerlink" title="集群原理"></a>集群原理</h3><ol>
<li><a target="_blank" rel="noopener" href="http://zookeeper.apache.org/doc/r3.4.10/zookeeperInternals.html#sc_quorum">ZooKeeper Internals</a></li>
<li>Documentation <a target="_blank" rel="noopener" href="http://zookeeper.apache.org/doc/current/index.html">http://zookeeper.apache.org/doc/current/index.html</a></li>
<li><a target="_blank" rel="noopener" href="https://www.cnblogs.com/gossip/p/7237991.html">浅谈分布式服务协调技术 Zookeeper</a></li>
<li><a target="_blank" rel="noopener" href="https://www.cnblogs.com/hapjin/p/5626889.html">分布式系统理论之 Quorum 机制</a></li>
</ol>
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kity@2.0.4/dist/kity.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text/javascript" src="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.6.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.6.0/dist/mindmap.min.css">
    </div>

    
    
    

    <footer class="post-footer">

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/cc7a2f74.html" rel="prev" title="ZooKeeper 的替代品">
                  <i class="fa fa-angle-left"></i> ZooKeeper 的替代品
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/60ef81a3.html" rel="next" title="ZooKeeper 的应用">
                  ZooKeeper 的应用 <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">tallate</span>
  </div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

  <a href="https://github.com/tallate" class="github-corner" title="在 GitHub 上关注我" aria-label="在 GitHub 上关注我" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>


  <script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"version":"7.1.2","options":null,"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.3.0/mermaid.min.js","integrity":"sha256-9y71g5Lz/KLsHjB8uXwnkuWDtAMDSzD/HdIbqhJfTAI="}}</script>
  <script src="/js/third-party/tags/mermaid.js"></script>





  





</body>
</html>
